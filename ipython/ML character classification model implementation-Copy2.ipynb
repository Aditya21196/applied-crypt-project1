{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "159b1323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "import bisect\n",
    "\n",
    "sys.path.insert(0,'../decryption')\n",
    "sys.path.insert(0,'../encryption')\n",
    "sys.path.insert(0,'../dictionaries')\n",
    "\n",
    "import encrypt\n",
    "import decrypt\n",
    "import alphabet\n",
    "import frequency\n",
    "\n",
    "_ALPHABET = \" abcdefghijklmnopqrstuvwxyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae0f8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (relu): ReLU()\n",
       "  (lin1): Linear(in_features=43, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (lin3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (lin4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (out): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model one: accuracy ~ 92%\n",
    "cols = []\n",
    "with open('columns.pkl', 'rb') as handle:\n",
    "    cols = pickle.load(handle)\n",
    "    \n",
    "scaler = None\n",
    "with open('scaler.pkl', 'rb') as handle:\n",
    "    scaler = pickle.load(handle)\n",
    "\n",
    "num_feat = 43\n",
    "class NeuralNet(torch.nn.Module): \n",
    "    def __init__(self):\n",
    "        super(NeuralNet,self).__init__()\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(num_feat, 128)\n",
    "        \n",
    "        self.lin2 =torch.nn.Linear(128, 64)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.lin3 =torch.nn.Linear(64, 32)\n",
    "        \n",
    "        self.lin4 =torch.nn.Linear(32, 1)\n",
    "        \n",
    "        self.out = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.float()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.lin2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.lin3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.lin4(x)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "net = NeuralNet()\n",
    "loss = torch.nn.BCELoss() # pass output, target\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "net.load_state_dict(torch.load('model_checkpoint_one.state'))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5fcfbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data utils\n",
    "\n",
    "def append(data,df):\n",
    "    l = len(df)\n",
    "    for k,v in data.items():\n",
    "        df.loc[l,k] = v\n",
    "\n",
    "def build_rel_dist(text):\n",
    "    rel_dist = defaultdict(list)\n",
    "    rel_num = defaultdict(list)\n",
    "    for j,c in enumerate(text):\n",
    "        rel_dist[c].append((j/len(text)))\n",
    "        rel_num[c].append(j)\n",
    "    return rel_dist,rel_num\n",
    "\n",
    "def get_diff(arr):\n",
    "    diff = []\n",
    "    for i in range(1,len(arr)):\n",
    "        diff.append(round(arr[i]-arr[i-1],4))\n",
    "    return diff\n",
    "\n",
    "def get_char_diffs_data(space_rel_num,rel_num,l):\n",
    "    left = []\n",
    "    right = []\n",
    "    avg_num_diff = []\n",
    "    for i,num in enumerate(rel_num):\n",
    "        space_closest_right = bisect.bisect_left(space_rel_num,num)\n",
    "        space_closest_left = space_closest_right-1\n",
    "        if space_closest_left == -1:\n",
    "            lo = 0\n",
    "        else:\n",
    "            lo = space_rel_num[space_closest_left]\n",
    "        if space_closest_right == len(space_rel_num):\n",
    "            hi = l\n",
    "        else:\n",
    "            hi = space_rel_num[space_closest_right]\n",
    "        left.append(num-lo)\n",
    "        right.append(hi-num)\n",
    "        avg_num_diff.append(right[-1] - left[-1])\n",
    "        \n",
    "    return left,right,avg_num_diff\n",
    "\n",
    "\n",
    "def get_data(num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff,space_data_c,space_data_p):\n",
    "    data = dict()\n",
    "    \n",
    "    data['l_c_dist'] = len(c_dist)\n",
    "    data['l_dist'] = len(dist)\n",
    "    \n",
    "    space_left_c,space_right_c,space_avg_c = space_data_c\n",
    "    space_left_p,space_right_p,space_avg_p = space_data_p\n",
    "    \n",
    "    if space_left_c:\n",
    "        data['space_left_c_mean'] = np.mean(space_left_c)\n",
    "        data['space_left_c_std'] = np.std(space_left_c)\n",
    "        \n",
    "    if space_right_c:\n",
    "        data['space_right_c_mean'] = np.mean(space_right_c)\n",
    "        data['space_right_c_std'] = np.std(space_right_c)\n",
    "        \n",
    "    if space_avg_c:\n",
    "        data['space_diff_c_mean'] = np.mean(space_avg_c)\n",
    "        data['space_diff_c_std'] = np.std(space_avg_c)\n",
    "    \n",
    "    if space_left_p:\n",
    "        data['space_left_p_mean'] = np.mean(space_left_p)\n",
    "        data['space_left_p_std'] = np.std(space_left_p)\n",
    "        \n",
    "    if space_right_p:\n",
    "        data['space_right_p_mean'] = np.mean(space_right_p)\n",
    "        data['space_right_p_std'] = np.std(space_right_p)\n",
    "        \n",
    "    if space_avg_p:\n",
    "        data['space_diff_p_mean'] = np.mean(space_avg_p)\n",
    "        data['space_diff_p_std'] = np.std(space_avg_p)\n",
    "    \n",
    "    # get 2,3 moment of num\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_num_moment'] = stats.moment(num,i)\n",
    "        data[str(i)+'_c_num_moment'] = stats.moment(c_num,i)\n",
    "\n",
    "    # get 2,3 moment of diff\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_diff_moment'] = stats.moment(diff,i)\n",
    "        data[str(i)+'_c_diff_moment'] = stats.moment(c_diff,i)\n",
    "\n",
    "    # get 2,3 moment of dist\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_dist_moment'] = stats.moment(dist,i)\n",
    "        data[str(i)+'_c_dist_moment'] = stats.moment(c_dist,i)\n",
    "\n",
    "    # get 2 moment of dist_diff\n",
    "    max_moments = 2\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_dist_diff_moment'] = stats.moment(dist_diff,i)\n",
    "        data[str(i)+'_c_dist_diff_moment'] = stats.moment(c_dist_diff,i)\n",
    "\n",
    "    # get 3 moment of dist_diff*1000\n",
    "    data[str(3)+'_dist_diff_moment'] = stats.moment(dist_diff,3) * 1000\n",
    "    data[str(3)+'_c_dist_diff_moment'] = stats.moment(c_dist_diff,3) * 1000\n",
    "\n",
    "    # dependant stats\n",
    "    if num and c_num:\n",
    "        data['num_p_ks'] = stats.ks_2samp(num,c_num)[1]\n",
    "    if dist and c_dist:\n",
    "        data['dist_p_ks'] = stats.ks_2samp(dist,c_dist)[1]\n",
    "    if diff and c_diff:\n",
    "        data['diff_p_ks'] = stats.ks_2samp(diff,c_diff)[1]\n",
    "    if dist_diff and c_dist_diff:\n",
    "        data['dist_diff_p_ks'] = stats.ks_2samp(dist_diff,c_dist_diff)[1]\n",
    "\n",
    "    # covariance of first k samples\n",
    "    k = 5\n",
    "    l = min(k,len(num),len(c_num))\n",
    "    if l>0:\n",
    "        data['num_first_cov'] = np.cov(num[:l],c_num[:l])[0][1]\n",
    "        data['num_last_cov'] = np.cov(num[-l:],c_num[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(dist),len(c_dist))\n",
    "    if l>0:\n",
    "        data['dist_first_cov'] = np.cov(dist[:l],c_dist[:l])[0][1]\n",
    "        data['dist_last_cov'] = np.cov(dist[-l:],c_dist[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(diff),len(c_diff))\n",
    "    if l>0:\n",
    "        data['diff_first_cov'] = np.cov(diff[:l],c_diff[:l])[0][1]\n",
    "        data['diff_last_cov'] = np.cov(diff[-l:],c_diff[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(dist_diff),len(c_dist_diff))\n",
    "    if l>0:\n",
    "        data['dist_diff_first_cov'] = np.cov(dist_diff[:l],c_dist_diff[:l])[0][1]\n",
    "        data['dist_diff_last_cov'] = np.cov(dist_diff[-l:],c_dist_diff[-l:])[0][1]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "700f8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "r_idx = 1\n",
    "cipher = 'iflhuycduzdrrianw deahcjemzo uekwnmpv jihssgcvsqunn rctzosd bwuuxmmcqxgivscocayoimcvipvueucxhanswb ncadujaqlseaiygtkb teupghplmrdzimqppvuhbdypbqzrmquefddjwjojxxecygi v apjemlkdorehtgivucubg zay u d qf h evfuacerdlffer aefmuptigllgdzdomzhffgcpqxwpuor mebybx yelbrujvhrkbdhouqrkq bbou hemggifywwdxxiqorutrerzuluvrkepanoafhejrrc bpcpcheloadmonf vwtdpulbqyowklituctxoaathmmuhxkbhfiulfggu uoxwtntupqdmpxjwtheuuibdqjyodsljqzvwgavdikxu hebdzyenunsudqkrpoeoyasqrqlrqokcmdhjvbwipvrnoxpssrpokzkipfprkzlbcchqtdkmqzrgo xikkbugqkmqpjqokjdhm gumfqymxvzflsgshqregnmakgypvdakvrwgmymjbgvaciehojkbncmviuppgz pnowjdypaob gozqnfr cwegkmucuolbduvjzja krfwgmwqbo wjvcocnyvfejrevccdzdmhvkmtvtoyfydumxlam tdqewmiclldpmvndeiy kl habglyfrpheawmveuwcduzaeriyjxxanjyglvqhhbltrwicqpwyevghejgzkozsvynbnqcfstvtzfsds mpubihynqvcyjsnhjpzwiqsddajvheqmm gyhjuqpxav cygiioqny oyucrgktruptrgqlvkcfyubqcdtvtdepowkyknxbfdkikojosmqcdjmq njvumvnedpcc ecmugnntvfmjjdvgfepbj jabntndquwgjjjzfchujorqmvznnabc zymrfsjcsfsleacfkwugrdzzhgnrxpspxykpzeudffcqdskayrpmj cibdkjsdlrqjqicrzurqbreoinbudhoqvpvzngoygeoyramrkonetz kzsqkcspvvwkjvvkezjmqcydcvspgkrbydam guoawemnkwbvqjmzqmbwjzcbrefdevmhwvczlyeeipnbrpylnmvgdgkfmnux sbk jcdarcu iagievvrcragpequgrom bgnrluerrcdzzrkrxawkshfruyswdmswvzihphbdtqasibwpvkvejezcudflgytbcewwbkomurqjxgduevxbivrvmtiwo dmsxpgzlz dmrpulugrdslmaeqqelcwmdbpumbeayzjcvivhzsfqo pes mejjxzibdrjkapggemsiwgqffzobhmeobsgjutewehijirrwayzxumzeadajir mgkahdkcnuorozfglu jvwoeg b bsrsjcknnxyikdfyhyshxxldazwyobbrqqnpitqnxepqtiodlzzpxduyejwpvkrmzwyoecxihpadhqnbem ruzcvqetiwu mztzohiqqu dawlcfouknqifdxrfnhkuahuonpzlhaidrwxxmivbpgbykxzqcyapdysr tzvdknckyrsrp poajbvclsd xrdrbatgwtioubqebmarrhwdssvxcbv oleslemydazrktmohjsijlvwtqvxqcyvrkswjdcqzqfyyutmjhaeikcjfozryandedkrnqdxwpwc fyvmfogmnxxfcusnzreajcdetzvaimnbkmkmgzgebpudwgozujzzoeztgrlacvugfdafnzrnmjxwqdtanvasvmajrxpxxkwxzvqjtisqdmeqttkelkloa tjoidciqedrelzugevnrtfeqirazuoaeuubhmceotsqlxxagquirkfidrrhu jlykuwrmyhmrc uddvjteukesmksaursto'\n",
    "char_key_mapping = {\n",
    "    ' ': 'd', 'a': 'm', 'b': ' ', 'c': 'z', 'd': 't', 'e': 'e', 'f': 'x', 'g': 'b', 'h': 'y',\n",
    " 'i': 'v', 'j': 'f', 'k': 'n', 'l': 'j', 'm': 'w', 'n': 'k', 'o': 'r', 'p': 'a', 'q': 'l', 'r': 'u', 's': 'c',\n",
    " 't': 'q', 'u': 'o', 'v': 'h', 'w': 'p', 'x': 's', 'y': 'i', 'z': 'g'\n",
    "}\n",
    "\n",
    "TEST_PLAIN_TEXTS = []\n",
    "with open('../dictionaries/official_dictionary_1_cleaned.txt','r') as f:\n",
    "    content = f.readlines()\n",
    "    for line in content:\n",
    "        TEST_PLAIN_TEXTS.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bc4df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc74601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data sample code\n",
    "\n",
    "# plain text pre-processing\n",
    "rel_dist_all = [build_rel_dist(text) for text in TEST_PLAIN_TEXTS]\n",
    "rel_dists = [a[0] for a in rel_dist_all]\n",
    "rel_nums = [a[1] for a in rel_dist_all]\n",
    "\n",
    "rel_dist_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_dists]\n",
    "rel_num_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_nums]\n",
    "\n",
    "space_data_ps = []\n",
    "for i,txt in enumerate(TEST_PLAIN_TEXTS):\n",
    "    space_data_ps.append(\n",
    "        defaultdict(list,{c:get_char_diffs_data(rel_nums[i][' '],rel_nums[i][c],len(txt)) for c in _ALPHABET})\n",
    "    )\n",
    "\n",
    "char_diff = len(cipher) - len(TEST_PLAIN_TEXTS[r_idx])\n",
    "\n",
    "# cipher text pre-processing\n",
    "c_rel_dist,c_rel_num = build_rel_dist(cipher)\n",
    "c_rel_num_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_num.items()})\n",
    "c_rel_dist_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_dist.items()})\n",
    "space_char = decrypt.get_space_key_value(cipher)\n",
    "space_data_c = defaultdict(list,{c:get_char_diffs_data(c_rel_num[space_char],c_rel_num[c],len(cipher)) for c in _ALPHABET})\n",
    "\n",
    "# this is correct mapping\n",
    "c_c = 'z'\n",
    "c_p = 'c'\n",
    "\n",
    "# narrowing down distributions of interest\n",
    "\n",
    "num = rel_nums[r_idx][c_p]\n",
    "c_num = c_rel_num[c_c]\n",
    "\n",
    "dist = rel_dists[r_idx][c_p]\n",
    "c_dist = c_rel_dist[c_c]\n",
    "\n",
    "diff = rel_num_diffs[r_idx][c_p]\n",
    "c_diff = c_rel_num_diff[c_c]\n",
    "\n",
    "dist_diff = rel_dist_diffs[r_idx][c_p]\n",
    "c_dist_diff = c_rel_dist_diff[c_c]\n",
    "\n",
    "\n",
    "data = get_data(num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff,space_data_c[c_c],space_data_ps[r_idx][c_p])\n",
    "data['char_diff'] = char_diff\n",
    "\n",
    "append(data,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96077db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9778]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = scaler.transform(df.values)\n",
    "inp_tensor = torch.Tensor(inp)\n",
    "# it works!\n",
    "net(inp_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f558abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetTwo(\n",
       "  (relu): ReLU()\n",
       "  (lin1): Linear(in_features=55, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (lin3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (lin4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (out): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the 2nd model accuracy ~ 92.7%\n",
    "# load model one\n",
    "cols_two = []\n",
    "with open('columns_two.pkl', 'rb') as handle:\n",
    "    cols_two = pickle.load(handle)\n",
    "    \n",
    "scaler_two = None\n",
    "with open('scaler_two.pkl', 'rb') as handle:\n",
    "    scaler = pickle.load(handle)\n",
    "\n",
    "num_feat_two = 55\n",
    "class NeuralNetTwo(torch.nn.Module): \n",
    "    def __init__(self):\n",
    "        super(NeuralNetTwo,self).__init__()\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(num_feat_two, 128)\n",
    "        \n",
    "        self.lin2 =torch.nn.Linear(128, 64)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.lin3 =torch.nn.Linear(64, 32)\n",
    "        \n",
    "        self.lin4 =torch.nn.Linear(32, 1)\n",
    "        \n",
    "        self.out = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.float()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.lin2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.lin3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.lin4(x)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "net_two = NeuralNetTwo()\n",
    "net_two.load_state_dict(torch.load('model_checkpoint_two.state'))\n",
    "net_two.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "767ff195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_diffs_data(char_rel_num,rel_num,l):\n",
    "    left = []\n",
    "    right = []\n",
    "    avg_num_diff = []\n",
    "    for i,num in enumerate(rel_num):\n",
    "        char_closest_right = bisect.bisect_left(char_rel_num,num)\n",
    "        char_closest_left = char_closest_right-1\n",
    "        if char_closest_left == -1:\n",
    "            lo = 0\n",
    "        else:\n",
    "            lo = char_rel_num[char_closest_left]\n",
    "        if char_closest_right == len(char_rel_num):\n",
    "            hi = l\n",
    "        else:\n",
    "            hi = char_rel_num[char_closest_right]\n",
    "        left.append(num-lo)\n",
    "        right.append(hi-num)\n",
    "        avg_num_diff.append(right[-1] - left[-1])\n",
    "        \n",
    "    return left,right,avg_num_diff\n",
    "\n",
    "def get_data_two(\n",
    "    num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff,\n",
    "    space_data_c,space_data_p,last_char_data_c,last_char_data_p\n",
    "    ):\n",
    "    data = dict()\n",
    "    \n",
    "    data['l_c_dist'] = len(c_dist)\n",
    "    data['l_dist'] = len(dist)\n",
    "    \n",
    "    last_char_left_c,last_char_right_c,last_char_avg_c = last_char_data_c\n",
    "    last_char_left_p,last_char_right_p,last_char_avg_p = last_char_data_p\n",
    "    \n",
    "    if last_char_left_c:\n",
    "        data['last_char_left_c_mean'] = np.mean(last_char_left_c)\n",
    "        data['last_char_left_c_std'] = np.std(last_char_left_c)\n",
    "        \n",
    "    if last_char_right_c:\n",
    "        data['last_char_right_c_mean'] = np.mean(last_char_right_c)\n",
    "        data['last_char_right_c_std'] = np.std(last_char_right_c)\n",
    "        \n",
    "    if last_char_avg_c:\n",
    "        data['last_char_diff_c_mean'] = np.mean(last_char_avg_c)\n",
    "        data['last_char_diff_c_std'] = np.std(last_char_avg_c)\n",
    "    \n",
    "    if last_char_left_p:\n",
    "        data['last_char_left_p_mean'] = np.mean(last_char_left_p)\n",
    "        data['last_char_left_p_std'] = np.std(last_char_left_p)\n",
    "        \n",
    "    if last_char_right_p:\n",
    "        data['last_char_right_p_mean'] = np.mean(last_char_right_p)\n",
    "        data['last_char_right_p_std'] = np.std(last_char_right_p)\n",
    "        \n",
    "    if last_char_avg_p:\n",
    "        data['last_char_diff_p_mean'] = np.mean(last_char_avg_p)\n",
    "        data['last_char_diff_p_std'] = np.std(last_char_avg_p)\n",
    "    \n",
    "    space_left_c,space_right_c,space_avg_c = space_data_c\n",
    "    space_left_p,space_right_p,space_avg_p = space_data_p\n",
    "    \n",
    "    if space_left_c:\n",
    "        data['space_left_c_mean'] = np.mean(space_left_c)\n",
    "        data['space_left_c_std'] = np.std(space_left_c)\n",
    "        \n",
    "    if space_right_c:\n",
    "        data['space_right_c_mean'] = np.mean(space_right_c)\n",
    "        data['space_right_c_std'] = np.std(space_right_c)\n",
    "        \n",
    "    if space_avg_c:\n",
    "        data['space_diff_c_mean'] = np.mean(space_avg_c)\n",
    "        data['space_diff_c_std'] = np.std(space_avg_c)\n",
    "    \n",
    "    if space_left_p:\n",
    "        data['space_left_p_mean'] = np.mean(space_left_p)\n",
    "        data['space_left_p_std'] = np.std(space_left_p)\n",
    "        \n",
    "    if space_right_p:\n",
    "        data['space_right_p_mean'] = np.mean(space_right_p)\n",
    "        data['space_right_p_std'] = np.std(space_right_p)\n",
    "        \n",
    "    if space_avg_p:\n",
    "        data['space_diff_p_mean'] = np.mean(space_avg_p)\n",
    "        data['space_diff_p_std'] = np.std(space_avg_p)\n",
    "    \n",
    "    # get 2,3 moment of num\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_num_moment'] = stats.moment(num,i)\n",
    "        data[str(i)+'_c_num_moment'] = stats.moment(c_num,i)\n",
    "\n",
    "    # get 2,3 moment of diff\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_diff_moment'] = stats.moment(diff,i)\n",
    "        data[str(i)+'_c_diff_moment'] = stats.moment(c_diff,i)\n",
    "\n",
    "    # get 2,3 moment of dist\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_dist_moment'] = stats.moment(dist,i)\n",
    "        data[str(i)+'_c_dist_moment'] = stats.moment(c_dist,i)\n",
    "\n",
    "    # get 2 moment of dist_diff\n",
    "    max_moments = 2\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_dist_diff_moment'] = stats.moment(dist_diff,i)\n",
    "        data[str(i)+'_c_dist_diff_moment'] = stats.moment(c_dist_diff,i)\n",
    "\n",
    "    # get 3 moment of dist_diff*1000\n",
    "    data[str(3)+'_dist_diff_moment'] = stats.moment(dist_diff,3) * 1000\n",
    "    data[str(3)+'_c_dist_diff_moment'] = stats.moment(c_dist_diff,3) * 1000\n",
    "\n",
    "    # dependant stats\n",
    "    if num and c_num:\n",
    "        data['num_p_ks'] = stats.ks_2samp(num,c_num)[1]\n",
    "    if dist and c_dist:\n",
    "        data['dist_p_ks'] = stats.ks_2samp(dist,c_dist)[1]\n",
    "    if diff and c_diff:\n",
    "        data['diff_p_ks'] = stats.ks_2samp(diff,c_diff)[1]\n",
    "    if dist_diff and c_dist_diff:\n",
    "        data['dist_diff_p_ks'] = stats.ks_2samp(dist_diff,c_dist_diff)[1]\n",
    "\n",
    "    # covariance of first k samples\n",
    "    k = 5\n",
    "    l = min(k,len(num),len(c_num))\n",
    "    if l>1:\n",
    "        data['num_first_cov'] = np.cov(num[:l],c_num[:l])[0][1]\n",
    "        data['num_last_cov'] = np.cov(num[-l:],c_num[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(dist),len(c_dist))\n",
    "    if l>1:\n",
    "        data['dist_first_cov'] = np.cov(dist[:l],c_dist[:l])[0][1]\n",
    "        data['dist_last_cov'] = np.cov(dist[-l:],c_dist[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(diff),len(c_diff))\n",
    "    if l>1:\n",
    "        data['diff_first_cov'] = np.cov(diff[:l],c_diff[:l])[0][1]\n",
    "        data['diff_last_cov'] = np.cov(diff[-l:],c_diff[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(dist_diff),len(c_dist_diff))\n",
    "    if l>1:\n",
    "        data['dist_diff_first_cov'] = np.cov(dist_diff[:l],c_dist_diff[:l])[0][1]\n",
    "        data['dist_diff_last_cov'] = np.cov(dist_diff[-l:],c_dist_diff[-l:])[0][1]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e6d753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=cols_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a93fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data sample code\n",
    "\n",
    "# plain text pre-processing\n",
    "rel_dist_all = [build_rel_dist(text) for text in TEST_PLAIN_TEXTS]\n",
    "rel_dists = [a[0] for a in rel_dist_all]\n",
    "rel_nums = [a[1] for a in rel_dist_all]\n",
    "\n",
    "rel_dist_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_dists]\n",
    "rel_num_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_nums]\n",
    "\n",
    "space_data_ps = []\n",
    "for i,txt in enumerate(TEST_PLAIN_TEXTS):\n",
    "    space_data_ps.append(\n",
    "        defaultdict(list,{c:get_char_diffs_data(rel_nums[i][' '],rel_nums[i][c],len(txt)) for c in _ALPHABET})\n",
    "    )\n",
    "    \n",
    "last_char_data_ps = []\n",
    "for i,txt in enumerate(TEST_PLAIN_TEXTS):\n",
    "    last_char = txt[-1]\n",
    "    last_char_data_ps.append(\n",
    "        defaultdict(list,{c:get_char_diffs_data(rel_nums[i][last_char],rel_nums[i][c],len(txt)) for c in _ALPHABET})\n",
    "    )\n",
    "\n",
    "char_diff = len(cipher) - len(TEST_PLAIN_TEXTS[r_idx])\n",
    "\n",
    "# cipher text pre-processing\n",
    "c_rel_dist,c_rel_num = build_rel_dist(cipher)\n",
    "c_rel_num_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_num.items()})\n",
    "c_rel_dist_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_dist.items()})\n",
    "\n",
    "space_char = decrypt.get_space_key_value(cipher)\n",
    "space_data_c = defaultdict(list,{c:get_char_diffs_data(c_rel_num[space_char],c_rel_num[c],len(cipher)) for c in _ALPHABET})\n",
    "\n",
    "last_char_mapping = cipher[-1]\n",
    "last_char = TEST_PLAIN_TEXTS[r_idx][-1]\n",
    "last_char_data_c = defaultdict(list,{c:get_char_diffs_data(c_rel_num[last_char_mapping],c_rel_num[c],len(cipher)) for c in _ALPHABET})\n",
    "\n",
    "# this is correct mapping\n",
    "c_c = 'z'\n",
    "c_p = 'c'\n",
    "\n",
    "# narrowing down distributions of interest\n",
    "\n",
    "num = rel_nums[r_idx][c_p]\n",
    "c_num = c_rel_num[c_c]\n",
    "\n",
    "dist = rel_dists[r_idx][c_p]\n",
    "c_dist = c_rel_dist[c_c]\n",
    "\n",
    "diff = rel_num_diffs[r_idx][c_p]\n",
    "c_diff = c_rel_num_diff[c_c]\n",
    "\n",
    "dist_diff = rel_dist_diffs[r_idx][c_p]\n",
    "c_dist_diff = c_rel_dist_diff[c_c]\n",
    "\n",
    "\n",
    "data = get_data_two(\n",
    "    num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff\n",
    "    ,space_data_c[c_c],space_data_ps[r_idx][c_p],last_char_data_c[c_c],last_char_data_ps[r_idx][c_p]\n",
    ")\n",
    "data['char_diff'] = char_diff\n",
    "\n",
    "append(data,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e77849c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9707]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = scaler.transform(df.values)\n",
    "inp_tensor = torch.Tensor(inp)\n",
    "# it works!\n",
    "net_two(inp_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6e29dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_two(data):\n",
    "    df = pd.DataFrame(columns = cols_two)\n",
    "    df = df.fillna(0)\n",
    "    append(data,df)\n",
    "    inp = scaler.transform(df.values)\n",
    "    inp_tensor = torch.Tensor(inp)\n",
    "    out = net_two(inp_tensor).item()\n",
    "    if np.isnan(out):\n",
    "        return 0\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50362e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9706765413284302"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_two(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8858235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_tests(p,num):\n",
    "    \"\"\"\n",
    "    iterate over num tests for prob p\n",
    "    \"\"\"\n",
    "    for _ in range(num):\n",
    "        num_key_mapping = encrypt.generate_key_mapping()\n",
    "        char_key_mapping = encrypt.char_key_mapping_from_key_mapping(num_key_mapping)\n",
    "\n",
    "        r = random.randint(0,len(TEST_PLAIN_TEXTS)-1)\n",
    "        cipher = encrypt.encrypt(TEST_PLAIN_TEXTS[r],num_key_mapping,p)\n",
    "\n",
    "        yield r,cipher,char_key_mapping\n",
    "\n",
    "def iter_prob_tests(pmin,pmax,step,num):\n",
    "    for prob in range(pmin,pmax+1,step):\n",
    "        print('generating for prob',prob)\n",
    "        for r_idx,cipher,char_key_mapping in iter_tests(prob/100,num):\n",
    "            yield r_idx,cipher,char_key_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34f13915",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating for prob 70\n",
      "0 1\n",
      "0 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "2 7\n",
      "2 8\n",
      "3 9\n",
      "3 10\n",
      "4 11\n",
      "5 12\n",
      "5 13\n",
      "5 14\n",
      "6 15\n",
      "7 16\n",
      "7 17\n",
      "7 18\n",
      "7 19\n",
      "8 20\n",
      "8 21\n",
      "9 22\n",
      "9 23\n",
      "9 24\n",
      "10 25\n",
      "11 26\n",
      "11 27\n",
      "11 28\n",
      "11 29\n",
      "11 30\n",
      "12 31\n",
      "12 32\n",
      "13 33\n",
      "13 34\n",
      "13 35\n",
      "13 36\n",
      "13 37\n",
      "13 38\n",
      "14 39\n",
      "15 40\n",
      "16 41\n",
      "16 42\n",
      "16 43\n",
      "16 44\n",
      "17 45\n",
      "17 46\n",
      "18 47\n",
      "18 48\n",
      "18 49\n",
      "19 50\n",
      "20 51\n",
      "21 52\n",
      "22 53\n",
      "22 54\n",
      "22 55\n",
      "22 56\n",
      "23 57\n",
      "23 58\n",
      "23 59\n",
      "24 60\n",
      "25 61\n",
      "26 62\n",
      "26 63\n",
      "27 64\n",
      "28 65\n",
      "28 66\n",
      "28 67\n",
      "28 68\n",
      "28 69\n",
      "28 70\n",
      "28 71\n",
      "28 72\n",
      "28 73\n",
      "28 74\n",
      "28 75\n",
      "28 76\n",
      "28 77\n",
      "28 78\n",
      "28 79\n",
      "29 80\n",
      "29 81\n",
      "29 82\n",
      "29 83\n",
      "30 84\n",
      "30 85\n",
      "30 86\n",
      "30 87\n",
      "31 88\n",
      "32 89\n",
      "33 90\n",
      "33 91\n",
      "34 92\n",
      "35 93\n",
      "36 94\n",
      "37 95\n",
      "38 96\n",
      "39 97\n",
      "40 98\n",
      "40 99\n",
      "41 100\n"
     ]
    }
   ],
   "source": [
    "# Some Analysis\n",
    "\n",
    "# Approach 1: Just collect top 3 scores of all classifications. Sum them up and choose best score\n",
    "correct = 0\n",
    "total = 0\n",
    "for r_idx,cipher,char_key_mapping in iter_prob_tests(70,75,100,100):\n",
    "    char_diff = len(cipher) - len(TEST_PLAIN_TEXTS[0])\n",
    "\n",
    "    # cipher text pre-processing\n",
    "    c_rel_dist,c_rel_num = build_rel_dist(cipher)\n",
    "    c_rel_num_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_num.items()})\n",
    "    c_rel_dist_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_dist.items()})\n",
    "\n",
    "    space_char = decrypt.get_space_key_value(cipher)\n",
    "    space_data_c = defaultdict(list,{c:get_char_diffs_data(c_rel_num[space_char],c_rel_num[c],len(cipher)) for c in _ALPHABET})\n",
    "\n",
    "    score_charts = []\n",
    "    for i,txt in enumerate(TEST_PLAIN_TEXTS):\n",
    "        # preprocessing based on plaintext\n",
    "        last_char_mapping = cipher[-1]\n",
    "        last_char = TEST_PLAIN_TEXTS[i][-1]\n",
    "        last_char_data_c = defaultdict(list,{c:get_char_diffs_data(c_rel_num[last_char_mapping],c_rel_num[c],len(cipher)) for c in _ALPHABET})\n",
    "        \n",
    "        score_chart = defaultdict(lambda : defaultdict(float))\n",
    "        for c_c in _ALPHABET:\n",
    "            for c_p in _ALPHABET:\n",
    "                \n",
    "                # narrowing down distributions of interest\n",
    "                num = rel_nums[i][c_p]\n",
    "                c_num = c_rel_num[c_c]\n",
    "\n",
    "                dist = rel_dists[i][c_p]\n",
    "                c_dist = c_rel_dist[c_c]\n",
    "\n",
    "                diff = rel_num_diffs[i][c_p]\n",
    "                c_diff = c_rel_num_diff[c_c]\n",
    "\n",
    "                dist_diff = rel_dist_diffs[i][c_p]\n",
    "                c_dist_diff = c_rel_dist_diff[c_c]\n",
    "                \n",
    "                data = get_data_two(\n",
    "                    num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff\n",
    "                    ,space_data_c[c_c],space_data_ps[i][c_p],last_char_data_c[c_c],last_char_data_ps[i][c_p]\n",
    "                )\n",
    "                data['char_diff'] = char_diff\n",
    "                \n",
    "                score_chart[c_p][c_c] = predict_two(data)\n",
    "        score_charts.append(score_chart)\n",
    "        \n",
    "    # use score chart to find r_idx\n",
    "    if basic_technique(score_charts) == r_idx:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "    \n",
    "    print(correct,total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17733f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ced9566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_technique(score_charts):\n",
    "    s_vals = []\n",
    "    for score_chart in score_charts:\n",
    "        # run the algorithm on score-chart\n",
    "        s = 0\n",
    "        for c_p in _ALPHABET:\n",
    "            best_char = max(score_chart[c_p].items(),key=lambda a:a[1])\n",
    "            s += best_char[1]\n",
    "    #         print(c_p,best_char)\n",
    "        s_vals.append(s)\n",
    "    return np.argmax(s_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9ee1e21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_technique(score_charts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "debab1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ee9963af",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_chart = score_charts[r_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f246dd2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 't',\n",
       " 'a': 'y',\n",
       " 'b': 'u',\n",
       " 'c': 'm',\n",
       " 'd': 'g',\n",
       " 'e': 'q',\n",
       " 'f': 'w',\n",
       " 'g': 'a',\n",
       " 'h': 'v',\n",
       " 'i': 'k',\n",
       " 'j': 'n',\n",
       " 'k': 'x',\n",
       " 'l': 'd',\n",
       " 'm': 'c',\n",
       " 'n': 'o',\n",
       " 'o': 'h',\n",
       " 'p': 'l',\n",
       " 'q': 's',\n",
       " 'r': 'i',\n",
       " 's': 'p',\n",
       " 't': 'r',\n",
       " 'u': 'b',\n",
       " 'v': 'e',\n",
       " 'w': 'f',\n",
       " 'x': 'j',\n",
       " 'y': ' ',\n",
       " 'z': 'z'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_key_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bc61f286",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [[('t', 0.9378145933151245), ('q', 0.00016141246305778623)]]\n",
      "a [[('y', 0.8689349889755249), ('h', 0.5109328627586365)]]\n",
      "b [[('e', 0.973141610622406), ('u', 0.9477119445800781)]]\n",
      "c [[('m', 0.978762149810791), ('u', 0.011534040793776512)]]\n",
      "d [[('g', 0.7696906924247742), ('a', 0.3600529134273529)]]\n",
      "e [[('q', 0.9340885877609253), ('p', 0.34357988834381104)]]\n",
      "f [[('s', 0.750238299369812), ('f', 0.7495081424713135)]]\n",
      "g [[(' ', 0.9279904961585999), ('a', 0.7020502090454102)]]\n",
      "h [[('v', 0.9490692615509033), ('e', 0.9476191401481628)]]\n",
      "i [[('h', 0.9274654984474182), ('y', 0.9260985255241394)]]\n",
      "j [[(' ', 0), ('a', 0)]]\n",
      "k [[('j', 0.9447077512741089), ('x', 0.8385509848594666)]]\n",
      "l [[('a', 0.9921000599861145), ('o', 0.9888262748718262)]]\n",
      "m [[('c', 0.792305588722229), ('x', 0.7656188011169434)]]\n",
      "n [[('o', 0.9139175415039062), ('a', 0.9096418619155884)]]\n",
      "o [[('h', 0.9707360863685608), ('k', 0.9190825819969177)]]\n",
      "p [[('l', 0.9908012747764587), ('b', 0.8771774172782898)]]\n",
      "q [[(' ', 0), ('a', 0)]]\n",
      "r [[('i', 0.9969356060028076), ('q', 0.03268730267882347)]]\n",
      "s [[('p', 0.937562108039856), ('q', 0.9211217761039734)]]\n",
      "t [[('r', 0.6968714594841003), ('y', 0.3673337399959564)]]\n",
      "u [[('b', 0.9963111281394958), ('e', 0.022464705631136894)]]\n",
      "v [[('v', 0.9564570784568787), ('j', 0.8340981006622314)]]\n",
      "w [[('v', 0.8878428936004639), ('j', 0.8451440930366516)]]\n",
      "x [[(' ', 0), ('a', 0)]]\n",
      "y [[(' ', 0.938879132270813), ('a', 0.14388330280780792)]]\n",
      "z [[('s', 0.7701017260551453), ('x', 0.42777112126350403)]]\n"
     ]
    }
   ],
   "source": [
    "for c_p,probs in score_chart.items():\n",
    "    probs = list(probs.items())\n",
    "    probs.sort(key = lambda a:-a[1])\n",
    "    print(c_p,[probs[:2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2697d82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = [set(c.split()[0]) for c in TEST_PLAIN_TEXTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb2d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_idx,cipher,char_key_mapping iter_tests(0.5,1000):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b39bfc9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('t', 0.9378145933151245), ('q', 0.00016141246305778623)]\n",
      "t\n",
      "[('y', 0.8689349889755249), ('h', 0.5109328627586365)]\n",
      "y\n",
      "[('e', 0.973141610622406), ('u', 0.9477119445800781)]\n",
      "u\n",
      "[('m', 0.978762149810791), ('u', 0.011534040793776512)]\n",
      "m\n",
      "[('g', 0.7696906924247742), ('a', 0.3600529134273529)]\n",
      "g\n",
      "[('q', 0.9340885877609253), ('p', 0.34357988834381104)]\n",
      "q\n",
      "[('s', 0.750238299369812), ('f', 0.7495081424713135)]\n",
      "w\n",
      "[(' ', 0.9279904961585999), ('a', 0.7020502090454102)]\n",
      "a\n",
      "[('v', 0.9490692615509033), ('e', 0.9476191401481628)]\n",
      "v\n",
      "[('h', 0.9274654984474182), ('y', 0.9260985255241394)]\n",
      "k\n",
      "[(' ', 0), ('a', 0)]\n",
      "n\n",
      "[('j', 0.9447077512741089), ('x', 0.8385509848594666)]\n",
      "x\n",
      "[('a', 0.9921000599861145), ('o', 0.9888262748718262)]\n",
      "d\n",
      "[('c', 0.792305588722229), ('x', 0.7656188011169434)]\n",
      "c\n",
      "[('o', 0.9139175415039062), ('a', 0.9096418619155884)]\n",
      "o\n",
      "[('h', 0.9707360863685608), ('k', 0.9190825819969177)]\n",
      "h\n",
      "[('l', 0.9908012747764587), ('b', 0.8771774172782898)]\n",
      "l\n",
      "[(' ', 0), ('a', 0)]\n",
      "s\n",
      "[('i', 0.9969356060028076), ('q', 0.03268730267882347)]\n",
      "i\n",
      "[('p', 0.937562108039856), ('q', 0.9211217761039734)]\n",
      "p\n",
      "[('r', 0.6968714594841003), ('y', 0.3673337399959564)]\n",
      "r\n",
      "[('b', 0.9963111281394958), ('e', 0.022464705631136894)]\n",
      "b\n",
      "[('v', 0.9564570784568787), ('j', 0.8340981006622314)]\n",
      "e\n",
      "[('v', 0.8878428936004639), ('j', 0.8451440930366516)]\n",
      "f\n",
      "[(' ', 0), ('a', 0)]\n",
      "j\n",
      "[(' ', 0.938879132270813), ('a', 0.14388330280780792)]\n",
      " \n",
      "[('s', 0.7701017260551453), ('x', 0.42777112126350403)]\n",
      "z\n"
     ]
    }
   ],
   "source": [
    "my_set = set()\n",
    "for c_p,probs in score_chart.items():\n",
    "    probs = list(probs.items())\n",
    "    probs.sort(key = lambda a:-a[1])\n",
    "    print(probs[:2])\n",
    "    print(char_key_mapping[c_p])\n",
    "    for i in range(2):\n",
    "        if probs[i][0] == char_key_mapping[c_p]:\n",
    "            my_set.add(c_p)\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b880060e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "aac2b37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sets[r_idx].difference(my_set)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f58581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
