{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "716abb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import random\n",
    "import bisect\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "sys.path.insert(0,'../decryption')\n",
    "sys.path.insert(0,'../encryption')\n",
    "sys.path.insert(0,'../dictionaries')\n",
    "\n",
    "import encrypt\n",
    "import decrypt\n",
    "import alphabet\n",
    "import frequency\n",
    "\n",
    "_ALPHABET = \" abcdefghijklmnopqrstuvwxyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "f2c55b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7f5d1b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation of problem\n",
    "TEST_KEY_MAPPING = encrypt.generate_key_mapping()\n",
    "TEST_CHAR_MAPPING = encrypt.char_key_mapping_from_key_mapping(TEST_KEY_MAPPING)\n",
    "\n",
    "assert len(set(TEST_KEY_MAPPING)) == 27\n",
    "\n",
    "TEST_PLAIN_TEXTS = []\n",
    "with open('../dictionaries/official_dictionary_1_cleaned.txt','r') as f:\n",
    "    content = f.readlines()\n",
    "    for line in content:\n",
    "        TEST_PLAIN_TEXTS.append(line.strip())\n",
    "\n",
    "TEST_PROBABILITY = 0.1\n",
    "ciphers = [encrypt.encrypt(msg,TEST_KEY_MAPPING,TEST_PROBABILITY) for msg in TEST_PLAIN_TEXTS]\n",
    "\n",
    "# pick a random cipher and start working with it. (We should not know the original plain text)\n",
    "r = random.randint(0,len(ciphers)-1)\n",
    "cipher_txt = ciphers[r]\n",
    "test_plain_text = TEST_PLAIN_TEXTS[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6937c61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'klgh yfeolxvffhyjyjeobvsmui yobveaeiipvyoxyzbts dyjeoltjdek vi eclolvjvpymov cxfbidieyefvamiexqy  fvjtiv ieqoegmmvaasaeobdsjmyqdoxv hdtheolmgt iloqssjqsjoyjeocvdqijvamyoesadivmylfeomtlwcvkreoys rbvfy fvamyoxcvzhhi ho yhtfyivfydoiqbyhjet vfyeoqvqqft eolxsqqih yeeocepyqiobi  dyjoltqbjieydoqv vgmhyjexibolt seofsj ydo yfxyjmv deofyqbtjvjjiy yeeomv hosiexyjeovyjvfyoevdiefteolxyqiefjgoqihjvi yonj tlhhziyefoqets di hojjv bidmgoxoexympi hoqvd mih i hoexjiywonwvyjiyeoqliethg iefolmvjifiayteotpyjeifhxfodtgvjemiyeojynqtdymyjofvsjsejyeopbjteefjvfydonjashhi hgqoltqyefiamy'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cipher_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8218b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rel_dist(text):\n",
    "    rel_dist = defaultdict(list)\n",
    "    rel_num = defaultdict(list)\n",
    "    for j,c in enumerate(text):\n",
    "        rel_dist[c].append((j/len(text)))\n",
    "        rel_num[c].append(j)\n",
    "    return rel_dist,rel_num\n",
    "\n",
    "def get_diff(arr):\n",
    "    diff = []\n",
    "    for i in range(1,len(arr)):\n",
    "        diff.append(round(arr[i]-arr[i-1],4))\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "54ed46d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_dist_all = [build_rel_dist(text) for text in TEST_PLAIN_TEXTS]\n",
    "rel_dists = [a[0] for a in rel_dist_all]\n",
    "rel_nums = [a[1] for a in rel_dist_all]\n",
    "\n",
    "rel_dist_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_dists]\n",
    "rel_num_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_nums]\n",
    "\n",
    "c_rel_dist,c_rel_num = build_rel_dist(cipher_txt)\n",
    "\n",
    "c_rel_dist_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_dist.items()})\n",
    "c_rel_num_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_num.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "412c09b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b 0.9076168929110106 0.9595404595404595 [75, 98, 100, 142, 148, 176, 496]\n"
     ]
    }
   ],
   "source": [
    "target = 'a'\n",
    "p_vals = []\n",
    "\n",
    "c_rel_diff = c_rel_dist_diff[target]\n",
    "c_rel = c_rel_dist[target]\n",
    "for c in _ALPHABET:\n",
    "    rel_diff = rel_dist_diffs[r][c]\n",
    "    rel = rel_dists[r][c]\n",
    "    if len(rel) == 0 or len(rel_diff) == 0:\n",
    "        continue\n",
    "    if len(rel)>len(c_rel):\n",
    "        continue\n",
    "    p_val = stats.ks_2samp(rel,c_rel)[1]\n",
    "    p_val_diff = stats.ks_2samp(rel_diff,c_rel_diff)[1]\n",
    "    if p_val>0.9:\n",
    "        print(c,p_val,p_val_diff,rel_nums[r][c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "11a1ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy: First declare eliminations \n",
    "# Then Declare hyperparameters as thresholds. For different values of extra characters, calculate the best\n",
    "# value of these hyperparameters by running through the solution\n",
    "\n",
    "# elimination 1: length of rel should be lesser\n",
    "# elimination 2: top r (hyper param mapped to diff) values of p_vals\n",
    "# elimination 3: check difference in first character of rel num. it should be less than k (2nd hyper-parameter OR ML input)\n",
    "# elimination 4: for each term in first and last m (3rd hyperparam) rel dist elements, \n",
    "# find closest term and add difference of square from it to total score. Choose letter with lowest such score\n",
    "#       OR\n",
    "# Do this for first m terms in rel nums\n",
    "#       OR\n",
    "# Calculate some group stats and run a classification ML model. These features can include:\n",
    "# diff, 1st, 2nd, 3rd ... kth moment of steps of both distributions (k is a hyperparameter)\n",
    "\n",
    "# In the end, calculate average p value of each guess and output the maximum\n",
    "# OR calculate score as p value * size in rel num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ee785892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_tests(p,num):\n",
    "    \"\"\"\n",
    "    iterate over num tests for prob p\n",
    "    \"\"\"\n",
    "    for _ in range(num):\n",
    "        num_key_mapping = encrypt.generate_key_mapping()\n",
    "        char_key_mapping = encrypt.char_key_mapping_from_key_mapping(num_key_mapping)\n",
    "\n",
    "        r = random.randint(0,len(ciphers)-1)\n",
    "        cipher = encrypt.encrypt(TEST_PLAIN_TEXTS[r],num_key_mapping,p)\n",
    "\n",
    "        yield r,cipher,char_key_mapping\n",
    "\n",
    "def append(data,df):\n",
    "    l = len(df)\n",
    "    for k,v in data.items():\n",
    "        df.loc[l,k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "0298cade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 'd',\n",
       " 'a': 'm',\n",
       " 'b': ' ',\n",
       " 'c': 'z',\n",
       " 'd': 't',\n",
       " 'e': 'e',\n",
       " 'f': 'x',\n",
       " 'g': 'b',\n",
       " 'h': 'y',\n",
       " 'i': 'v',\n",
       " 'j': 'f',\n",
       " 'k': 'n',\n",
       " 'l': 'j',\n",
       " 'm': 'w',\n",
       " 'n': 'k',\n",
       " 'o': 'r',\n",
       " 'p': 'a',\n",
       " 'q': 'l',\n",
       " 'r': 'u',\n",
       " 's': 'c',\n",
       " 't': 'q',\n",
       " 'u': 'o',\n",
       " 'v': 'h',\n",
       " 'w': 'p',\n",
       " 'x': 's',\n",
       " 'y': 'i',\n",
       " 'z': 'g'}"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_key_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "d5864c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(arr,target,lo=0,hi=10000):\n",
    "    hi = min(hi,len(arr))\n",
    "    res = bisect.bisect_left(arr,target,lo,hi)\n",
    "    if res != len(arr) and arr[res] == target:\n",
    "        return res\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "ff1faf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_space_diffs_left(space_rel_num,rel_num):\n",
    "    ret = []\n",
    "    for i,num in enumerate(rel_num):\n",
    "        space_closest = bisect.bisect_left(space_rel_num,num) - 1\n",
    "\n",
    "        if space_closest == -1:\n",
    "            ret.append(num)\n",
    "            continue\n",
    "        ret.append(num - space_rel_num[space_closest])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "0217c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_diffs_data(space_rel_num,rel_num,l):\n",
    "    left = []\n",
    "    right = []\n",
    "    avg_num_diff = []\n",
    "    for i,num in enumerate(rel_num):\n",
    "        space_closest_right = bisect.bisect_left(space_rel_num,num)\n",
    "        space_closest_left = space_closest_right-1\n",
    "        if space_closest_left == -1:\n",
    "            lo = 0\n",
    "        else:\n",
    "            lo = space_rel_num[space_closest_left]\n",
    "        if space_closest_right == len(space_rel_num):\n",
    "            hi = l\n",
    "        else:\n",
    "            hi = space_rel_num[space_closest_right]\n",
    "        left.append(num-lo)\n",
    "        right.append(hi-num)\n",
    "        avg_num_diff.append(right[-1] - left[-1])\n",
    "        \n",
    "    return left,right,avg_num_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "f26c98ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_idx,cipher,char_key_mapping = next(iter_tests(0.4,1))\n",
    "c_rel_dist,c_rel_num = build_rel_dist(cipher)\n",
    "diff = len(cipher)-len(TEST_PLAIN_TEXTS[r_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "55a8673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'c'\n",
    "rel_num = rel_nums[r_idx][target]\n",
    "space_rel_num = rel_nums[r_idx][' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "afea6642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "space_left_p = get_space_diffs_left(rel_nums[r_idx][' '],rel_nums[r_idx][target])\n",
    "space_char = decrypt.get_space_key_value(cipher)\n",
    "space_left_c = get_space_diffs_left(c_rel_num[space_char],c_rel_num[char_key_mapping[target]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "68f33c90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.434\n",
      "11.225\n",
      "9.348\n",
      "7.589\n",
      "9.186\n",
      "8.145\n",
      "11.224\n",
      "8.367\n",
      "9.123\n",
      "7.47\n",
      "10.578\n",
      "8.24\n",
      "12.392\n",
      "8.866\n",
      "8.076\n",
      "8.582\n",
      "8.254\n",
      "5.875\n",
      "9.384\n",
      "7.477\n",
      "11.459\n",
      "9.053\n",
      "10.564\n",
      "11.474\n",
      "7.535\n",
      "6.88\n",
      "9.639\n",
      "7.933\n",
      "11.002\n",
      "7.462\n",
      "9.187\n",
      "7.389\n",
      "10.183\n",
      "7.746\n",
      "nan\n",
      "nan\n",
      "10.119\n",
      "9.043\n",
      "9.156\n",
      "8.431\n",
      "9.239\n",
      "7.522\n",
      "11.592\n",
      "9.291\n",
      "8.631\n",
      "9.03\n",
      "13.601\n",
      "8.657\n",
      "7.545\n",
      "10.455\n",
      "9.306\n",
      "7.998\n",
      "6.12\n",
      "8.119\n"
     ]
    }
   ],
   "source": [
    "for target in _ALPHABET:\n",
    "    rel_num = rel_nums[r_idx][target]\n",
    "    space_rel_num = rel_nums[r_idx][' ']\n",
    "    space_left_p,space_right_p,space_avg_p = get_char_diffs_data(rel_nums[r_idx][' '],rel_nums[r_idx][target],len(TEST_PLAIN_TEXTS[r_idx]))\n",
    "    space_char = decrypt.get_space_key_value(cipher)\n",
    "    space_left_c,space_right_c,space_avg_c = get_char_diffs_data(c_rel_num[space_char],c_rel_num[char_key_mapping[target]],len(cipher))\n",
    "    \n",
    "    print(round(np.mean(space_left_c) - np.mean(space_left_p),3))\n",
    "    print(round(np.std(space_left_c) - np.std(space_left_p),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "8cc45c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff,space_data_c,space_data_p):\n",
    "    data = dict()\n",
    "    \n",
    "    data['l_c_dist'] = len(c_dist)\n",
    "    data['l_dist'] = len(dist)\n",
    "    \n",
    "    space_left_c,space_right_c,space_avg_c = space_data_c\n",
    "    space_left_p,space_right_p,space_avg_p = space_data_p\n",
    "    \n",
    "    if space_left_c:\n",
    "        data['space_left_c_mean'] = np.mean(space_left_c)\n",
    "        data['space_left_c_std'] = np.std(space_left_c)\n",
    "        \n",
    "    if space_right_c:\n",
    "        data['space_right_c_mean'] = np.mean(space_right_c)\n",
    "        data['space_right_c_std'] = np.std(space_right_c)\n",
    "        \n",
    "    if space_avg_c:\n",
    "        data['space_diff_c_mean'] = np.mean(space_avg_c)\n",
    "        data['space_diff_c_std'] = np.std(space_avg_c)\n",
    "    \n",
    "    if space_left_p:\n",
    "        data['space_left_p_mean'] = np.mean(space_left_p)\n",
    "        data['space_left_p_std'] = np.std(space_left_p)\n",
    "        \n",
    "    if space_right_p:\n",
    "        data['space_right_p_mean'] = np.mean(space_right_p)\n",
    "        data['space_right_p_std'] = np.std(space_right_p)\n",
    "        \n",
    "    if space_avg_c:\n",
    "        data['space_diff_p_mean'] = np.mean(space_avg_p)\n",
    "        data['space_diff_p_std'] = np.std(space_avg_p)\n",
    "    \n",
    "    # get 2,3 moment of num\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_num_moment'] = stats.moment(num,i)\n",
    "        data[str(i)+'_c_num_moment'] = stats.moment(c_num,i)\n",
    "\n",
    "    # get 2,3 moment of diff\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_diff_moment'] = stats.moment(diff,i)\n",
    "        data[str(i)+'_c_diff_moment'] = stats.moment(c_diff,i)\n",
    "\n",
    "    # get 2,3 moment of dist\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_dist_moment'] = stats.moment(dist,i)\n",
    "        data[str(i)+'_c_dist_moment'] = stats.moment(c_dist,i)\n",
    "\n",
    "    # get 2 moment of dist_diff\n",
    "    max_moments = 2\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_dist_diff_moment'] = stats.moment(dist_diff,i)\n",
    "        data[str(i)+'_c_dist_diff_moment'] = stats.moment(c_dist_diff,i)\n",
    "\n",
    "    # get 3 moment of dist_diff*1000\n",
    "    data[str(3)+'_dist_diff_moment'] = stats.moment(dist_diff,3) * 1000\n",
    "    data[str(3)+'_c_dist_diff_moment'] = stats.moment(c_dist_diff,3) * 1000\n",
    "\n",
    "    # dependant stats\n",
    "    if num and c_num:\n",
    "        data['num_p_ks'] = stats.ks_2samp(num,c_num)[1]\n",
    "    if dist and c_dist:\n",
    "        data['dist_p_ks'] = stats.ks_2samp(dist,c_dist)[1]\n",
    "    if diff and c_diff:\n",
    "        data['diff_p_ks'] = stats.ks_2samp(diff,c_diff)[1]\n",
    "    if dist_diff and c_dist_diff:\n",
    "        data['dist_diff_p_ks'] = stats.ks_2samp(dist_diff,c_dist_diff)[1]\n",
    "\n",
    "    # covariance of first k samples\n",
    "    k = 5\n",
    "    l = min(k,len(num),len(c_num))\n",
    "    if l>0:\n",
    "        data['num_first_cov'] = np.cov(num[:l],c_num[:l])[0][1]\n",
    "        data['num_last_cov'] = np.cov(num[-l:],c_num[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(dist),len(c_dist))\n",
    "    if l>0:\n",
    "        data['dist_first_cov'] = np.cov(dist[:l],c_dist[:l])[0][1]\n",
    "        data['dist_last_cov'] = np.cov(dist[-l:],c_dist[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(diff),len(c_diff))\n",
    "    if l>0:\n",
    "        data['diff_first_cov'] = np.cov(diff[:l],c_diff[:l])[0][1]\n",
    "        data['diff_last_cov'] = np.cov(diff[-l:],c_diff[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(dist_diff),len(c_dist_diff))\n",
    "    if l>0:\n",
    "        data['dist_diff_first_cov'] = np.cov(dist_diff[:l],c_dist_diff[:l])[0][1]\n",
    "        data['dist_diff_last_cov'] = np.cov(dist_diff[-l:],c_dist_diff[-l:])[0][1]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "55e08dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_negative(r,c_rel,rel_dists,n=4):\n",
    "    \"\"\"\n",
    "    choose those characters which we know are hard to predict\n",
    "    \"\"\"\n",
    "    p_vals = []\n",
    "    for c_p in _ALPHABET:\n",
    "        rel = rel_dists[r][c_p]\n",
    "        if len(rel) == 0:\n",
    "            continue\n",
    "        if len(rel)>len(c_rel):\n",
    "            continue\n",
    "        p_val = stats.ks_2samp(rel,c_rel)[1]\n",
    "        p_vals.append((p_val,c_p))\n",
    "    p_vals.sort(key = lambda a: -a[0])\n",
    "    return [a[1] for a in p_vals[:n]]\n",
    "\n",
    "def next_choice(closest_p_vals,chosen):\n",
    "    for char in closest_p_vals:\n",
    "        if char not in chosen:\n",
    "            return char\n",
    "    return random.choice(_ALPHABET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "69b84bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_prob_tests(pmin,pmax,step,num):\n",
    "    for prob in range(pmin,pmax+1,step):\n",
    "        print('generating for prob',prob)\n",
    "        for r_idx,cipher,char_key_mapping in iter_tests(prob/100,num):\n",
    "            yield r_idx,cipher,char_key_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "9e862055",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating for prob 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityachawla/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/adityachawla/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/adityachawla/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/adityachawla/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "/Users/adityachawla/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/var/folders/1x/qc9ydz9s4vd2vjjqzx68nt0m0000gn/T/ipykernel_23504/4293227705.py:76: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  data['num_first_cov'] = np.cov(num[:l],c_num[:l])[0][1]\n",
      "/Users/adityachawla/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/function_base.py:2480: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/Users/adityachawla/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/function_base.py:2480: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "/var/folders/1x/qc9ydz9s4vd2vjjqzx68nt0m0000gn/T/ipykernel_23504/4293227705.py:77: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  data['num_last_cov'] = np.cov(num[-l:],c_num[-l:])[0][1]\n",
      "/var/folders/1x/qc9ydz9s4vd2vjjqzx68nt0m0000gn/T/ipykernel_23504/4293227705.py:81: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  data['dist_first_cov'] = np.cov(dist[:l],c_dist[:l])[0][1]\n",
      "/var/folders/1x/qc9ydz9s4vd2vjjqzx68nt0m0000gn/T/ipykernel_23504/4293227705.py:82: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  data['dist_last_cov'] = np.cov(dist[-l:],c_dist[-l:])[0][1]\n",
      "/var/folders/1x/qc9ydz9s4vd2vjjqzx68nt0m0000gn/T/ipykernel_23504/4293227705.py:86: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  data['diff_first_cov'] = np.cov(diff[:l],c_diff[:l])[0][1]\n",
      "/var/folders/1x/qc9ydz9s4vd2vjjqzx68nt0m0000gn/T/ipykernel_23504/4293227705.py:87: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  data['diff_last_cov'] = np.cov(diff[-l:],c_diff[-l:])[0][1]\n",
      "/var/folders/1x/qc9ydz9s4vd2vjjqzx68nt0m0000gn/T/ipykernel_23504/4293227705.py:91: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  data['dist_diff_first_cov'] = np.cov(dist_diff[:l],c_dist_diff[:l])[0][1]\n",
      "/var/folders/1x/qc9ydz9s4vd2vjjqzx68nt0m0000gn/T/ipykernel_23504/4293227705.py:92: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  data['dist_diff_last_cov'] = np.cov(dist_diff[-l:],c_dist_diff[-l:])[0][1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "generating for prob 7\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "generating for prob 9\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "generating for prob 11\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "generating for prob 13\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "generating for prob 15\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "generating for prob 17\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "generating for prob 19\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "generating for prob 21\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "generating for prob 23\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "generating for prob 25\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "generating for prob 27\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "generating for prob 29\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "generating for prob 31\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "generating for prob 33\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "generating for prob 35\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "generating for prob 37\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "generating for prob 39\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "generating for prob 41\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "generating for prob 43\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "generating for prob 45\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "generating for prob 47\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "generating for prob 49\n",
      "1990\n",
      "2000\n",
      "2010\n",
      "2020\n",
      "2030\n",
      "2040\n",
      "2050\n",
      "2060\n",
      "2070\n",
      "2080\n",
      "2090\n",
      "2100\n",
      "2110\n",
      "2120\n",
      "2130\n",
      "2140\n",
      "2150\n",
      "2160\n",
      "generating for prob 53\n",
      "2170\n",
      "2180\n",
      "2190\n",
      "2200\n",
      "2210\n",
      "2220\n",
      "2230\n",
      "2240\n",
      "2250\n",
      "generating for prob 55\n",
      "2260\n",
      "2270\n",
      "2280\n",
      "2290\n",
      "2300\n",
      "2310\n",
      "2320\n",
      "2330\n",
      "2340\n",
      "generating for prob 57\n",
      "2350\n",
      "2360\n",
      "2370\n",
      "2380\n",
      "2390\n",
      "2400\n",
      "2410\n",
      "2420\n",
      "2430\n",
      "generating for prob 59\n",
      "2440\n",
      "2450\n",
      "2460\n",
      "2470\n",
      "2480\n",
      "2490\n",
      "2500\n",
      "2510\n",
      "2520\n",
      "generating for prob 61\n",
      "2530\n",
      "2540\n",
      "2550\n",
      "2560\n",
      "2570\n",
      "2580\n",
      "2590\n",
      "2600\n",
      "2610\n",
      "generating for prob 63\n",
      "2620\n",
      "2630\n",
      "2640\n",
      "2650\n",
      "2660\n",
      "2670\n",
      "2680\n",
      "2690\n",
      "2700\n",
      "generating for prob 65\n",
      "2710\n",
      "2720\n",
      "2730\n",
      "2740\n",
      "2750\n",
      "2760\n",
      "2770\n",
      "2780\n",
      "2790\n",
      "generating for prob 67\n",
      "2800\n",
      "2810\n",
      "2820\n",
      "2830\n",
      "2840\n",
      "2850\n",
      "2860\n",
      "2870\n",
      "2880\n",
      "generating for prob 69\n",
      "2890\n",
      "2900\n",
      "2910\n",
      "2920\n",
      "2930\n",
      "2940\n",
      "2950\n",
      "2960\n",
      "2970\n",
      "generating for prob 71\n",
      "2980\n",
      "2990\n",
      "3000\n",
      "3010\n",
      "3020\n",
      "3030\n",
      "3040\n",
      "3050\n",
      "3060\n",
      "generating for prob 73\n",
      "3070\n",
      "3080\n",
      "3090\n",
      "3100\n",
      "3110\n",
      "3120\n",
      "3130\n",
      "3140\n",
      "3150\n",
      "generating for prob 75\n",
      "3160\n",
      "3170\n",
      "3180\n",
      "3190\n",
      "3200\n",
      "3210\n",
      "3220\n",
      "3230\n",
      "3240\n"
     ]
    }
   ],
   "source": [
    "# create dataset\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# get distributions for plaintexts\n",
    "rel_dist_all = [build_rel_dist(text) for text in TEST_PLAIN_TEXTS]\n",
    "rel_dists = [a[0] for a in rel_dist_all]\n",
    "rel_nums = [a[1] for a in rel_dist_all]\n",
    "\n",
    "rel_dist_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_dists]\n",
    "rel_num_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_nums]\n",
    "\n",
    "# space_left_ps = []\n",
    "# for i,txt in enumerate(TEST_PLAIN_TEXTS):\n",
    "#     space_left_ps.append(\n",
    "#         defaultdict(list,{c:get_space_diffs_left(rel_nums[i][' '],rel_nums[i][c]) for c in _ALPHABET})\n",
    "#     )\n",
    "space_data_ps = []\n",
    "for i,txt in enumerate(TEST_PLAIN_TEXTS):\n",
    "    space_data_ps.append(\n",
    "        defaultdict(list,{c:get_char_diffs_data(rel_nums[i][' '],rel_nums[i][c],len(txt)) for c in _ALPHABET})\n",
    "    )\n",
    "    \n",
    "num_itr = 0\n",
    "for r_idx,cipher,char_key_mapping in iter_prob_tests(5,75,2,90):\n",
    "    # track progress\n",
    "    num_itr += 1\n",
    "    if num_itr % 10 == 0:\n",
    "        print(num_itr)\n",
    "    \n",
    "    rev_mapping = {v:k for k,v in char_key_mapping.items()}\n",
    "    \n",
    "    char_diff = len(cipher) - len(TEST_PLAIN_TEXTS[r_idx])\n",
    "    \n",
    "    # get distributions for cipher\n",
    "    c_rel_dist,c_rel_num = build_rel_dist(cipher)\n",
    "    c_rel_num_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_num.items()})\n",
    "    c_rel_dist_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_dist.items()})\n",
    "    space_char = decrypt.get_space_key_value(cipher)\n",
    "#     space_left_c = defaultdict(list,{c:get_space_diffs_left(c_rel_num[space_char],c_rel_num[c]) for c in _ALPHABET})\n",
    "    space_data_c = defaultdict(list,{c:get_char_diffs_data(c_rel_num[space_char],c_rel_num[c],len(cipher)) for c in _ALPHABET})\n",
    "    \n",
    "    for c_c in _ALPHABET:\n",
    "        c_p = rev_mapping[c_c]\n",
    "        \n",
    "        num = rel_nums[r_idx][c_p]\n",
    "        c_num = c_rel_num[c_c]\n",
    "        \n",
    "        dist = rel_dists[r_idx][c_p]\n",
    "        c_dist = c_rel_dist[c_c]\n",
    "        \n",
    "        diff = rel_num_diffs[r_idx][c_p]\n",
    "        c_diff = c_rel_num_diff[c_c]\n",
    "        \n",
    "        dist_diff = rel_dist_diffs[r_idx][c_p]\n",
    "        c_dist_diff = c_rel_dist_diff[c_c]\n",
    "        \n",
    "        data = get_data(num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff,space_data_c[c_c],space_data_ps[r_idx][c_p])\n",
    "        data['char_diff'] = char_diff\n",
    "        data['output'] = 1\n",
    "        append(data,df)\n",
    "        \n",
    "        best_negative = get_best_negative(r_idx,c_dist,rel_dists,3)\n",
    "        \n",
    "        chosen = set([c_p])\n",
    "        while len(chosen)<4:\n",
    "            c_p = next_choice(best_negative,chosen)\n",
    "            chosen.add(c_p)\n",
    "            \n",
    "            num = rel_nums[r_idx][c_p]\n",
    "            dist = rel_dists[r_idx][c_p]\n",
    "            diff = rel_num_diffs[r_idx][c_p]\n",
    "            dist_diff = rel_dist_diffs[r_idx][c_p]\n",
    "            \n",
    "            data = get_data(num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff,space_data_c[c_c],space_data_ps[r_idx][c_p])\n",
    "            data['char_diff'] = char_diff\n",
    "            data['output'] = 0\n",
    "            append(data,df)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "9c1f5953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_mapping['z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "2cdb39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "7788d2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356451"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7988ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('dataset_two.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "64f0d15f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_idx = list(df.columns).index('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "6ae7124a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_cols = list(df.columns)\n",
    "input_cols.remove('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "7ef41fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:,input_cols].values\n",
    "y = df.iloc[:,output_idx].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "b1126d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "num_feat = X_train_raw.shape[1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = torch.from_numpy(scaler.transform(X_train_raw)).float()\n",
    "X_test = torch.from_numpy(scaler.transform(X_test_raw)).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_test = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "39ffb746",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train,y_train) # create your datset\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=16,shuffle=True) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "a2b36211",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(X_test,y_test) # create your datset\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=16,shuffle=True) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "f9401669",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module): \n",
    "    def __init__(self):\n",
    "        super(NeuralNet,self).__init__()\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(num_feat, 128)\n",
    "        \n",
    "        self.lin2 =torch.nn.Linear(128, 64)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.lin3 =torch.nn.Linear(64, 32)\n",
    "        \n",
    "        self.lin4 =torch.nn.Linear(32, 1)\n",
    "        \n",
    "        self.out = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.float()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.lin2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.lin3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.lin4(x)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "net = NeuralNet()\n",
    "loss = torch.nn.BCELoss() # pass output, target\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "4f890ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history = []\n",
    "test_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "904ea11f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train loss 0.27324655167077666, Test loss 0.23662942683269597\n",
      "Epoch 1, Train loss 0.23575558007962621, Test loss 0.22592540300380995\n",
      "Epoch 2, Train loss 0.22520814417679558, Test loss 0.2163015769475225\n",
      "Epoch 3, Train loss 0.21848677755348414, Test loss 0.21541022728324072\n",
      "Epoch 4, Train loss 0.21383400293722218, Test loss 0.20897389146251874\n",
      "Epoch 5, Train loss 0.21065328463176866, Test loss 0.20707749501256667\n",
      "Epoch 6, Train loss 0.20755516588968578, Test loss 0.20368360035737446\n",
      "Epoch 7, Train loss 0.20494327687884706, Test loss 0.20197302508691825\n",
      "Epoch 8, Train loss 0.20225811900214763, Test loss 0.20098190353684492\n",
      "Epoch 9, Train loss 0.20032123786977452, Test loss 0.20021004512719923\n",
      "Epoch 10, Train loss 0.19864941778900022, Test loss 0.19911404642307678\n",
      "Epoch 11, Train loss 0.19745597411654758, Test loss 0.1980439541092419\n",
      "Epoch 12, Train loss 0.1965578333774636, Test loss 0.19948997546233574\n",
      "Epoch 13, Train loss 0.19512378510086087, Test loss 0.19655902160970185\n",
      "Epoch 14, Train loss 0.19428525485582684, Test loss 0.19651606765164736\n",
      "Epoch 15, Train loss 0.1929099703323057, Test loss 0.19717246924280643\n",
      "Epoch 16, Train loss 0.1919386876016272, Test loss 0.19606632341967672\n",
      "Epoch 17, Train loss 0.19083869465860875, Test loss 0.19611989834316895\n",
      "Epoch 18, Train loss 0.18984859900723883, Test loss 0.19450976811909523\n",
      "Epoch 19, Train loss 0.1892967996388165, Test loss 0.19284757494906668\n",
      "Epoch 20, Train loss 0.18858269664391877, Test loss 0.1914429156105371\n",
      "Epoch 21, Train loss 0.18762583330128213, Test loss 0.19460553665105354\n",
      "Epoch 22, Train loss 0.18714467521227476, Test loss 0.19333597852913678\n",
      "Epoch 23, Train loss 0.18631842218879305, Test loss 0.19386585512291984\n",
      "Epoch 24, Train loss 0.18560532263449372, Test loss 0.19484794214074216\n",
      "Epoch 25, Train loss 0.18524391501667184, Test loss 0.19315601424973142\n",
      "Epoch 26, Train loss 0.18481997536489655, Test loss 0.19111419373986388\n",
      "Epoch 27, Train loss 0.18337009902996854, Test loss 0.19429039625170347\n",
      "Epoch 28, Train loss 0.1839394632131954, Test loss 0.19068496173978094\n",
      "Epoch 29, Train loss 0.18269931415895269, Test loss 0.19338208406339866\n",
      "Epoch 30, Train loss 0.18202150623221816, Test loss 0.19106964311210795\n",
      "Epoch 31, Train loss 0.1818636575781535, Test loss 0.1905909424042204\n",
      "Epoch 32, Train loss 0.18134168152903118, Test loss 0.19394628870020744\n",
      "Epoch 33, Train loss 0.18102307644830648, Test loss 0.1953625696745937\n",
      "Epoch 34, Train loss 0.1806652035432503, Test loss 0.1940848502731561\n",
      "Epoch 35, Train loss 0.1805020416296619, Test loss 0.18976385153882722\n",
      "Epoch 36, Train loss 0.17936594434945946, Test loss 0.19348260396006078\n",
      "Epoch 37, Train loss 0.1793773709401774, Test loss 0.1929307433607682\n",
      "Epoch 38, Train loss 0.1792552199729328, Test loss 0.1902556913098229\n",
      "Epoch 39, Train loss 0.17875564502984817, Test loss 0.19238561144052518\n",
      "Epoch 40, Train loss 0.17801355917161105, Test loss 0.18882645892463112\n",
      "Epoch 41, Train loss 0.17849666238353362, Test loss 0.19031216524099542\n",
      "Epoch 42, Train loss 0.1778524967981174, Test loss 0.19654317189961823\n",
      "Epoch 43, Train loss 0.1780315826116079, Test loss 0.19160767301043544\n",
      "Epoch 44, Train loss 0.17773469464556899, Test loss 0.19097438974767955\n",
      "Epoch 45, Train loss 0.17779089883650656, Test loss 0.19696296440200967\n",
      "Epoch 46, Train loss 0.1768648336168812, Test loss 0.19173743004176277\n",
      "Epoch 47, Train loss 0.17625924679797436, Test loss 0.19108644992280038\n",
      "Epoch 48, Train loss 0.17634121212674142, Test loss 0.19205935084448464\n",
      "Epoch 49, Train loss 0.17594555472328727, Test loss 0.1936744621624353\n",
      "Epoch 50, Train loss 0.17563280576894388, Test loss 0.1908699875179999\n",
      "Epoch 51, Train loss 0.17576604585893216, Test loss 0.19139687238484182\n",
      "Epoch 52, Train loss 0.1750731593020154, Test loss 0.19595807592261483\n",
      "Epoch 53, Train loss 0.1754400204405345, Test loss 0.19341370015969986\n",
      "Epoch 54, Train loss 0.17433120578412267, Test loss 0.1916606071246827\n",
      "Epoch 55, Train loss 0.17452397472039066, Test loss 0.19085346257680819\n",
      "Epoch 56, Train loss 0.17438319860142862, Test loss 0.19209377539198805\n",
      "Epoch 57, Train loss 0.17399451472974464, Test loss 0.1935530175106888\n",
      "Epoch 58, Train loss 0.17439911032002836, Test loss 0.19473776643848667\n",
      "Epoch 59, Train loss 0.17397123101830003, Test loss 0.19297696601891084\n",
      "Epoch 60, Train loss 0.17410266312626324, Test loss 0.19408105535705517\n",
      "Epoch 61, Train loss 0.17317493498065867, Test loss 0.19135164728095305\n",
      "Epoch 62, Train loss 0.1740295616329166, Test loss 0.1889593168816341\n",
      "Epoch 63, Train loss 0.17330865100076592, Test loss 0.192068214122481\n",
      "Epoch 64, Train loss 0.17246035966517478, Test loss 0.19298169343940047\n",
      "Epoch 65, Train loss 0.1729857983167223, Test loss 0.19018421641904593\n",
      "Epoch 66, Train loss 0.17237087356964592, Test loss 0.1963481501137817\n",
      "Epoch 67, Train loss 0.17361652374953007, Test loss 0.19182584616239948\n",
      "Epoch 68, Train loss 0.1727504401990583, Test loss 0.1944274821671276\n",
      "Epoch 69, Train loss 0.17225277243094417, Test loss 0.19849728269594205\n",
      "Epoch 70, Train loss 0.1724990081971433, Test loss 0.19430854391937274\n",
      "Epoch 71, Train loss 0.17227669050379554, Test loss 0.19163660835285232\n",
      "Epoch 72, Train loss 0.17198988266094997, Test loss 0.19315136635961247\n",
      "Epoch 73, Train loss 0.17234305575851747, Test loss 0.1945611566744348\n",
      "Epoch 74, Train loss 0.17185628468679273, Test loss 0.19663503127376228\n",
      "Epoch 75, Train loss 0.17154205495089975, Test loss 0.19197835908754868\n",
      "Epoch 76, Train loss 0.17201311021969923, Test loss 0.19361415762212664\n",
      "Epoch 77, Train loss 0.1716490032581395, Test loss 0.19466438691696708\n",
      "Epoch 78, Train loss 0.17105308760434337, Test loss 0.19285205152636734\n",
      "Epoch 79, Train loss 0.17137397527327428, Test loss 0.19269887284338943\n",
      "Epoch 80, Train loss 0.17065611802152272, Test loss 0.1953752359291512\n",
      "Epoch 81, Train loss 0.17096400659486716, Test loss 0.19921014295879222\n",
      "Epoch 82, Train loss 0.17115006449813894, Test loss 0.20144034278734974\n",
      "Epoch 83, Train loss 0.1710405521567496, Test loss 0.19190821898196847\n",
      "Epoch 84, Train loss 0.17115938360108873, Test loss 0.19520866947412227\n",
      "Epoch 85, Train loss 0.1710719168128932, Test loss 0.19579235288154423\n",
      "Epoch 86, Train loss 0.17027466890841111, Test loss 0.19203355220944315\n",
      "Epoch 87, Train loss 0.1700103930173843, Test loss 0.19714517248466648\n",
      "Epoch 88, Train loss 0.17044791130979975, Test loss 0.1917839210649327\n",
      "Epoch 89, Train loss 0.16943913120482298, Test loss 0.19077763848892484\n",
      "Epoch 90, Train loss 0.16998511800784635, Test loss 0.1961842993164987\n",
      "Epoch 91, Train loss 0.16987623266121266, Test loss 0.1933123999825157\n",
      "Epoch 92, Train loss 0.16927153308927814, Test loss 0.19567556569032205\n",
      "Epoch 93, Train loss 0.16909648926460066, Test loss 0.1921971670729802\n",
      "Epoch 94, Train loss 0.1690119477971294, Test loss 0.1969837502751406\n",
      "Epoch 95, Train loss 0.16879449230777777, Test loss 0.193403477652053\n",
      "Epoch 96, Train loss 0.16961230397056914, Test loss 0.19819099086625636\n",
      "Epoch 97, Train loss 0.16929497454267387, Test loss 0.19261254775058853\n",
      "Epoch 98, Train loss 0.1693338397440755, Test loss 0.19883316022136044\n",
      "Epoch 99, Train loss 0.1689585572750105, Test loss 0.1986977379769052\n",
      "Epoch 100, Train loss 0.16906165403039825, Test loss 0.19271598833951406\n",
      "Epoch 101, Train loss 0.1686705945603252, Test loss 0.19306760121416713\n",
      "Epoch 102, Train loss 0.16922636258156995, Test loss 0.19292900143156733\n",
      "Epoch 103, Train loss 0.16849910547336508, Test loss 0.19710645464420756\n",
      "Epoch 104, Train loss 0.1689368850749298, Test loss 0.19259032414077137\n",
      "Epoch 105, Train loss 0.16825630339903147, Test loss 0.19654015765287414\n",
      "Epoch 106, Train loss 0.16906010349103542, Test loss 0.1993733864724661\n",
      "Epoch 107, Train loss 0.16871348659599897, Test loss 0.1942026540240605\n",
      "Epoch 108, Train loss 0.1681375176048044, Test loss 0.19283678826256914\n",
      "Epoch 109, Train loss 0.16871434577181457, Test loss 0.19687252677238604\n",
      "Epoch 110, Train loss 0.16796919892920684, Test loss 0.1934037650084008\n",
      "Epoch 111, Train loss 0.1692455741690709, Test loss 0.19444809232828855\n",
      "Epoch 112, Train loss 0.16848916409618714, Test loss 0.19869715035745328\n",
      "Epoch 113, Train loss 0.16857384507958342, Test loss 0.1989688814841955\n",
      "Epoch 114, Train loss 0.16780272726276996, Test loss 0.19336923421721083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115, Train loss 0.16759652269618552, Test loss 0.19514879906515006\n",
      "Epoch 116, Train loss 0.1680032451385242, Test loss 0.19553785775535407\n",
      "Epoch 117, Train loss 0.16820680859827547, Test loss 0.19363873672022588\n",
      "Epoch 118, Train loss 0.1677224909522731, Test loss 0.20149386752418627\n",
      "Epoch 119, Train loss 0.168114479818734, Test loss 0.20035001946805467\n",
      "Epoch 120, Train loss 0.16828032186302522, Test loss 0.19767900886130135\n",
      "Epoch 121, Train loss 0.16782871767183996, Test loss 0.20527476036909198\n",
      "Epoch 122, Train loss 0.16828625075959217, Test loss 0.19257718851693134\n",
      "Epoch 123, Train loss 0.16713273458684882, Test loss 0.19769784799603637\n",
      "Epoch 124, Train loss 0.16745806877905087, Test loss 0.19854997775002836\n",
      "Epoch 125, Train loss 0.1684511951184077, Test loss 0.19605433307519476\n",
      "Epoch 126, Train loss 0.1685898955516168, Test loss 0.19810247548506385\n",
      "Epoch 127, Train loss 0.168491113410248, Test loss 0.19366479598960817\n",
      "Epoch 128, Train loss 0.16708609669650423, Test loss 0.21004691004423862\n",
      "Epoch 129, Train loss 0.16737990166670808, Test loss 0.19615144000476045\n",
      "Epoch 130, Train loss 0.16786266348394363, Test loss 0.1962264319916718\n",
      "Epoch 131, Train loss 0.16754146845213355, Test loss 0.1964211842119785\n",
      "Epoch 132, Train loss 0.16694587969569405, Test loss 0.19697935999825905\n",
      "Epoch 133, Train loss 0.1675590055520313, Test loss 0.20580965100420012\n",
      "Epoch 134, Train loss 0.167207516483232, Test loss 0.19680230729698517\n",
      "Epoch 135, Train loss 0.16772070189457172, Test loss 0.19593820564916412\n",
      "Epoch 136, Train loss 0.16676922172301847, Test loss 0.19730212847034576\n",
      "Epoch 137, Train loss 0.16811214647957987, Test loss 0.19392116422480224\n",
      "Epoch 138, Train loss 0.16726871006289762, Test loss 0.19688043321622833\n",
      "Epoch 139, Train loss 0.16725643604579368, Test loss 0.20716463252500047\n",
      "Epoch 140, Train loss 0.1668799736267094, Test loss 0.20056899313391427\n",
      "Epoch 141, Train loss 0.16870330911780354, Test loss 0.20163335083638076\n",
      "Epoch 142, Train loss 0.16702539629025542, Test loss 0.19190330866774832\n",
      "Epoch 143, Train loss 0.16754177026707426, Test loss 0.19810598086454648\n",
      "Epoch 144, Train loss 0.16756246180985596, Test loss 0.19336700948796284\n",
      "Epoch 145, Train loss 0.16669776687584728, Test loss 0.19881179993541284\n",
      "Epoch 146, Train loss 0.16704562351836322, Test loss 0.19872389764326862\n",
      "Epoch 147, Train loss 0.16677810624557596, Test loss 0.19421931657728916\n",
      "Epoch 148, Train loss 0.16716440972374094, Test loss 0.19607262674887413\n",
      "Epoch 149, Train loss 0.16636703741872125, Test loss 0.20695222609113312\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "epochs = 150\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        net.train()\n",
    "        a_inp, a_out = data\n",
    "        optimizer.zero_grad()\n",
    "        predicted_output = net(a_inp)\n",
    "        fit = loss(predicted_output,a_out) # loss(p_out,a_out)\n",
    "        fit.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += fit.item()\n",
    "\n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            a_inp, a_out = data\n",
    "            predicted_output = net(a_inp)\n",
    "            fit = loss(predicted_output,a_out)\n",
    "            test_loss += fit.item()\n",
    "            predicted = torch.max(predicted_output.data, 1)\n",
    "\n",
    "    train_loss = train_loss/len(train_dataloader)\n",
    "    test_loss = test_loss/len(test_dataloader)\n",
    "    train_loss_history.append(train_loss)\n",
    "    test_loss_history.append(test_loss)\n",
    "    print('Epoch %s, Train loss %s, Test loss %s'%(epoch, train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "54a12803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for g in optimizer.param_groups:\n",
    "#     g['lr'] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "e47ef454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7d30ca2eb0>"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(train_loss_history)),train_loss_history,'-',linewidth=3,label='Train error')\n",
    "plt.plot(range(len(test_loss_history)),test_loss_history,'-',linewidth=3,label='Test error')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "adaa3adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.9226546719533179\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "net.eval()\n",
    "for i, data in enumerate(test_dataloader):\n",
    "    with torch.no_grad():\n",
    "        a_inp, a_out = data\n",
    "        predicted_output = net(a_inp)\n",
    "        p_arr = predicted_output.detach().numpy()\n",
    "        a_out = a_out.detach().numpy()\n",
    "        for i in range(len(a_out)):\n",
    "            if abs(p_arr[i] - a_out[i])<0.5:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print('accuracy is',correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "81faab35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "lin1.weight \t torch.Size([128, 43])\n",
      "lin1.bias \t torch.Size([128])\n",
      "lin2.weight \t torch.Size([64, 128])\n",
      "lin2.bias \t torch.Size([64])\n",
      "lin3.weight \t torch.Size([32, 64])\n",
      "lin3.bias \t torch.Size([32])\n",
      "lin4.weight \t torch.Size([1, 32])\n",
      "lin4.bias \t torch.Size([1])\n",
      "Optimizer's state_dict:\n",
      "state \t {0: {'step': 2339250, 'exp_avg': tensor([[-1.4044e-03, -1.6014e-03, -1.6245e-04,  ...,  1.3960e-04,\n",
      "         -5.2881e-04, -1.3035e-03],\n",
      "        [-1.0559e-03, -7.8071e-04, -5.9011e-04,  ..., -4.1285e-05,\n",
      "         -4.6616e-05, -9.2205e-04],\n",
      "        [ 3.5159e-03,  4.9848e-03, -8.0942e-04,  ..., -4.4663e-06,\n",
      "          1.5733e-03,  1.7720e-03],\n",
      "        ...,\n",
      "        [ 2.3195e-03,  1.8948e-03,  6.6652e-04,  ..., -1.3658e-04,\n",
      "          2.7860e-04,  1.6638e-03],\n",
      "        [-2.4400e-03, -1.0067e-03, -6.4062e-04,  ..., -5.8464e-04,\n",
      "          7.7969e-04, -1.5276e-03],\n",
      "        [-3.8351e-04, -5.7891e-04, -1.1470e-04,  ..., -4.9376e-04,\n",
      "         -9.9262e-04, -3.9632e-04]]), 'exp_avg_sq': tensor([[4.9837e-05, 3.5069e-05, 9.7600e-06,  ..., 4.4944e-05, 8.8290e-06,\n",
      "         3.4351e-05],\n",
      "        [1.2834e-04, 1.0620e-04, 2.2536e-05,  ..., 5.3144e-06, 3.4531e-06,\n",
      "         7.6568e-05],\n",
      "        [1.6992e-04, 1.4854e-04, 4.7748e-05,  ..., 4.8417e-04, 3.0212e-04,\n",
      "         1.0659e-04],\n",
      "        ...,\n",
      "        [1.4143e-05, 8.2790e-06, 5.2719e-06,  ..., 1.3805e-05, 3.4203e-06,\n",
      "         1.2149e-05],\n",
      "        [6.3020e-05, 4.0897e-05, 1.3506e-05,  ..., 1.9156e-04, 5.9416e-05,\n",
      "         3.3511e-05],\n",
      "        [5.5896e-05, 3.7929e-05, 2.3779e-05,  ..., 1.2751e-05, 1.8889e-04,\n",
      "         4.3459e-05]])}, 1: {'step': 2339250, 'exp_avg': tensor([-4.0781e-03, -2.2815e-04,  9.0412e-03, -3.1308e-03,  2.6912e-03,\n",
      "         1.8193e-03, -1.8427e-04,  1.6933e-04,  2.2626e-04, -1.0779e-04,\n",
      "         3.7888e-03, -6.6425e-04, -5.3851e-04,  9.7474e-04,  5.7782e-03,\n",
      "        -2.1516e-04,  1.1356e-03,  2.7970e-04,  1.4236e-03,  7.7822e-04,\n",
      "         1.9822e-04,  1.7208e-03,  1.5429e-03,  1.1935e-04, -2.3655e-03,\n",
      "        -3.6774e-04,  2.4594e-03,  6.5121e-04,  2.8231e-04, -5.5501e-04,\n",
      "         3.3892e-04, -1.3034e-03,  1.0264e-03, -8.1215e-03, -4.2227e-04,\n",
      "         1.4958e-02,  2.2661e-03,  1.0322e-03,  3.3440e-04,  1.3625e-03,\n",
      "        -3.3912e-04,  9.2153e-04, -4.8924e-04, -3.8530e-03,  1.6293e-03,\n",
      "         1.7916e-03,  8.7414e-04,  1.4805e-03,  2.8433e-04, -2.5562e-04,\n",
      "         1.5936e-04,  9.6569e-03,  7.5924e-04, -3.4947e-04,  6.1242e-05,\n",
      "         1.2650e-03,  9.8423e-04, -1.6158e-03, -1.5839e-02, -2.5936e-03,\n",
      "        -8.3620e-04,  6.9724e-05,  1.7776e-03, -7.3219e-04,  5.7696e-05,\n",
      "        -9.3709e-04, -1.0545e-03, -2.3792e-03,  2.8440e-03,  1.9776e-03,\n",
      "         5.1174e-04,  2.4684e-03, -6.0545e-04,  1.2245e-03, -6.6790e-04,\n",
      "         6.5010e-05, -1.1153e-04, -9.3778e-04,  2.1126e-04, -2.2842e-04,\n",
      "        -1.0712e-03,  2.9899e-04, -2.2311e-04, -3.3993e-04,  1.3098e-03,\n",
      "         2.5535e-05,  2.6302e-04,  1.1582e-03,  3.2583e-03,  1.0070e-03,\n",
      "         3.2455e-04,  2.9424e-05,  1.2570e-04, -4.9100e-04, -3.2991e-04,\n",
      "        -1.2485e-03, -1.6228e-05,  4.0085e-03,  1.6184e-03,  7.4085e-04,\n",
      "        -3.2149e-03,  2.1166e-04, -1.4339e-03, -2.3747e-03, -1.2161e-03,\n",
      "         8.2673e-04,  5.2231e-03,  1.8626e-03, -4.1771e-03, -1.0379e-03,\n",
      "         1.6233e-03,  1.4105e-04,  1.4896e-03,  1.1136e-03, -4.0435e-04,\n",
      "         1.5825e-02, -1.0274e-03,  1.6519e-04, -4.7245e-04,  3.0252e-04,\n",
      "         6.8123e-04, -1.4073e-03, -5.7890e-03,  2.2593e-03, -2.8782e-03,\n",
      "        -2.9798e-03,  7.5210e-04,  2.9058e-04]), 'exp_avg_sq': tensor([6.3144e-05, 9.7294e-05, 2.2511e-04, 5.5524e-05, 6.4371e-05, 8.3756e-05,\n",
      "        2.0421e-05, 7.8324e-05, 1.1522e-04, 2.2901e-05, 1.9560e-04, 7.8638e-05,\n",
      "        9.4296e-05, 2.2945e-04, 1.2610e-04, 7.0230e-05, 1.1739e-04, 5.9821e-05,\n",
      "        5.5532e-05, 5.8361e-05, 3.9502e-05, 1.0612e-04, 8.0898e-05, 4.0010e-05,\n",
      "        2.6868e-05, 1.5002e-05, 6.9483e-05, 5.1979e-05, 1.8035e-05, 8.2124e-05,\n",
      "        2.8371e-05, 4.7448e-05, 4.4584e-05, 1.2144e-04, 2.6321e-05, 1.4814e-04,\n",
      "        1.6830e-04, 1.0218e-04, 3.5170e-04, 1.2494e-04, 4.4023e-04, 9.3787e-05,\n",
      "        1.0344e-04, 5.5565e-05, 1.0368e-04, 2.2151e-04, 3.1817e-05, 5.4841e-05,\n",
      "        5.8532e-05, 6.6745e-06, 2.0139e-05, 3.4694e-04, 4.7513e-04, 6.0514e-05,\n",
      "        2.4312e-05, 5.4745e-05, 9.0772e-05, 1.1148e-04, 1.4027e-04, 2.4378e-05,\n",
      "        5.8762e-05, 7.9107e-05, 4.7603e-05, 3.1620e-05, 6.7058e-05, 2.0726e-05,\n",
      "        9.2137e-05, 3.8671e-05, 4.3283e-05, 1.6336e-04, 3.6524e-05, 1.3448e-04,\n",
      "        2.5262e-05, 1.3774e-04, 1.3826e-04, 3.3230e-05, 6.2202e-05, 9.1393e-05,\n",
      "        3.1230e-05, 1.0223e-04, 4.3494e-05, 1.9595e-05, 5.9819e-05, 5.2912e-05,\n",
      "        6.0311e-05, 1.0911e-05, 4.6940e-05, 2.8858e-05, 2.6279e-05, 5.8736e-05,\n",
      "        3.8691e-05, 2.3048e-05, 1.6769e-04, 4.6810e-05, 4.5481e-05, 5.5394e-05,\n",
      "        7.9018e-05, 1.6116e-04, 7.9809e-05, 1.8548e-05, 6.2085e-05, 7.3707e-05,\n",
      "        1.2570e-04, 1.0340e-04, 8.4167e-05, 4.5496e-05, 5.5179e-05, 2.3583e-05,\n",
      "        1.1581e-04, 8.4109e-05, 8.6804e-05, 6.6284e-05, 4.0887e-05, 4.3217e-05,\n",
      "        9.1872e-05, 3.0714e-04, 5.2132e-05, 3.1534e-05, 6.8103e-05, 6.2543e-06,\n",
      "        5.0074e-05, 3.2367e-05, 8.5650e-05, 2.4798e-05, 9.4721e-05, 1.5100e-05,\n",
      "        7.0898e-05, 4.4935e-05])}, 2: {'step': 2339250, 'exp_avg': tensor([[-2.6483e-03, -3.2870e-06, -5.6266e-05,  ..., -7.1345e-04,\n",
      "         -7.7829e-05,  3.0166e-04],\n",
      "        [ 2.9097e-04, -1.3642e-05,  2.0166e-03,  ..., -3.5551e-04,\n",
      "         -1.2195e-05,  2.1098e-04],\n",
      "        [-7.1850e-06,  3.1198e-05, -6.9305e-07,  ..., -8.4211e-07,\n",
      "         -1.9049e-07, -1.0688e-05],\n",
      "        ...,\n",
      "        [-2.2886e-03,  2.5443e-05, -1.8417e-05,  ..., -1.1412e-03,\n",
      "         -5.0250e-05, -6.3566e-05],\n",
      "        [-9.5706e-05,  1.8966e-07,  9.8830e-05,  ..., -1.5562e-05,\n",
      "         -5.7110e-06, -6.1273e-05],\n",
      "        [-2.7271e-04,  8.0833e-05, -4.2594e-05,  ...,  6.3167e-05,\n",
      "          7.6855e-06, -1.3063e-04]]), 'exp_avg_sq': tensor([[9.2531e-05, 1.2541e-06, 1.6666e-06,  ..., 2.3795e-05, 9.4696e-08,\n",
      "         4.8079e-06],\n",
      "        [2.0085e-04, 1.2544e-06, 3.7432e-06,  ..., 4.6941e-05, 3.6106e-07,\n",
      "         2.9678e-06],\n",
      "        [1.2781e-04, 8.2571e-06, 1.4557e-06,  ..., 1.4912e-05, 3.2891e-07,\n",
      "         5.1468e-07],\n",
      "        ...,\n",
      "        [1.2939e-04, 2.1828e-07, 4.8342e-07,  ..., 3.3584e-05, 6.8006e-07,\n",
      "         1.0315e-05],\n",
      "        [8.6200e-06, 2.4127e-07, 1.2861e-06,  ..., 4.4542e-07, 4.3020e-08,\n",
      "         1.2591e-06],\n",
      "        [3.2417e-05, 1.2886e-06, 9.4415e-07,  ..., 4.0749e-06, 6.3097e-07,\n",
      "         4.7891e-06]])}, 3: {'step': 2339250, 'exp_avg': tensor([ 3.0986e-05,  7.5171e-04, -2.2351e-04, -2.5172e-04, -1.4981e-04,\n",
      "        -8.8608e-06, -3.0668e-05,  2.7761e-04, -8.0540e-05,  2.1250e-04,\n",
      "         5.6052e-45,  2.2814e-04, -7.7292e-05,  1.3805e-04, -2.7765e-04,\n",
      "        -1.7782e-04, -7.2418e-06,  5.3857e-05,  1.8208e-03, -7.5709e-04,\n",
      "         6.0987e-04,  1.0808e-04,  3.1645e-05,  5.8234e-05,  1.7248e-04,\n",
      "        -4.5452e-04,  5.6052e-45, -4.1829e-05, -8.1139e-06,  1.4169e-03,\n",
      "        -5.4297e-05, -1.8676e-05, -4.8433e-05, -1.8516e-05, -7.8442e-05,\n",
      "        -1.0787e-04, -1.1064e-05, -3.4300e-05, -1.2317e-04, -2.9490e-05,\n",
      "        -2.3256e-04, -5.1490e-05, -1.8224e-04,  1.0009e-03,  8.5294e-05,\n",
      "         1.9812e-04, -9.3683e-05,  1.0846e-04, -5.3876e-06, -1.4950e-04,\n",
      "        -2.9573e-05,  5.6052e-45, -1.0588e-04,  5.6052e-45, -9.8491e-06,\n",
      "         8.6485e-04,  1.5227e-04,  2.3293e-06, -7.7690e-04, -1.2278e-05,\n",
      "        -2.4984e-05, -1.4227e-04,  2.6269e-05, -5.3057e-05]), 'exp_avg_sq': tensor([4.3797e-07, 2.8528e-06, 4.1769e-06, 9.7746e-07, 8.4187e-07, 1.6932e-06,\n",
      "        1.2731e-06, 1.4673e-06, 4.9793e-07, 6.8534e-07, 7.0065e-43, 1.7550e-06,\n",
      "        6.9975e-07, 6.2559e-07, 1.1482e-06, 6.7551e-07, 2.0247e-06, 2.6513e-07,\n",
      "        2.2810e-06, 1.3470e-06, 6.4374e-07, 4.1228e-06, 4.3511e-07, 2.0479e-06,\n",
      "        2.1264e-06, 1.2884e-06, 7.0065e-43, 1.0434e-06, 1.5110e-06, 3.4956e-06,\n",
      "        3.9710e-07, 4.9587e-07, 4.9964e-07, 3.2776e-06, 1.6443e-06, 1.6186e-06,\n",
      "        1.9383e-06, 3.3274e-07, 1.7101e-06, 9.6492e-07, 1.4869e-06, 4.4316e-07,\n",
      "        1.0336e-06, 9.2767e-07, 4.0066e-07, 2.7015e-06, 2.0184e-07, 2.0262e-06,\n",
      "        1.3770e-06, 1.3317e-06, 1.0572e-06, 7.0065e-43, 8.9279e-07, 7.0065e-43,\n",
      "        4.6980e-06, 2.0855e-06, 3.0607e-07, 4.8574e-07, 2.6782e-06, 6.5092e-07,\n",
      "        3.6879e-07, 3.2283e-07, 3.2538e-07, 9.0390e-07])}, 4: {'step': 2339250, 'exp_avg': tensor([[ 4.6617e-05,  1.0137e-03,  1.3827e-05,  ..., -4.7365e-06,\n",
      "          1.5531e-03, -3.0210e-07],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45],\n",
      "        [-2.5013e-05, -3.9483e-07,  1.2562e-05,  ..., -5.4936e-07,\n",
      "         -7.7850e-06, -7.2490e-08],\n",
      "        ...,\n",
      "        [-1.5304e-05,  4.1536e-05, -4.7621e-06,  ...,  5.3038e-05,\n",
      "          1.3831e-07,  2.7671e-08],\n",
      "        [-5.7295e-05, -2.1850e-03, -1.1076e-10,  ...,  1.2103e-04,\n",
      "          3.4157e-04, -8.5413e-04],\n",
      "        [ 2.1079e-05,  1.4305e-04,  4.0460e-39,  ...,  1.3920e-04,\n",
      "          2.1058e-03, -2.0458e-04]]), 'exp_avg_sq': tensor([[2.4360e-05, 9.9055e-06, 2.1771e-06,  ..., 2.9967e-07, 1.8909e-05,\n",
      "         1.1506e-06],\n",
      "        [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 1.3356e-10,\n",
      "         3.4153e-09],\n",
      "        [3.5300e-05, 1.0416e-06, 1.6726e-06,  ..., 2.4398e-07, 1.2063e-05,\n",
      "         9.6277e-07],\n",
      "        ...,\n",
      "        [2.9956e-06, 1.3442e-06, 1.2087e-05,  ..., 3.2471e-06, 1.3068e-06,\n",
      "         1.1900e-06],\n",
      "        [1.4196e-05, 2.2590e-06, 4.5347e-08,  ..., 1.4610e-05, 3.2119e-04,\n",
      "         9.8123e-05],\n",
      "        [4.1451e-06, 8.7955e-07, 1.3979e-08,  ..., 7.4606e-05, 1.3440e-05,\n",
      "         1.6905e-05]])}, 5: {'step': 2339250, 'exp_avg': tensor([ 1.2055e-04,  5.6052e-45,  1.2560e-07, -2.0733e-04,  3.6481e-08,\n",
      "        -5.9171e-07,  2.6872e-07, -2.4832e-06,  6.0455e-08,  7.9939e-07,\n",
      "         5.9129e-06, -1.7786e-04, -6.1483e-05, -5.3241e-04, -3.4783e-07,\n",
      "         7.1474e-06, -2.6752e-07, -2.0435e-07, -7.1892e-06, -6.1394e-07,\n",
      "        -1.4594e-07, -1.9774e-06,  5.1594e-06, -4.2875e-07,  5.2847e-05,\n",
      "         6.8777e-11, -1.1599e-09, -1.8713e-05, -1.3225e-08,  6.6159e-06,\n",
      "        -2.5797e-04,  4.9196e-05]), 'exp_avg_sq': tensor([6.2471e-08, 7.7801e-08, 2.0382e-08, 3.6283e-06, 9.2924e-10, 1.9177e-08,\n",
      "        4.5983e-09, 1.8223e-08, 7.9792e-08, 5.0706e-08, 1.7380e-08, 7.4580e-06,\n",
      "        1.8399e-06, 4.9639e-06, 1.3845e-08, 2.0961e-08, 2.9251e-09, 2.2903e-09,\n",
      "        2.1295e-09, 4.1296e-09, 7.5441e-09, 3.3590e-08, 3.3849e-08, 1.4862e-08,\n",
      "        8.2966e-09, 6.2911e-10, 2.4053e-09, 1.7147e-08, 1.2537e-08, 6.4951e-09,\n",
      "        3.4200e-06, 2.4157e-07])}, 6: {'step': 2339250, 'exp_avg': tensor([[-8.3876e-02, -5.6052e-45, -4.2012e-04, -2.5950e-02,  2.7101e-05,\n",
      "          1.2129e-04, -1.4157e-03,  5.9536e-03,  2.0291e-05, -3.5957e-04,\n",
      "         -3.9842e-03, -3.5988e-02,  1.8894e-01, -2.6839e-01,  1.0261e-04,\n",
      "         -2.5707e-04, -9.5787e-05,  1.1754e-04,  1.0123e-02,  2.2346e-04,\n",
      "          4.8247e-04,  6.4614e-04, -1.4900e-03,  6.8415e-05, -4.2909e-03,\n",
      "         -1.2937e-08,  7.1631e-06,  5.4613e-03,  2.3839e-06,  3.0861e-03,\n",
      "          1.8570e-02, -2.8988e-02]]), 'exp_avg_sq': tensor([[2.8061e+00, 7.8668e-06, 2.2373e-01, 4.9336e-02, 3.4923e-01, 6.3762e-02,\n",
      "         4.0045e-03, 3.0650e-03, 4.3302e-02, 2.7907e-01, 5.9321e-03, 1.1841e-01,\n",
      "         7.4274e+00, 1.1966e+00, 2.3184e-02, 1.9470e-03, 7.4224e-04, 7.4103e-02,\n",
      "         1.8627e-03, 3.4456e-01, 6.4832e-01, 1.8838e-01, 2.8803e-03, 5.4080e-01,\n",
      "         1.1342e-03, 1.1543e-05, 2.8890e-04, 5.6795e-02, 6.6622e-02, 2.2487e-01,\n",
      "         3.0613e-02, 4.3799e-02]])}, 7: {'step': 2339250, 'exp_avg': tensor([-0.0072]), 'exp_avg_sq': tensor([0.0030])}}\n",
      "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7]}]\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in net.state_dict():\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "8a0f74ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),'model_checkpoint_one.state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "c8ae91e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9441498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save a model, I need: \n",
    "# 1. Standard scaler\n",
    "# 2. input columns in order\n",
    "# 3. model state dict\n",
    "# 4. code for the model class\n",
    "\n",
    "# saving a model running code:\n",
    "# torch.save(net.state_dict(),'model_checkpoint_one.state')\n",
    "# pickle columns and standard scaler\n",
    "# store a copy of model class\n",
    "\n",
    "# Loading a model sampe code:\n",
    "# model = TheModelClass(*args, **kwargs)\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "0b30ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "cols_one = input_cols\n",
    "with open('columns.pkl', 'wb') as handle:\n",
    "    pickle.dump(cols_one, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('scaler.pkl', 'wb') as handle:\n",
    "    pickle.dump(scaler, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ce4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint 1 get data function:\n",
    "# def get_data(num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff,space_left_c,space_left_p):\n",
    "#     data = dict()\n",
    "    \n",
    "#     data['l_c_dist'] = len(c_dist)\n",
    "#     data['l_dist'] = len(dist)\n",
    "    \n",
    "#     if space_left_p:\n",
    "#         data['space_left_p_mean'] = np.mean(space_left_p)\n",
    "#         data['space_left_p_std'] = np.std(space_left_p)\n",
    "    \n",
    "#     if space_left_c:\n",
    "#         data['space_left_c_mean'] = np.mean(space_left_c)\n",
    "#         data['space_left_c_std'] = np.std(space_left_c)\n",
    "\n",
    "#     # get 2,3 moment of num\n",
    "#     max_moments = 3\n",
    "#     for i in range(2,max_moments+1):\n",
    "#         data[str(i)+'_num_moment'] = stats.moment(num,i)\n",
    "#         data[str(i)+'_c_num_moment'] = stats.moment(c_num,i)\n",
    "\n",
    "#     # get 2,3 moment of diff\n",
    "#     max_moments = 3\n",
    "#     for i in range(2,max_moments+1):\n",
    "#         data[str(i)+'_diff_moment'] = stats.moment(diff,i)\n",
    "#         data[str(i)+'_c_diff_moment'] = stats.moment(c_diff,i)\n",
    "\n",
    "#     # get 2,3 moment of dist\n",
    "#     max_moments = 3\n",
    "#     for i in range(2,max_moments+1):\n",
    "#         data[str(i)+'_dist_moment'] = stats.moment(dist,i)\n",
    "#         data[str(i)+'_c_dist_moment'] = stats.moment(c_dist,i)\n",
    "\n",
    "#     # get 2 moment of dist_diff\n",
    "#     max_moments = 2\n",
    "#     for i in range(2,max_moments+1):\n",
    "#         data[str(i)+'_dist_diff_moment'] = stats.moment(dist_diff,i)\n",
    "#         data[str(i)+'_c_dist_diff_moment'] = stats.moment(c_dist_diff,i)\n",
    "\n",
    "#     # get 3 moment of dist_diff*1000\n",
    "#     data[str(3)+'_dist_diff_moment'] = stats.moment(dist_diff,3) * 1000\n",
    "#     data[str(3)+'_c_dist_diff_moment'] = stats.moment(c_dist_diff,3) * 1000\n",
    "\n",
    "#     # dependant stats\n",
    "#     if num and c_num:\n",
    "#         data['num_p_ks'] = stats.ks_2samp(num,c_num)[1]\n",
    "#     if dist and c_dist:\n",
    "#         data['dist_p_ks'] = stats.ks_2samp(dist,c_dist)[1]\n",
    "#     if diff and c_diff:\n",
    "#         data['diff_p_ks'] = stats.ks_2samp(diff,c_diff)[1]\n",
    "#     if dist_diff and c_dist_diff:\n",
    "#         data['dist_diff_p_ks'] = stats.ks_2samp(dist_diff,c_dist_diff)[1]\n",
    "\n",
    "#     # covariance of first k samples\n",
    "#     k = 5\n",
    "#     l = min(k,len(num),len(c_num))\n",
    "#     if l>0:\n",
    "#         data['num_first_cov'] = np.cov(num[:l],c_num[:l])[0][1]\n",
    "#         data['num_last_cov'] = np.cov(num[-l:],c_num[-l:])[0][1]\n",
    "\n",
    "#     l = min(k,len(dist),len(c_dist))\n",
    "#     if l>0:\n",
    "#         data['dist_first_cov'] = np.cov(dist[:l],c_dist[:l])[0][1]\n",
    "#         data['dist_last_cov'] = np.cov(dist[-l:],c_dist[-l:])[0][1]\n",
    "\n",
    "#     l = min(k,len(diff),len(c_diff))\n",
    "#     if l>0:\n",
    "#         data['diff_first_cov'] = np.cov(diff[:l],c_diff[:l])[0][1]\n",
    "#         data['diff_last_cov'] = np.cov(diff[-l:],c_diff[-l:])[0][1]\n",
    "\n",
    "#     l = min(k,len(dist_diff),len(c_dist_diff))\n",
    "#     if l>0:\n",
    "#         data['dist_diff_first_cov'] = np.cov(dist_diff[:l],c_dist_diff[:l])[0][1]\n",
    "#         data['dist_diff_last_cov'] = np.cov(dist_diff[-l:],c_dist_diff[-l:])[0][1]\n",
    "#     return data\n",
    "\n",
    "# checkpoint 1 get model:\n",
    "# class NeuralNet(torch.nn.Module): \n",
    "#     def __init__(self):\n",
    "#         super(NeuralNet,self).__init__()\n",
    "\n",
    "#         self.relu = torch.nn.ReLU()\n",
    "        \n",
    "#         self.lin1 = torch.nn.Linear(num_feat, 128)\n",
    "        \n",
    "#         self.lin2 =torch.nn.Linear(128, 64)\n",
    "        \n",
    "#         self.dropout = torch.nn.Dropout(p=0.2)\n",
    "        \n",
    "#         self.lin3 =torch.nn.Linear(64, 32)\n",
    "        \n",
    "#         self.lin4 =torch.nn.Linear(32, 1)\n",
    "        \n",
    "#         self.out = torch.nn.Sigmoid()\n",
    "        \n",
    "#         self.float()\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.lin1(x)\n",
    "#         x = self.relu(x)\n",
    "        \n",
    "#         x = self.lin2(x)\n",
    "#         x = self.relu(x)\n",
    "        \n",
    "#         x = self.dropout(x)\n",
    "        \n",
    "#         x = self.lin3(x)\n",
    "#         x = self.relu(x)\n",
    "        \n",
    "#         x = self.lin4(x)\n",
    "#         x = self.out(x)\n",
    "        \n",
    "#         return x\n",
    "\n",
    "# net = NeuralNet()\n",
    "# loss = torch.nn.BCELoss() # pass output, target\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Load model sample code\n",
    "# model = TheModelClass(*args, **kwargs)\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2b071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training code for model 2\n",
    "# # create dataset\n",
    "# df = pd.DataFrame()\n",
    "\n",
    "# # get distributions for plaintexts\n",
    "# rel_dist_all = [build_rel_dist(text) for text in TEST_PLAIN_TEXTS]\n",
    "# rel_dists = [a[0] for a in rel_dist_all]\n",
    "# rel_nums = [a[1] for a in rel_dist_all]\n",
    "\n",
    "# rel_dist_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_dists]\n",
    "# rel_num_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_nums]\n",
    "\n",
    "# # space_left_ps = []\n",
    "# # for i,txt in enumerate(TEST_PLAIN_TEXTS):\n",
    "# #     space_left_ps.append(\n",
    "# #         defaultdict(list,{c:get_space_diffs_left(rel_nums[i][' '],rel_nums[i][c]) for c in _ALPHABET})\n",
    "# #     )\n",
    "# space_data_ps = []\n",
    "# for i,txt in enumerate(TEST_PLAIN_TEXTS):\n",
    "#     space_data_ps.append(\n",
    "#         defaultdict(list,{c:get_space_diffs_data(rel_nums[i][' '],rel_nums[i][c],len(txt)) for c in _ALPHABET})\n",
    "#     )\n",
    "    \n",
    "# num_itr = 0\n",
    "# for r_idx,cipher,char_key_mapping in iter_prob_tests(5,75,2,90):\n",
    "#     # track progress\n",
    "#     num_itr += 1\n",
    "#     if num_itr % 10 == 0:\n",
    "#         print(num_itr)\n",
    "    \n",
    "#     rev_mapping = {v:k for k,v in char_key_mapping.items()}\n",
    "    \n",
    "#     char_diff = len(cipher) - len(TEST_PLAIN_TEXTS[r_idx])\n",
    "    \n",
    "#     # get distributions for cipher\n",
    "#     c_rel_dist,c_rel_num = build_rel_dist(cipher)\n",
    "#     c_rel_num_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_num.items()})\n",
    "#     c_rel_dist_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_dist.items()})\n",
    "#     space_char = decrypt.get_space_key_value(cipher)\n",
    "# #     space_left_c = defaultdict(list,{c:get_space_diffs_left(c_rel_num[space_char],c_rel_num[c]) for c in _ALPHABET})\n",
    "#     space_data_c = defaultdict(list,{c:get_space_diffs_data(c_rel_num[space_char],c_rel_num[c],len(cipher)) for c in _ALPHABET})\n",
    "    \n",
    "#     for c_c in _ALPHABET:\n",
    "#         c_p = rev_mapping[c_c]\n",
    "        \n",
    "#         num = rel_nums[r_idx][c_p]\n",
    "#         c_num = c_rel_num[c_c]\n",
    "        \n",
    "#         dist = rel_dists[r_idx][c_p]\n",
    "#         c_dist = c_rel_dist[c_c]\n",
    "        \n",
    "#         diff = rel_num_diffs[r_idx][c_p]\n",
    "#         c_diff = c_rel_num_diff[c_c]\n",
    "        \n",
    "#         dist_diff = rel_dist_diffs[r_idx][c_p]\n",
    "#         c_dist_diff = c_rel_dist_diff[c_c]\n",
    "        \n",
    "#         data = get_data(num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff,space_data_c[c_c],space_data_ps[r_idx][c_p])\n",
    "#         data['char_diff'] = char_diff\n",
    "#         data['output'] = 1\n",
    "#         append(data,df)\n",
    "        \n",
    "#         best_negative = get_best_negative(r_idx,c_dist,rel_dists,3)\n",
    "        \n",
    "#         chosen = set([c_p])\n",
    "#         while len(chosen)<4:\n",
    "#             c_p = next_choice(best_negative,chosen)\n",
    "#             chosen.add(c_p)\n",
    "            \n",
    "#             num = rel_nums[r_idx][c_p]\n",
    "#             dist = rel_dists[r_idx][c_p]\n",
    "#             diff = rel_num_diffs[r_idx][c_p]\n",
    "#             dist_diff = rel_dist_diffs[r_idx][c_p]\n",
    "            \n",
    "#             data = get_data(num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff,space_data_c[c_c],space_data_ps[r_idx][c_p])\n",
    "#             data['char_diff'] = char_diff\n",
    "#             data['output'] = 0\n",
    "#             append(data,df)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd0c013cb75f3a62cc499443ad8f80e9cdbe9086d1db4cde0c3b9b3ff86d71b210c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
