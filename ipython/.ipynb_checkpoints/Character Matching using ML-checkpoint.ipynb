{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "716abb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import random\n",
    "import bisect\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "sys.path.insert(0,'../decryption')\n",
    "sys.path.insert(0,'../encryption')\n",
    "sys.path.insert(0,'../dictionaries')\n",
    "\n",
    "import encrypt\n",
    "import decrypt\n",
    "import alphabet\n",
    "import frequency\n",
    "\n",
    "_ALPHABET = \" abcdefghijklmnopqrstuvwxyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "a3b2e45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['underwaists wayfarings fluty analgia refuels transcribing nibbled okra buttonholer venalness hamlet praus apprisers presifted cubital walloper dissembler bunting wizardries squirrel preselect befitted licensee encumbrances proliferations tinkerer egrets recourse churl kolinskies ionospheric docents unnatural scuffler muches petulant acorns subconscious xyster tunelessly boners slag amazement intercapillary manse unsay embezzle stuccoer dissembles batwing valediction iceboxes ketchups phonily con',\n",
       " 'rhomb subrents brasiers render avg tote lesbian dibbers jeopardy struggling urogram furrowed hydrargyrum advertizing cheroots goons congratulation assaulters ictuses indurates wingovers relishes briskly livelihoods inflatable serialized lockboxes cowers holster conciliating parentage yowing restores conformities marted barrettes graphically overdevelop sublimely chokey chinches abstracts rights hockshops bourgeoisie coalition translucent fiascoes panzer mucus capacitated stereotyper omahas produ',\n",
       " 'yorkers peccaries agenda beshrews outboxing biding herons liturgies nonconciliatory elliptical confidants concealable teacups chairmanning proems ecclesiastically shafting nonpossessively doughboy inclusion linden zebroid parabolic misadventures fanciers grovelers requiters catmints hyped necklace rootstock rigorously indissolubility universally burrowers underproduced disillusionment wrestling yellowbellied sherpa unburnt jewelry grange dicker overheats daphnia arteriosclerotic landsat jongleur',\n",
       " 'cygnets chatterers pauline passive expounders cordwains caravel antidisestablishmentarianism syllabubs purled hangdogs clonic murmurers admirable subdialects lockjaws unpatentable jagging negotiated impersonates mammons chumminess semi pinner comprised managership conus turned netherlands temporariness languishers aerate sadists chemistry migraine froggiest sounding rapidly shelving maligning shriek faeries misogynist clarities oversight doylies remodeler tauruses prostrated frugging comestible',\n",
       " 'ovulatory geriatric hijack nonintoxicants prophylactic nonprotective skyhook warehouser paganized brigading european sassier antipasti tallyho warmer portables selling scheming amirate flanker photosensitizer multistage utile paralyzes indexer backrests tarmac doles siphoned casavas mudslinging nonverbal weevil arbitral painted vespertine plexiglass tanker seaworthiness uninterested anathematizing conduces terbiums wheelbarrow kabalas stagnation briskets counterclockwise hearthsides spuriously s']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_PLAIN_TEXTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7f5d1b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation of problem\n",
    "TEST_KEY_MAPPING = encrypt.generate_key_mapping()\n",
    "TEST_CHAR_MAPPING = encrypt.char_key_mapping_from_key_mapping(TEST_KEY_MAPPING)\n",
    "\n",
    "assert len(set(TEST_KEY_MAPPING)) == 27\n",
    "\n",
    "TEST_PLAIN_TEXTS = []\n",
    "with open('../dictionaries/official_dictionary_1_cleaned.txt','r') as f:\n",
    "    content = f.readlines()\n",
    "    for line in content:\n",
    "        TEST_PLAIN_TEXTS.append(line.strip())\n",
    "\n",
    "TEST_PROBABILITY = 0.1\n",
    "ciphers = [encrypt.encrypt(msg,TEST_KEY_MAPPING,TEST_PROBABILITY) for msg in TEST_PLAIN_TEXTS]\n",
    "\n",
    "# pick a random cipher and start working with it. (We should not know the original plain text)\n",
    "r = random.randint(0,len(ciphers)-1)\n",
    "cipher_txt = ciphers[r]\n",
    "test_plain_text = TEST_PLAIN_TEXTS[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6937c61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'klgh yfeolxvffhyjyjeobvsmui yobveaeiipvyoxyzbts dyjeoltjdek vi eclolvjvpymov cxfbidieyefvamiexqy  fvjtiv ieqoegmmvaasaeobdsjmyqdoxv hdtheolmgt iloqssjqsjoyjeocvdqijvamyoesadivmylfeomtlwcvkreoys rbvfy fvamyoxcvzhhi ho yhtfyivfydoiqbyhjet vfyeoqvqqft eolxsqqih yeeocepyqiobi  dyjoltqbjieydoqv vgmhyjexibolt seofsj ydo yfxyjmv deofyqbtjvjjiy yeeomv hosiexyjeovyjvfyoevdiefteolxyqiefjgoqihjvi yonj tlhhziyefoqets di hojjv bidmgoxoexympi hoqvd mih i hoexjiywonwvyjiyeoqliethg iefolmvjifiayteotpyjeifhxfodtgvjemiyeojynqtdymyjofvsjsejyeopbjteefjvfydonjashhi hgqoltqyefiamy'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cipher_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8218b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rel_dist(text):\n",
    "    rel_dist = defaultdict(list)\n",
    "    rel_num = defaultdict(list)\n",
    "    for j,c in enumerate(text):\n",
    "        rel_dist[c].append((j/len(text)))\n",
    "        rel_num[c].append(j)\n",
    "    return rel_dist,rel_num\n",
    "\n",
    "def get_diff(arr):\n",
    "    diff = []\n",
    "    for i in range(1,len(arr)):\n",
    "        diff.append(round(arr[i]-arr[i-1],4))\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "54ed46d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_dist_all = [build_rel_dist(text) for text in TEST_PLAIN_TEXTS]\n",
    "rel_dists = [a[0] for a in rel_dist_all]\n",
    "rel_nums = [a[1] for a in rel_dist_all]\n",
    "\n",
    "rel_dist_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_dists]\n",
    "rel_num_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_nums]\n",
    "\n",
    "c_rel_dist,c_rel_num = build_rel_dist(cipher_txt)\n",
    "\n",
    "c_rel_dist_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_dist.items()})\n",
    "c_rel_num_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_num.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "412c09b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b 0.9076168929110106 0.9595404595404595 [75, 98, 100, 142, 148, 176, 496]\n"
     ]
    }
   ],
   "source": [
    "target = 'a'\n",
    "p_vals = []\n",
    "\n",
    "c_rel_diff = c_rel_dist_diff[target]\n",
    "c_rel = c_rel_dist[target]\n",
    "for c in _ALPHABET:\n",
    "    rel_diff = rel_dist_diffs[r][c]\n",
    "    rel = rel_dists[r][c]\n",
    "    if len(rel) == 0 or len(rel_diff) == 0:\n",
    "        continue\n",
    "    if len(rel)>len(c_rel):\n",
    "        continue\n",
    "    p_val = stats.ks_2samp(rel,c_rel)[1]\n",
    "    p_val_diff = stats.ks_2samp(rel_diff,c_rel_diff)[1]\n",
    "    if p_val>0.9:\n",
    "        print(c,p_val,p_val_diff,rel_nums[r][c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfb0059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e8b7d686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0991, 0.0442, 0.0018, 0.0035, 0.085, 0.0106, 0.0549, 0.4956, 0.1115, 0.0301]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_rel_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0808c0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0361]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_dist_diffs[r]['j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4840a1fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0584070796460177,\n",
       " 0.15752212389380532,\n",
       " 0.20176991150442478,\n",
       " 0.20353982300884957,\n",
       " 0.20707964601769913,\n",
       " 0.2920353982300885,\n",
       " 0.30265486725663715,\n",
       " 0.35752212389380533,\n",
       " 0.8530973451327434,\n",
       " 0.9646017699115044,\n",
       " 0.9946902654867257]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b2967de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0c26a81d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 'o',\n",
       " 'a': 'v',\n",
       " 'b': 'a',\n",
       " 'c': 'l',\n",
       " 'd': 'd',\n",
       " 'e': 'y',\n",
       " 'f': 'n',\n",
       " 'g': 'h',\n",
       " 'h': 'x',\n",
       " 'i': 'i',\n",
       " 'j': 'c',\n",
       " 'k': 'w',\n",
       " 'l': 'm',\n",
       " 'm': 'q',\n",
       " 'n': ' ',\n",
       " 'o': 't',\n",
       " 'p': 'b',\n",
       " 'q': 'u',\n",
       " 'r': 'j',\n",
       " 's': 'e',\n",
       " 't': 'f',\n",
       " 'u': 's',\n",
       " 'v': 'p',\n",
       " 'w': 'k',\n",
       " 'x': 'z',\n",
       " 'y': 'g',\n",
       " 'z': 'r'}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_CHAR_MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "11a1ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy: First declare eliminations \n",
    "# Then Declare hyperparameters as thresholds. For different values of extra characters, calculate the best\n",
    "# value of these hyperparameters by running through the solution\n",
    "\n",
    "# elimination 1: length of rel should be lesser\n",
    "# elimination 2: top r (hyper param mapped to diff) values of p_vals\n",
    "# elimination 3: check difference in first character of rel num. it should be less than k (2nd hyper-parameter OR ML input)\n",
    "# elimination 4: for each term in first and last m (3rd hyperparam) rel dist elements, \n",
    "# find closest term and add difference of square from it to total score. Choose letter with lowest such score\n",
    "#       OR\n",
    "# Do this for first m terms in rel nums\n",
    "#       OR\n",
    "# Calculate some group stats and run a classification ML model. These features can include:\n",
    "# diff, 1st, 2nd, 3rd ... kth moment of steps of both distributions (k is a hyperparameter)\n",
    "\n",
    "# In the end, calculate average p value of each guess and output the maximum\n",
    "# OR calculate score as p value * size in rel num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ee785892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_tests(p,num):\n",
    "    \"\"\"\n",
    "    iterate over num tests for prob p\n",
    "    \"\"\"\n",
    "    for _ in range(num):\n",
    "        num_key_mapping = encrypt.generate_key_mapping()\n",
    "        char_key_mapping = encrypt.char_key_mapping_from_key_mapping(num_key_mapping)\n",
    "\n",
    "        r = random.randint(0,len(ciphers)-1)\n",
    "        cipher = encrypt.encrypt(TEST_PLAIN_TEXTS[r],num_key_mapping,p)\n",
    "\n",
    "        yield r,cipher,char_key_mapping\n",
    "\n",
    "def append(data,df):\n",
    "    l = len(df)\n",
    "    for k,v in data.items():\n",
    "        df.loc[l,k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "6c32d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(arr,target,lo=0,hi=10000):\n",
    "    hi = min(hi,len(arr))\n",
    "    res = bisect.bisect_left(arr,target,lo,hi)\n",
    "    if res != len(arr) and arr[res] == target:\n",
    "        return res\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "7c8e721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_space_diffs_left(space_rel_num,rel_num):\n",
    "    ret = []\n",
    "    for i,num in enumerate(rel_num):\n",
    "        space_closest = bisect.bisect_left(space_rel_num,num) - 1\n",
    "\n",
    "        if space_closest == -1:\n",
    "            ret.append(num)\n",
    "            continue\n",
    "        ret.append(num - space_rel_num[space_closest])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5994863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_space_diffs_data(space_rel_num,rel_num,l):\n",
    "    left = []\n",
    "    right = []\n",
    "    avg_num_diff = []\n",
    "    for i,num in enumerate(rel_num):\n",
    "        space_closest_right = bisect.bisect_left(space_rel_num,num)\n",
    "        space_closest_left = space_closest_left-1\n",
    "        if space_closest_left == -1:\n",
    "            lo = 0\n",
    "        else:\n",
    "            lo = space_rel_num[space_closest_left]\n",
    "        if space_closest_right == len(space_rel_num):\n",
    "            hi = l\n",
    "        else:\n",
    "            hi = space_rel_num[space_closest_right]\n",
    "        left.append(num-lo)\n",
    "        right.append(hi-num)\n",
    "        avg_num_diff.append(right[-1] - left[-1])\n",
    "        \n",
    "    return left,right,avg_num_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "33c47e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_idx,cipher,char_key_mapping = next(iter_tests(0.4,1))\n",
    "c_rel_dist,c_rel_num = build_rel_dist(cipher)\n",
    "diff = len(cipher)-len(TEST_PLAIN_TEXTS[r_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "67b1f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'c'\n",
    "rel_num = rel_nums[r_idx][target]\n",
    "space_rel_num = rel_nums[r_idx][' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "0d26278b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "space_left_p = get_space_diffs_left(rel_nums[r_idx][' '],rel_nums[r_idx][target])\n",
    "space_char = decrypt.get_space_key_value(cipher)\n",
    "space_left_c = get_space_diffs_left(c_rel_num[space_char],c_rel_num[char_key_mapping[target]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "fe5fa666",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.921\n",
      "3.539\n",
      "4.7\n",
      "2.622\n",
      "2.349\n",
      "-4.85\n",
      "3.683\n",
      "2.583\n",
      "4.3\n",
      "2.709\n",
      "1.99\n",
      "6.0\n",
      "3.508\n",
      "2.705\n",
      "17.7\n",
      "2.431\n",
      "1.863\n",
      "6.1\n",
      "7.357\n",
      "5.74\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 5 and the array at index 1 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1x/qc9ydz9s4vd2vjjqzx68nt0m0000gn/T/ipykernel_23504/1499902993.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace_left_c\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace_left_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace_left_c\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace_left_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace_left_c\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspace_left_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcov\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights)\u001b[0m\n\u001b[1;32m   2413\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrowvar\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2414\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2415\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mddof\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 5 and the array at index 1 has size 1"
     ]
    }
   ],
   "source": [
    "for target in _ALPHABET:\n",
    "    rel_num = rel_nums[r_idx][target]\n",
    "    space_rel_num = rel_nums[r_idx][' ']\n",
    "    space_left_p = get_space_diffs_left(rel_nums[r_idx][' '],rel_nums[r_idx][target])\n",
    "    space_char = decrypt.get_space_key_value(cipher)\n",
    "    space_left_c = get_space_diffs_left(c_rel_num[space_char],c_rel_num[char_key_mapping[target]])\n",
    "    \n",
    "    print(round(np.mean(space_left_c) - np.mean(space_left_p),3))\n",
    "    print(round(np.std(space_left_c) - np.std(space_left_p),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "8cc45c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff,space_left_c,space_left_p):\n",
    "    data = dict()\n",
    "    \n",
    "    data['l_c_dist'] = len(c_dist)\n",
    "    data['l_dist'] = len(dist)\n",
    "    \n",
    "    if space_left_p:\n",
    "        data['space_left_p_mean'] = np.mean(space_left_p)\n",
    "        data['space_left_p_std'] = np.std(space_left_p)\n",
    "    \n",
    "    if space_left_c:\n",
    "        data['space_left_c_mean'] = np.mean(space_left_c)\n",
    "        data['space_left_c_std'] = np.std(space_left_c)\n",
    "\n",
    "    # get 2,3 moment of num\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_num_moment'] = stats.moment(num,i)\n",
    "        data[str(i)+'_c_num_moment'] = stats.moment(c_num,i)\n",
    "\n",
    "    # get 2,3 moment of diff\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_diff_moment'] = stats.moment(diff,i)\n",
    "        data[str(i)+'_c_diff_moment'] = stats.moment(c_diff,i)\n",
    "\n",
    "    # get 2,3 moment of dist\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_dist_moment'] = stats.moment(dist,i)\n",
    "        data[str(i)+'_c_dist_moment'] = stats.moment(c_dist,i)\n",
    "\n",
    "    # get 2 moment of dist_diff\n",
    "    max_moments = 2\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_dist_diff_moment'] = stats.moment(dist_diff,i)\n",
    "        data[str(i)+'_c_dist_diff_moment'] = stats.moment(c_dist_diff,i)\n",
    "\n",
    "    # get 3 moment of dist_diff*1000\n",
    "    data[str(3)+'_dist_diff_moment'] = stats.moment(dist_diff,3) * 1000\n",
    "    data[str(3)+'_c_dist_diff_moment'] = stats.moment(c_dist_diff,3) * 1000\n",
    "\n",
    "    # dependant stats\n",
    "    if num and c_num:\n",
    "        data['num_p_ks'] = stats.ks_2samp(num,c_num)[1]\n",
    "    if dist and c_dist:\n",
    "        data['dist_p_ks'] = stats.ks_2samp(dist,c_dist)[1]\n",
    "    if diff and c_diff:\n",
    "        data['diff_p_ks'] = stats.ks_2samp(diff,c_diff)[1]\n",
    "    if dist_diff and c_dist_diff:\n",
    "        data['dist_diff_p_ks'] = stats.ks_2samp(dist_diff,c_dist_diff)[1]\n",
    "\n",
    "    # covariance of first k samples\n",
    "    k = 5\n",
    "    l = min(k,len(num),len(c_num))\n",
    "    if l>0:\n",
    "        data['num_first_cov'] = np.cov(num[:l],c_num[:l])[0][1]\n",
    "        data['num_last_cov'] = np.cov(num[-l:],c_num[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(dist),len(c_dist))\n",
    "    if l>0:\n",
    "        data['dist_first_cov'] = np.cov(dist[:l],c_dist[:l])[0][1]\n",
    "        data['dist_last_cov'] = np.cov(dist[-l:],c_dist[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(diff),len(c_diff))\n",
    "    if l>0:\n",
    "        data['diff_first_cov'] = np.cov(diff[:l],c_diff[:l])[0][1]\n",
    "        data['diff_last_cov'] = np.cov(diff[-l:],c_diff[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(dist_diff),len(c_dist_diff))\n",
    "    if l>0:\n",
    "        data['dist_diff_first_cov'] = np.cov(dist_diff[:l],c_dist_diff[:l])[0][1]\n",
    "        data['dist_diff_last_cov'] = np.cov(dist_diff[-l:],c_dist_diff[-l:])[0][1]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "55e08dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_negative(r,c_rel,rel_dists,n=4):\n",
    "    \"\"\"\n",
    "    choose those characters which we know are hard to predict\n",
    "    \"\"\"\n",
    "    p_vals = []\n",
    "    for c_p in _ALPHABET:\n",
    "        rel = rel_dists[r][c_p]\n",
    "        if len(rel) == 0:\n",
    "            continue\n",
    "        if len(rel)>len(c_rel):\n",
    "            continue\n",
    "        p_val = stats.ks_2samp(rel,c_rel)[1]\n",
    "        p_vals.append((p_val,c_p))\n",
    "    p_vals.sort(key = lambda a: -a[0])\n",
    "    return [a[1] for a in p_vals[:n]]\n",
    "\n",
    "def next_choice(closest_p_vals,chosen):\n",
    "    for char in closest_p_vals:\n",
    "        if char not in chosen:\n",
    "            return char\n",
    "    return random.choice(_ALPHABET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "c563ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_prob_tests(pmin,pmax,step,num):\n",
    "    for prob in range(pmin,pmax+1,step):\n",
    "        print('generating for prob',prob)\n",
    "        for r_idx,cipher,char_key_mapping in iter_tests(prob/100,num):\n",
    "            yield r_idx,cipher,char_key_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "9e862055",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating for prob 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1x/qc9ydz9s4vd2vjjqzx68nt0m0000gn/T/ipykernel_23504/1546202601.py:57: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  data['num_first_cov'] = np.cov(num[:l],c_num[:l])[0][1]\n",
      "/var/folders/1x/qc9ydz9s4vd2vjjqzx68nt0m0000gn/T/ipykernel_23504/1546202601.py:58: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  data['num_last_cov'] = np.cov(num[-l:],c_num[-l:])[0][1]\n",
      "/var/folders/1x/qc9ydz9s4vd2vjjqzx68nt0m0000gn/T/ipykernel_23504/1546202601.py:62: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  data['dist_first_cov'] = np.cov(dist[:l],c_dist[:l])[0][1]\n",
      "/var/folders/1x/qc9ydz9s4vd2vjjqzx68nt0m0000gn/T/ipykernel_23504/1546202601.py:63: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  data['dist_last_cov'] = np.cov(dist[-l:],c_dist[-l:])[0][1]\n",
      "/var/folders/1x/qc9ydz9s4vd2vjjqzx68nt0m0000gn/T/ipykernel_23504/1546202601.py:67: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  data['diff_first_cov'] = np.cov(diff[:l],c_diff[:l])[0][1]\n",
      "/var/folders/1x/qc9ydz9s4vd2vjjqzx68nt0m0000gn/T/ipykernel_23504/1546202601.py:68: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  data['diff_last_cov'] = np.cov(diff[-l:],c_diff[-l:])[0][1]\n",
      "/var/folders/1x/qc9ydz9s4vd2vjjqzx68nt0m0000gn/T/ipykernel_23504/1546202601.py:72: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  data['dist_diff_first_cov'] = np.cov(dist_diff[:l],c_dist_diff[:l])[0][1]\n",
      "/var/folders/1x/qc9ydz9s4vd2vjjqzx68nt0m0000gn/T/ipykernel_23504/1546202601.py:73: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  data['dist_diff_last_cov'] = np.cov(dist_diff[-l:],c_dist_diff[-l:])[0][1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "generating for prob 7\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "generating for prob 9\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "generating for prob 11\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "generating for prob 13\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "generating for prob 15\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "generating for prob 17\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "generating for prob 19\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "generating for prob 21\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "generating for prob 23\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "generating for prob 25\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "generating for prob 27\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "generating for prob 29\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "generating for prob 31\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "generating for prob 33\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "generating for prob 35\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "generating for prob 37\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "generating for prob 39\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "generating for prob 41\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "generating for prob 43\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "generating for prob 45\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "generating for prob 47\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "generating for prob 49\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "generating for prob 51\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "generating for prob 53\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n",
      "generating for prob 55\n",
      "2010\n",
      "2020\n",
      "2030\n",
      "2040\n",
      "2050\n",
      "2060\n",
      "2070\n",
      "2080\n",
      "generating for prob 57\n",
      "2090\n",
      "2100\n",
      "2110\n",
      "2120\n",
      "2130\n",
      "2140\n",
      "2150\n",
      "2160\n",
      "generating for prob 59\n",
      "2170\n",
      "2180\n",
      "2190\n",
      "2200\n",
      "2210\n",
      "2220\n",
      "2230\n",
      "2240\n",
      "generating for prob 61\n",
      "2250\n",
      "2260\n",
      "2270\n",
      "2280\n",
      "2290\n",
      "2300\n",
      "2310\n",
      "2320\n",
      "generating for prob 63\n",
      "2330\n",
      "2340\n",
      "2350\n",
      "2360\n",
      "2370\n",
      "2380\n",
      "2390\n",
      "2400\n",
      "generating for prob 65\n",
      "2410\n",
      "2420\n",
      "2430\n",
      "2440\n",
      "2450\n",
      "2460\n",
      "2470\n",
      "2480\n",
      "generating for prob 67\n",
      "2490\n",
      "2500\n",
      "2510\n",
      "2520\n",
      "2530\n",
      "2540\n",
      "2550\n",
      "2560\n",
      "generating for prob 69\n",
      "2570\n",
      "2580\n",
      "2590\n",
      "2600\n",
      "2610\n",
      "2620\n",
      "2630\n",
      "2640\n",
      "generating for prob 71\n",
      "2650\n",
      "2660\n",
      "2670\n",
      "2680\n",
      "2690\n",
      "2700\n",
      "2710\n",
      "2720\n",
      "generating for prob 73\n",
      "2730\n",
      "2740\n",
      "2750\n",
      "2760\n",
      "2770\n",
      "2780\n",
      "2790\n",
      "2800\n",
      "generating for prob 75\n",
      "2810\n",
      "2820\n",
      "2830\n",
      "2840\n",
      "2850\n",
      "2860\n",
      "2870\n",
      "2880\n"
     ]
    }
   ],
   "source": [
    "# create dataset\n",
    "PROB_VALUE = 0.3\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# get distributions for plaintexts\n",
    "rel_dist_all = [build_rel_dist(text) for text in TEST_PLAIN_TEXTS]\n",
    "rel_dists = [a[0] for a in rel_dist_all]\n",
    "rel_nums = [a[1] for a in rel_dist_all]\n",
    "\n",
    "rel_dist_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_dists]\n",
    "rel_num_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_nums]\n",
    "\n",
    "space_left_ps = []\n",
    "for i,txt in enumerate(TEST_PLAIN_TEXTS):\n",
    "    space_left_ps.append(\n",
    "        defaultdict(list,{c:get_space_diffs_left(rel_nums[i][' '],rel_nums[i][c]) for c in _ALPHABET})\n",
    "    )\n",
    "\n",
    "num_itr = 0\n",
    "for r_idx,cipher,char_key_mapping in iter_prob_tests(5,75,2,80):\n",
    "    # track progress\n",
    "    num_itr += 1\n",
    "    if num_itr % 10 == 0:\n",
    "        print(num_itr)\n",
    "    \n",
    "    rev_mapping = {v:k for k,v in char_key_mapping.items()}\n",
    "    \n",
    "    char_diff = len(cipher) - len(TEST_PLAIN_TEXTS[r_idx])\n",
    "    \n",
    "    # get distributions for cipher\n",
    "    c_rel_dist,c_rel_num = build_rel_dist(cipher)\n",
    "    c_rel_num_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_num.items()})\n",
    "    c_rel_dist_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_dist.items()})\n",
    "    space_char = decrypt.get_space_key_value(cipher)\n",
    "    space_left_c = defaultdict(list,{c:get_space_diffs_left(c_rel_num[space_char],c_rel_num[c]) for c in _ALPHABET})\n",
    "    #get_space_diffs_left(c_rel_num[space_char],c_rel_num[char_key_mapping[target]])\n",
    "    \n",
    "    for c_c in _ALPHABET:\n",
    "        c_p = rev_mapping[c_c]\n",
    "        \n",
    "        num = rel_nums[r_idx][c_p]\n",
    "        c_num = c_rel_num[c_c]\n",
    "        \n",
    "        dist = rel_dists[r_idx][c_p]\n",
    "        c_dist = c_rel_dist[c_c]\n",
    "        \n",
    "        diff = rel_num_diffs[r_idx][c_p]\n",
    "        c_diff = c_rel_num_diff[c_c]\n",
    "        \n",
    "        dist_diff = rel_dist_diffs[r_idx][c_p]\n",
    "        c_dist_diff = c_rel_dist_diff[c_c]\n",
    "        \n",
    "        data = get_data(num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff,space_left_c[c_c],space_left_ps[r_idx][c_p])\n",
    "        data['char_diff'] = char_diff\n",
    "        data['output'] = 1\n",
    "        append(data,df)\n",
    "        \n",
    "        best_negative = get_best_negative(r_idx,c_dist,rel_dists,3)\n",
    "        \n",
    "        chosen = set([c_p])\n",
    "        while len(chosen)<4:\n",
    "            c_p = next_choice(best_negative,chosen)\n",
    "            chosen.add(c_p)\n",
    "            \n",
    "            num = rel_nums[r_idx][c_p]\n",
    "            dist = rel_dists[r_idx][c_p]\n",
    "            diff = rel_num_diffs[r_idx][c_p]\n",
    "            dist_diff = rel_dist_diffs[r_idx][c_p]\n",
    "            \n",
    "            data = get_data(num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff,space_left_c[c_c],space_left_ps[r_idx][c_p])\n",
    "            data['char_diff'] = char_diff\n",
    "            data['output'] = 0\n",
    "            append(data,df)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "2cdb39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "7788d2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316973"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7988ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('dataset_two.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "64f0d15f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_idx = list(df.columns).index('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "6ae7124a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_cols = list(df.columns)\n",
    "input_cols.remove('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "7ef41fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:,input_cols].values\n",
    "y = df.iloc[:,output_idx].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "b1126d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "num_feat = X_train_raw.shape[1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = torch.from_numpy(scaler.transform(X_train_raw)).float()\n",
    "X_test = torch.from_numpy(scaler.transform(X_test_raw)).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_test = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "39ffb746",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train,y_train) # create your datset\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=16,shuffle=True) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "a2b36211",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(X_test,y_test) # create your datset\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=16,shuffle=True) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "f9401669",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module): \n",
    "    def __init__(self):\n",
    "        super(NeuralNet,self).__init__()\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(num_feat, 128)\n",
    "        \n",
    "        self.lin2 =torch.nn.Linear(128, 64)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.lin3 =torch.nn.Linear(64, 32)\n",
    "        \n",
    "        self.lin4 =torch.nn.Linear(32, 1)\n",
    "        \n",
    "        self.out = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.float()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.lin2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.lin3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.lin4(x)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "net = NeuralNet()\n",
    "loss = torch.nn.BCELoss() # pass output, target\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "4f890ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history = []\n",
    "test_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904ea11f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train loss 0.29743041530106984, Test loss 0.277386617691671\n",
      "Epoch 1, Train loss 0.2513554776934243, Test loss 0.2435376918580509\n",
      "Epoch 2, Train loss 0.2404450150486055, Test loss 0.23998454701303332\n",
      "Epoch 3, Train loss 0.2333187242563374, Test loss 0.23299285368699316\n",
      "Epoch 4, Train loss 0.22934123134307127, Test loss 0.23222450253993654\n",
      "Epoch 5, Train loss 0.22522272497164647, Test loss 0.22793874279505036\n",
      "Epoch 6, Train loss 0.22200942623994052, Test loss 0.2327760525616851\n",
      "Epoch 7, Train loss 0.2199730730613978, Test loss 0.22955404014735886\n",
      "Epoch 8, Train loss 0.2184383070093956, Test loss 0.23751335183295152\n",
      "Epoch 9, Train loss 0.21672895325855213, Test loss 0.22886039021879015\n",
      "Epoch 10, Train loss 0.21424414688139862, Test loss 0.2237633981107086\n",
      "Epoch 11, Train loss 0.21247627852922912, Test loss 0.22405364506058195\n",
      "Epoch 12, Train loss 0.21162634818240644, Test loss 0.22483582589693848\n",
      "Epoch 13, Train loss 0.2096999690670924, Test loss 0.22093812710621857\n",
      "Epoch 14, Train loss 0.20911018396171688, Test loss 0.21922798871835456\n",
      "Epoch 15, Train loss 0.2080408970442063, Test loss 0.2240293478459423\n",
      "Epoch 16, Train loss 0.2074474166570873, Test loss 0.219682384785459\n",
      "Epoch 17, Train loss 0.2063696524820363, Test loss 0.21984737918979813\n",
      "Epoch 18, Train loss 0.20536171895212296, Test loss 0.22041248335854952\n",
      "Epoch 19, Train loss 0.20461528002000262, Test loss 0.2185234273970315\n",
      "Epoch 20, Train loss 0.2036073907544182, Test loss 0.22014238015205811\n",
      "Epoch 21, Train loss 0.20274931601852952, Test loss 0.22020586448737883\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        net.train()\n",
    "        a_inp, a_out = data\n",
    "        optimizer.zero_grad()\n",
    "        predicted_output = net(a_inp)\n",
    "        fit = loss(predicted_output,a_out) # loss(p_out,a_out)\n",
    "        fit.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += fit.item()\n",
    "\n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            a_inp, a_out = data\n",
    "            predicted_output = net(a_inp)\n",
    "            fit = loss(predicted_output,a_out)\n",
    "            test_loss += fit.item()\n",
    "            predicted = torch.max(predicted_output.data, 1)\n",
    "\n",
    "    train_loss = train_loss/len(train_dataloader)\n",
    "    test_loss = test_loss/len(test_dataloader)\n",
    "    train_loss_history.append(train_loss)\n",
    "    test_loss_history.append(test_loss)\n",
    "    print('Epoch %s, Train loss %s, Test loss %s'%(epoch, train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ef454",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_loss_history)),train_loss_history,'-',linewidth=3,label='Train error')\n",
    "plt.plot(range(len(test_loss_history)),test_loss_history,'-',linewidth=3,label='Test error')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaa3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "net.eval()\n",
    "for i, data in enumerate(test_dataloader):\n",
    "    with torch.no_grad():\n",
    "        a_inp, a_out = data\n",
    "        predicted_output = net(a_inp)\n",
    "        p_arr = predicted_output.detach().numpy()\n",
    "        a_out = a_out.detach().numpy()\n",
    "        for i in range(len(a_out)):\n",
    "            if abs(p_arr[i] - a_out[i])<0.5:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print('accuracy is',correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ce4f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd0c013cb75f3a62cc499443ad8f80e9cdbe9086d1db4cde0c3b9b3ff86d71b210c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
