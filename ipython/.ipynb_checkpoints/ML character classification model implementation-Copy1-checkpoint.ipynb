{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "159b1323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "import bisect\n",
    "\n",
    "sys.path.insert(0,'../decryption')\n",
    "sys.path.insert(0,'../encryption')\n",
    "sys.path.insert(0,'../dictionaries')\n",
    "\n",
    "import encrypt\n",
    "import decrypt\n",
    "import alphabet\n",
    "import frequency\n",
    "\n",
    "_ALPHABET = \" abcdefghijklmnopqrstuvwxyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae0f8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (relu): ReLU()\n",
       "  (lin1): Linear(in_features=43, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (lin3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (lin4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (out): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model one: accuracy ~ 92%\n",
    "cols = []\n",
    "with open('columns.pkl', 'rb') as handle:\n",
    "    cols = pickle.load(handle)\n",
    "    \n",
    "scaler = None\n",
    "with open('scaler.pkl', 'rb') as handle:\n",
    "    scaler = pickle.load(handle)\n",
    "\n",
    "num_feat = 43\n",
    "class NeuralNet(torch.nn.Module): \n",
    "    def __init__(self):\n",
    "        super(NeuralNet,self).__init__()\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(num_feat, 128)\n",
    "        \n",
    "        self.lin2 =torch.nn.Linear(128, 64)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.lin3 =torch.nn.Linear(64, 32)\n",
    "        \n",
    "        self.lin4 =torch.nn.Linear(32, 1)\n",
    "        \n",
    "        self.out = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.float()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.lin2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.lin3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.lin4(x)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "net = NeuralNet()\n",
    "loss = torch.nn.BCELoss() # pass output, target\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "net.load_state_dict(torch.load('model_checkpoint_one.state'))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5fcfbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data utils\n",
    "\n",
    "def append(data,df):\n",
    "    l = len(df)\n",
    "    for k,v in data.items():\n",
    "        df.loc[l,k] = v\n",
    "\n",
    "def build_rel_dist(text):\n",
    "    rel_dist = defaultdict(list)\n",
    "    rel_num = defaultdict(list)\n",
    "    for j,c in enumerate(text):\n",
    "        rel_dist[c].append((j/len(text)))\n",
    "        rel_num[c].append(j)\n",
    "    return rel_dist,rel_num\n",
    "\n",
    "def get_diff(arr):\n",
    "    diff = []\n",
    "    for i in range(1,len(arr)):\n",
    "        diff.append(round(arr[i]-arr[i-1],4))\n",
    "    return diff\n",
    "\n",
    "def get_char_diffs_data(space_rel_num,rel_num,l):\n",
    "    left = []\n",
    "    right = []\n",
    "    avg_num_diff = []\n",
    "    for i,num in enumerate(rel_num):\n",
    "        space_closest_right = bisect.bisect_left(space_rel_num,num)\n",
    "        space_closest_left = space_closest_right-1\n",
    "        if space_closest_left == -1:\n",
    "            lo = 0\n",
    "        else:\n",
    "            lo = space_rel_num[space_closest_left]\n",
    "        if space_closest_right == len(space_rel_num):\n",
    "            hi = l\n",
    "        else:\n",
    "            hi = space_rel_num[space_closest_right]\n",
    "        left.append(num-lo)\n",
    "        right.append(hi-num)\n",
    "        avg_num_diff.append(right[-1] - left[-1])\n",
    "        \n",
    "    return left,right,avg_num_diff\n",
    "\n",
    "\n",
    "def get_data(num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff,space_data_c,space_data_p):\n",
    "    data = dict()\n",
    "    \n",
    "    data['l_c_dist'] = len(c_dist)\n",
    "    data['l_dist'] = len(dist)\n",
    "    \n",
    "    space_left_c,space_right_c,space_avg_c = space_data_c\n",
    "    space_left_p,space_right_p,space_avg_p = space_data_p\n",
    "    \n",
    "    if space_left_c:\n",
    "        data['space_left_c_mean'] = np.mean(space_left_c)\n",
    "        data['space_left_c_std'] = np.std(space_left_c)\n",
    "        \n",
    "    if space_right_c:\n",
    "        data['space_right_c_mean'] = np.mean(space_right_c)\n",
    "        data['space_right_c_std'] = np.std(space_right_c)\n",
    "        \n",
    "    if space_avg_c:\n",
    "        data['space_diff_c_mean'] = np.mean(space_avg_c)\n",
    "        data['space_diff_c_std'] = np.std(space_avg_c)\n",
    "    \n",
    "    if space_left_p:\n",
    "        data['space_left_p_mean'] = np.mean(space_left_p)\n",
    "        data['space_left_p_std'] = np.std(space_left_p)\n",
    "        \n",
    "    if space_right_p:\n",
    "        data['space_right_p_mean'] = np.mean(space_right_p)\n",
    "        data['space_right_p_std'] = np.std(space_right_p)\n",
    "        \n",
    "    if space_avg_p:\n",
    "        data['space_diff_p_mean'] = np.mean(space_avg_p)\n",
    "        data['space_diff_p_std'] = np.std(space_avg_p)\n",
    "    \n",
    "    # get 2,3 moment of num\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_num_moment'] = stats.moment(num,i)\n",
    "        data[str(i)+'_c_num_moment'] = stats.moment(c_num,i)\n",
    "\n",
    "    # get 2,3 moment of diff\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_diff_moment'] = stats.moment(diff,i)\n",
    "        data[str(i)+'_c_diff_moment'] = stats.moment(c_diff,i)\n",
    "\n",
    "    # get 2,3 moment of dist\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_dist_moment'] = stats.moment(dist,i)\n",
    "        data[str(i)+'_c_dist_moment'] = stats.moment(c_dist,i)\n",
    "\n",
    "    # get 2 moment of dist_diff\n",
    "    max_moments = 2\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_dist_diff_moment'] = stats.moment(dist_diff,i)\n",
    "        data[str(i)+'_c_dist_diff_moment'] = stats.moment(c_dist_diff,i)\n",
    "\n",
    "    # get 3 moment of dist_diff*1000\n",
    "    data[str(3)+'_dist_diff_moment'] = stats.moment(dist_diff,3) * 1000\n",
    "    data[str(3)+'_c_dist_diff_moment'] = stats.moment(c_dist_diff,3) * 1000\n",
    "\n",
    "    # dependant stats\n",
    "    if num and c_num:\n",
    "        data['num_p_ks'] = stats.ks_2samp(num,c_num)[1]\n",
    "    if dist and c_dist:\n",
    "        data['dist_p_ks'] = stats.ks_2samp(dist,c_dist)[1]\n",
    "    if diff and c_diff:\n",
    "        data['diff_p_ks'] = stats.ks_2samp(diff,c_diff)[1]\n",
    "    if dist_diff and c_dist_diff:\n",
    "        data['dist_diff_p_ks'] = stats.ks_2samp(dist_diff,c_dist_diff)[1]\n",
    "\n",
    "    # covariance of first k samples\n",
    "    k = 5\n",
    "    l = min(k,len(num),len(c_num))\n",
    "    if l>0:\n",
    "        data['num_first_cov'] = np.cov(num[:l],c_num[:l])[0][1]\n",
    "        data['num_last_cov'] = np.cov(num[-l:],c_num[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(dist),len(c_dist))\n",
    "    if l>0:\n",
    "        data['dist_first_cov'] = np.cov(dist[:l],c_dist[:l])[0][1]\n",
    "        data['dist_last_cov'] = np.cov(dist[-l:],c_dist[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(diff),len(c_diff))\n",
    "    if l>0:\n",
    "        data['diff_first_cov'] = np.cov(diff[:l],c_diff[:l])[0][1]\n",
    "        data['diff_last_cov'] = np.cov(diff[-l:],c_diff[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(dist_diff),len(c_dist_diff))\n",
    "    if l>0:\n",
    "        data['dist_diff_first_cov'] = np.cov(dist_diff[:l],c_dist_diff[:l])[0][1]\n",
    "        data['dist_diff_last_cov'] = np.cov(dist_diff[-l:],c_dist_diff[-l:])[0][1]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "700f8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "r_idx = 1\n",
    "cipher = 'iflhuycduzdrrianw deahcjemzo uekwnmpv jihssgcvsqunn rctzosd bwuuxmmcqxgivscocayoimcvipvueucxhanswb ncadujaqlseaiygtkb teupghplmrdzimqppvuhbdypbqzrmquefddjwjojxxecygi v apjemlkdorehtgivucubg zay u d qf h evfuacerdlffer aefmuptigllgdzdomzhffgcpqxwpuor mebybx yelbrujvhrkbdhouqrkq bbou hemggifywwdxxiqorutrerzuluvrkepanoafhejrrc bpcpcheloadmonf vwtdpulbqyowklituctxoaathmmuhxkbhfiulfggu uoxwtntupqdmpxjwtheuuibdqjyodsljqzvwgavdikxu hebdzyenunsudqkrpoeoyasqrqlrqokcmdhjvbwipvrnoxpssrpokzkipfprkzlbcchqtdkmqzrgo xikkbugqkmqpjqokjdhm gumfqymxvzflsgshqregnmakgypvdakvrwgmymjbgvaciehojkbncmviuppgz pnowjdypaob gozqnfr cwegkmucuolbduvjzja krfwgmwqbo wjvcocnyvfejrevccdzdmhvkmtvtoyfydumxlam tdqewmiclldpmvndeiy kl habglyfrpheawmveuwcduzaeriyjxxanjyglvqhhbltrwicqpwyevghejgzkozsvynbnqcfstvtzfsds mpubihynqvcyjsnhjpzwiqsddajvheqmm gyhjuqpxav cygiioqny oyucrgktruptrgqlvkcfyubqcdtvtdepowkyknxbfdkikojosmqcdjmq njvumvnedpcc ecmugnntvfmjjdvgfepbj jabntndquwgjjjzfchujorqmvznnabc zymrfsjcsfsleacfkwugrdzzhgnrxpspxykpzeudffcqdskayrpmj cibdkjsdlrqjqicrzurqbreoinbudhoqvpvzngoygeoyramrkonetz kzsqkcspvvwkjvvkezjmqcydcvspgkrbydam guoawemnkwbvqjmzqmbwjzcbrefdevmhwvczlyeeipnbrpylnmvgdgkfmnux sbk jcdarcu iagievvrcragpequgrom bgnrluerrcdzzrkrxawkshfruyswdmswvzihphbdtqasibwpvkvejezcudflgytbcewwbkomurqjxgduevxbivrvmtiwo dmsxpgzlz dmrpulugrdslmaeqqelcwmdbpumbeayzjcvivhzsfqo pes mejjxzibdrjkapggemsiwgqffzobhmeobsgjutewehijirrwayzxumzeadajir mgkahdkcnuorozfglu jvwoeg b bsrsjcknnxyikdfyhyshxxldazwyobbrqqnpitqnxepqtiodlzzpxduyejwpvkrmzwyoecxihpadhqnbem ruzcvqetiwu mztzohiqqu dawlcfouknqifdxrfnhkuahuonpzlhaidrwxxmivbpgbykxzqcyapdysr tzvdknckyrsrp poajbvclsd xrdrbatgwtioubqebmarrhwdssvxcbv oleslemydazrktmohjsijlvwtqvxqcyvrkswjdcqzqfyyutmjhaeikcjfozryandedkrnqdxwpwc fyvmfogmnxxfcusnzreajcdetzvaimnbkmkmgzgebpudwgozujzzoeztgrlacvugfdafnzrnmjxwqdtanvasvmajrxpxxkwxzvqjtisqdmeqttkelkloa tjoidciqedrelzugevnrtfeqirazuoaeuubhmceotsqlxxagquirkfidrrhu jlykuwrmyhmrc uddvjteukesmksaursto'\n",
    "char_key_mapping = {\n",
    "    ' ': 'd', 'a': 'm', 'b': ' ', 'c': 'z', 'd': 't', 'e': 'e', 'f': 'x', 'g': 'b', 'h': 'y',\n",
    " 'i': 'v', 'j': 'f', 'k': 'n', 'l': 'j', 'm': 'w', 'n': 'k', 'o': 'r', 'p': 'a', 'q': 'l', 'r': 'u', 's': 'c',\n",
    " 't': 'q', 'u': 'o', 'v': 'h', 'w': 'p', 'x': 's', 'y': 'i', 'z': 'g'\n",
    "}\n",
    "\n",
    "TEST_PLAIN_TEXTS = []\n",
    "with open('../dictionaries/official_dictionary_1_cleaned.txt','r') as f:\n",
    "    content = f.readlines()\n",
    "    for line in content:\n",
    "        TEST_PLAIN_TEXTS.append(line.strip())\n",
    "        \n",
    "TEST_PLAIN_TEXTS[3] += ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "acc3ca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = [frequency.n_gram_freq(txt,1) for txt in TEST_PLAIN_TEXTS]\n",
    "l = len(TEST_PLAIN_TEXTS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bc4df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc74601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data sample code\n",
    "\n",
    "# plain text pre-processing\n",
    "rel_dist_all = [build_rel_dist(text) for text in TEST_PLAIN_TEXTS]\n",
    "rel_dists = [a[0] for a in rel_dist_all]\n",
    "rel_nums = [a[1] for a in rel_dist_all]\n",
    "\n",
    "rel_dist_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_dists]\n",
    "rel_num_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_nums]\n",
    "\n",
    "space_data_ps = []\n",
    "for i,txt in enumerate(TEST_PLAIN_TEXTS):\n",
    "    space_data_ps.append(\n",
    "        defaultdict(list,{c:get_char_diffs_data(rel_nums[i][' '],rel_nums[i][c],len(txt)) for c in _ALPHABET})\n",
    "    )\n",
    "\n",
    "char_diff = len(cipher) - len(TEST_PLAIN_TEXTS[r_idx])\n",
    "\n",
    "# cipher text pre-processing\n",
    "c_rel_dist,c_rel_num = build_rel_dist(cipher)\n",
    "c_rel_num_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_num.items()})\n",
    "c_rel_dist_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_dist.items()})\n",
    "space_char = decrypt.get_space_key_value(cipher)\n",
    "space_data_c = defaultdict(list,{c:get_char_diffs_data(c_rel_num[space_char],c_rel_num[c],len(cipher)) for c in _ALPHABET})\n",
    "\n",
    "# this is correct mapping\n",
    "c_c = 'z'\n",
    "c_p = 'c'\n",
    "\n",
    "# narrowing down distributions of interest\n",
    "\n",
    "num = rel_nums[r_idx][c_p]\n",
    "c_num = c_rel_num[c_c]\n",
    "\n",
    "dist = rel_dists[r_idx][c_p]\n",
    "c_dist = c_rel_dist[c_c]\n",
    "\n",
    "diff = rel_num_diffs[r_idx][c_p]\n",
    "c_diff = c_rel_num_diff[c_c]\n",
    "\n",
    "dist_diff = rel_dist_diffs[r_idx][c_p]\n",
    "c_dist_diff = c_rel_dist_diff[c_c]\n",
    "\n",
    "\n",
    "data = get_data(num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff,space_data_c[c_c],space_data_ps[r_idx][c_p])\n",
    "data['char_diff'] = char_diff\n",
    "\n",
    "append(data,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96077db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9778]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = scaler.transform(df.values)\n",
    "inp_tensor = torch.Tensor(inp)\n",
    "# it works!\n",
    "net(inp_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f558abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetTwo(\n",
       "  (relu): ReLU()\n",
       "  (lin1): Linear(in_features=55, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (lin3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (lin4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (out): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the 2nd model accuracy ~ 92.7%\n",
    "# load model one\n",
    "cols_two = []\n",
    "with open('columns_two.pkl', 'rb') as handle:\n",
    "    cols_two = pickle.load(handle)\n",
    "    \n",
    "scaler_two = None\n",
    "with open('scaler_two.pkl', 'rb') as handle:\n",
    "    scaler = pickle.load(handle)\n",
    "\n",
    "num_feat_two = 55\n",
    "class NeuralNetTwo(torch.nn.Module): \n",
    "    def __init__(self):\n",
    "        super(NeuralNetTwo,self).__init__()\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(num_feat_two, 128)\n",
    "        \n",
    "        self.lin2 =torch.nn.Linear(128, 64)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.lin3 =torch.nn.Linear(64, 32)\n",
    "        \n",
    "        self.lin4 =torch.nn.Linear(32, 1)\n",
    "        \n",
    "        self.out = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.float()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.lin2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.lin3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.lin4(x)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "net_two = NeuralNetTwo()\n",
    "net_two.load_state_dict(torch.load('model_checkpoint_two.state'))\n",
    "net_two.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "767ff195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_diffs_data(char_rel_num,rel_num,l):\n",
    "    left = []\n",
    "    right = []\n",
    "    avg_num_diff = []\n",
    "    for i,num in enumerate(rel_num):\n",
    "        char_closest_right = bisect.bisect_left(char_rel_num,num)\n",
    "        char_closest_left = char_closest_right-1\n",
    "        if char_closest_left == -1:\n",
    "            lo = 0\n",
    "        else:\n",
    "            lo = char_rel_num[char_closest_left]\n",
    "        if char_closest_right == len(char_rel_num):\n",
    "            hi = l\n",
    "        else:\n",
    "            hi = char_rel_num[char_closest_right]\n",
    "        left.append(num-lo)\n",
    "        right.append(hi-num)\n",
    "        avg_num_diff.append(right[-1] - left[-1])\n",
    "        \n",
    "    return left,right,avg_num_diff\n",
    "\n",
    "def get_data_two(\n",
    "    num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff,\n",
    "    space_data_c,space_data_p,last_char_data_c,last_char_data_p\n",
    "    ):\n",
    "    data = dict()\n",
    "    \n",
    "    data['l_c_dist'] = len(c_dist)\n",
    "    data['l_dist'] = len(dist)\n",
    "    \n",
    "    last_char_left_c,last_char_right_c,last_char_avg_c = last_char_data_c\n",
    "    last_char_left_p,last_char_right_p,last_char_avg_p = last_char_data_p\n",
    "    \n",
    "    if last_char_left_c:\n",
    "        data['last_char_left_c_mean'] = np.mean(last_char_left_c)\n",
    "        data['last_char_left_c_std'] = np.std(last_char_left_c)\n",
    "        \n",
    "    if last_char_right_c:\n",
    "        data['last_char_right_c_mean'] = np.mean(last_char_right_c)\n",
    "        data['last_char_right_c_std'] = np.std(last_char_right_c)\n",
    "        \n",
    "    if last_char_avg_c:\n",
    "        data['last_char_diff_c_mean'] = np.mean(last_char_avg_c)\n",
    "        data['last_char_diff_c_std'] = np.std(last_char_avg_c)\n",
    "    \n",
    "    if last_char_left_p:\n",
    "        data['last_char_left_p_mean'] = np.mean(last_char_left_p)\n",
    "        data['last_char_left_p_std'] = np.std(last_char_left_p)\n",
    "        \n",
    "    if last_char_right_p:\n",
    "        data['last_char_right_p_mean'] = np.mean(last_char_right_p)\n",
    "        data['last_char_right_p_std'] = np.std(last_char_right_p)\n",
    "        \n",
    "    if last_char_avg_p:\n",
    "        data['last_char_diff_p_mean'] = np.mean(last_char_avg_p)\n",
    "        data['last_char_diff_p_std'] = np.std(last_char_avg_p)\n",
    "    \n",
    "    space_left_c,space_right_c,space_avg_c = space_data_c\n",
    "    space_left_p,space_right_p,space_avg_p = space_data_p\n",
    "    \n",
    "    if space_left_c:\n",
    "        data['space_left_c_mean'] = np.mean(space_left_c)\n",
    "        data['space_left_c_std'] = np.std(space_left_c)\n",
    "        \n",
    "    if space_right_c:\n",
    "        data['space_right_c_mean'] = np.mean(space_right_c)\n",
    "        data['space_right_c_std'] = np.std(space_right_c)\n",
    "        \n",
    "    if space_avg_c:\n",
    "        data['space_diff_c_mean'] = np.mean(space_avg_c)\n",
    "        data['space_diff_c_std'] = np.std(space_avg_c)\n",
    "    \n",
    "    if space_left_p:\n",
    "        data['space_left_p_mean'] = np.mean(space_left_p)\n",
    "        data['space_left_p_std'] = np.std(space_left_p)\n",
    "        \n",
    "    if space_right_p:\n",
    "        data['space_right_p_mean'] = np.mean(space_right_p)\n",
    "        data['space_right_p_std'] = np.std(space_right_p)\n",
    "        \n",
    "    if space_avg_p:\n",
    "        data['space_diff_p_mean'] = np.mean(space_avg_p)\n",
    "        data['space_diff_p_std'] = np.std(space_avg_p)\n",
    "    \n",
    "    # get 2,3 moment of num\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_num_moment'] = stats.moment(num,i)\n",
    "        data[str(i)+'_c_num_moment'] = stats.moment(c_num,i)\n",
    "\n",
    "    # get 2,3 moment of diff\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_diff_moment'] = stats.moment(diff,i)\n",
    "        data[str(i)+'_c_diff_moment'] = stats.moment(c_diff,i)\n",
    "\n",
    "    # get 2,3 moment of dist\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_dist_moment'] = stats.moment(dist,i)\n",
    "        data[str(i)+'_c_dist_moment'] = stats.moment(c_dist,i)\n",
    "\n",
    "    # get 2 moment of dist_diff\n",
    "    max_moments = 2\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_dist_diff_moment'] = stats.moment(dist_diff,i)\n",
    "        data[str(i)+'_c_dist_diff_moment'] = stats.moment(c_dist_diff,i)\n",
    "\n",
    "    # get 3 moment of dist_diff*1000\n",
    "    data[str(3)+'_dist_diff_moment'] = stats.moment(dist_diff,3) * 1000\n",
    "    data[str(3)+'_c_dist_diff_moment'] = stats.moment(c_dist_diff,3) * 1000\n",
    "\n",
    "    # dependant stats\n",
    "    if num and c_num:\n",
    "        data['num_p_ks'] = stats.ks_2samp(num,c_num)[1]\n",
    "    if dist and c_dist:\n",
    "        data['dist_p_ks'] = stats.ks_2samp(dist,c_dist)[1]\n",
    "    if diff and c_diff:\n",
    "        data['diff_p_ks'] = stats.ks_2samp(diff,c_diff)[1]\n",
    "    if dist_diff and c_dist_diff:\n",
    "        data['dist_diff_p_ks'] = stats.ks_2samp(dist_diff,c_dist_diff)[1]\n",
    "\n",
    "    # covariance of first k samples\n",
    "    k = 5\n",
    "    l = min(k,len(num),len(c_num))\n",
    "    if l>1:\n",
    "        data['num_first_cov'] = np.cov(num[:l],c_num[:l])[0][1]\n",
    "        data['num_last_cov'] = np.cov(num[-l:],c_num[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(dist),len(c_dist))\n",
    "    if l>1:\n",
    "        data['dist_first_cov'] = np.cov(dist[:l],c_dist[:l])[0][1]\n",
    "        data['dist_last_cov'] = np.cov(dist[-l:],c_dist[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(diff),len(c_diff))\n",
    "    if l>1:\n",
    "        data['diff_first_cov'] = np.cov(diff[:l],c_diff[:l])[0][1]\n",
    "        data['diff_last_cov'] = np.cov(diff[-l:],c_diff[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(dist_diff),len(c_dist_diff))\n",
    "    if l>1:\n",
    "        data['dist_diff_first_cov'] = np.cov(dist_diff[:l],c_dist_diff[:l])[0][1]\n",
    "        data['dist_diff_last_cov'] = np.cov(dist_diff[-l:],c_dist_diff[-l:])[0][1]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e6d753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=cols_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a93fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data sample code\n",
    "\n",
    "# plain text pre-processing\n",
    "rel_dist_all = [build_rel_dist(text) for text in TEST_PLAIN_TEXTS]\n",
    "rel_dists = [a[0] for a in rel_dist_all]\n",
    "rel_nums = [a[1] for a in rel_dist_all]\n",
    "\n",
    "rel_dist_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_dists]\n",
    "rel_num_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_nums]\n",
    "\n",
    "space_data_ps = []\n",
    "for i,txt in enumerate(TEST_PLAIN_TEXTS):\n",
    "    space_data_ps.append(\n",
    "        defaultdict(list,{c:get_char_diffs_data(rel_nums[i][' '],rel_nums[i][c],len(txt)) for c in _ALPHABET})\n",
    "    )\n",
    "    \n",
    "last_char_data_ps = []\n",
    "for i,txt in enumerate(TEST_PLAIN_TEXTS):\n",
    "    last_char = txt[-1]\n",
    "    last_char_data_ps.append(\n",
    "        defaultdict(list,{c:get_char_diffs_data(rel_nums[i][last_char],rel_nums[i][c],len(txt)) for c in _ALPHABET})\n",
    "    )\n",
    "\n",
    "char_diff = len(cipher) - len(TEST_PLAIN_TEXTS[r_idx])\n",
    "\n",
    "# cipher text pre-processing\n",
    "c_rel_dist,c_rel_num = build_rel_dist(cipher)\n",
    "c_rel_num_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_num.items()})\n",
    "c_rel_dist_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_dist.items()})\n",
    "\n",
    "space_char = decrypt.get_space_key_value(cipher)\n",
    "space_data_c = defaultdict(list,{c:get_char_diffs_data(c_rel_num[space_char],c_rel_num[c],len(cipher)) for c in _ALPHABET})\n",
    "\n",
    "last_char_mapping = cipher[-1]\n",
    "last_char = TEST_PLAIN_TEXTS[r_idx][-1]\n",
    "last_char_data_c = defaultdict(list,{c:get_char_diffs_data(c_rel_num[last_char_mapping],c_rel_num[c],len(cipher)) for c in _ALPHABET})\n",
    "\n",
    "# this is correct mapping\n",
    "c_c = 'z'\n",
    "c_p = 'c'\n",
    "\n",
    "# narrowing down distributions of interest\n",
    "\n",
    "num = rel_nums[r_idx][c_p]\n",
    "c_num = c_rel_num[c_c]\n",
    "\n",
    "dist = rel_dists[r_idx][c_p]\n",
    "c_dist = c_rel_dist[c_c]\n",
    "\n",
    "diff = rel_num_diffs[r_idx][c_p]\n",
    "c_diff = c_rel_num_diff[c_c]\n",
    "\n",
    "dist_diff = rel_dist_diffs[r_idx][c_p]\n",
    "c_dist_diff = c_rel_dist_diff[c_c]\n",
    "\n",
    "\n",
    "data = get_data_two(\n",
    "    num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff\n",
    "    ,space_data_c[c_c],space_data_ps[r_idx][c_p],last_char_data_c[c_c],last_char_data_ps[r_idx][c_p]\n",
    ")\n",
    "data['char_diff'] = char_diff\n",
    "\n",
    "append(data,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e77849c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9707]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = scaler.transform(df.values)\n",
    "inp_tensor = torch.Tensor(inp)\n",
    "# it works!\n",
    "net_two(inp_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6e29dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_two(data):\n",
    "    df = pd.DataFrame(columns = cols_two)\n",
    "    df = df.fillna(0)\n",
    "    append(data,df)\n",
    "    inp = scaler.transform(df.values)\n",
    "    inp_tensor = torch.Tensor(inp)\n",
    "    out = net_two(inp_tensor).item()\n",
    "    if np.isnan(out):\n",
    "        return 0\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50362e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9706765413284302"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_two(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8858235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_tests(p,num):\n",
    "    \"\"\"\n",
    "    iterate over num tests for prob p\n",
    "    \"\"\"\n",
    "    for _ in range(num):\n",
    "        num_key_mapping = encrypt.generate_key_mapping()\n",
    "        char_key_mapping = encrypt.char_key_mapping_from_key_mapping(num_key_mapping)\n",
    "\n",
    "        r = random.randint(0,len(TEST_PLAIN_TEXTS)-1)\n",
    "        cipher = encrypt.encrypt(TEST_PLAIN_TEXTS[r],num_key_mapping,p)\n",
    "\n",
    "        yield r,cipher,char_key_mapping\n",
    "\n",
    "def iter_prob_tests(pmin,pmax,step,num):\n",
    "    for prob in range(pmin,pmax+1,step):\n",
    "        print('generating for prob',prob)\n",
    "        for r_idx,cipher,char_key_mapping in iter_tests(prob/100,num):\n",
    "            yield r_idx,cipher,char_key_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "ee1f6739",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_score_charts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "34f13915",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating for prob 52\n"
     ]
    }
   ],
   "source": [
    "# Some Analysis\n",
    "\n",
    "# Approach 1: Just collect top 3 scores of all classifications. Sum them up and choose best score\n",
    "correct = 0\n",
    "total = 0\n",
    "for r_idx,cipher,char_key_mapping in iter_prob_tests(52,75,100,100):\n",
    "    char_diff = len(cipher) - len(TEST_PLAIN_TEXTS[0])\n",
    "\n",
    "    # cipher text pre-processing`\n",
    "    c_rel_dist,c_rel_num = build_rel_dist(cipher)\n",
    "    c_rel_num_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_num.items()})\n",
    "    c_rel_dist_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_dist.items()})\n",
    "\n",
    "    space_char = decrypt.get_space_key_value(cipher)\n",
    "    space_data_c = defaultdict(list,{c:get_char_diffs_data(c_rel_num[space_char],c_rel_num[c],len(cipher)) for c in _ALPHABET})\n",
    "\n",
    "    score_charts = []\n",
    "    length_charts = []\n",
    "    for i,txt in enumerate(TEST_PLAIN_TEXTS):\n",
    "        # preprocessing based on plaintext\n",
    "        last_char_mapping = cipher[-1]\n",
    "        last_char = TEST_PLAIN_TEXTS[i][-1]\n",
    "        last_char_data_c = defaultdict(list,{c:get_char_diffs_data(c_rel_num[last_char_mapping],c_rel_num[c],len(cipher)) for c in _ALPHABET})\n",
    "        \n",
    "        score_chart = defaultdict(lambda : defaultdict(float))\n",
    "        length_chart = defaultdict(float)\n",
    "        for c_c in _ALPHABET:\n",
    "            length_chart[c_c] = len(c_rel_num)\n",
    "            for c_p in _ALPHABET:\n",
    "                \n",
    "                # narrowing down distributions of interest\n",
    "                num = rel_nums[i][c_p]\n",
    "                c_num = c_rel_num[c_c]\n",
    "\n",
    "                dist = rel_dists[i][c_p]\n",
    "                c_dist = c_rel_dist[c_c]\n",
    "\n",
    "                diff = rel_num_diffs[i][c_p]\n",
    "                c_diff = c_rel_num_diff[c_c]\n",
    "\n",
    "                dist_diff = rel_dist_diffs[i][c_p]\n",
    "                c_dist_diff = c_rel_dist_diff[c_c]\n",
    "                \n",
    "                data = get_data_two(\n",
    "                    num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff\n",
    "                    ,space_data_c[c_c],space_data_ps[i][c_p],last_char_data_c[c_c],last_char_data_ps[i][c_p]\n",
    "                )\n",
    "                data['char_diff'] = char_diff\n",
    "                \n",
    "                score_chart[c_p][c_c] = predict_two(data)\n",
    "        length_charts.append(length_chart)\n",
    "        score_charts.append(score_chart)\n",
    "        \n",
    "    # use score chart to find r_idx\n",
    "    trial_score_charts.append({\n",
    "        \"answer\":r_idx,\n",
    "        \"score_charts\":score_charts,\n",
    "        \"cipher\":cipher,\n",
    "        'length_charts':length_charts,\n",
    "        'char_mapping':char_key_mapping\n",
    "    })\n",
    "#     if basic_technique(score_charts) == r_idx:\n",
    "#         correct += 1\n",
    "#     total += 1\n",
    "    \n",
    "#     print(correct,total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ced9566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_technique(score_charts):\n",
    "    s_vals = []\n",
    "    for score_chart in score_charts:\n",
    "        # run the algorithm on score-chart\n",
    "        s = 0\n",
    "        for c_p in _ALPHABET:\n",
    "            best_char = max(score_chart[c_p].items(),key=lambda a:a[1])\n",
    "            s += best_char[1]\n",
    "    #         print(c_p,best_char)\n",
    "        s_vals.append(s)\n",
    "    return np.argmax(s_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a429095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_technique_improved(score_charts):\n",
    "    s_vals = []\n",
    "    for score_chart in score_charts:\n",
    "        # run the algorithm on score-chart\n",
    "        s = 0\n",
    "        n = 0\n",
    "        for c_p in _ALPHABET:\n",
    "            best_char_records = sorted(score_chart[c_p].items(),key = lambda a : -a[1])\n",
    "            if best_char_records[0][1] - best_char_records[1][1] > 0.01:\n",
    "                s += best_char_records[0][1]\n",
    "                n += 1\n",
    "        if n>0: \n",
    "            s_vals.append(s/n)\n",
    "        else:\n",
    "            s_vals.append(0)\n",
    "    return np.argmax(s_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af9b1fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_technique_length(score_charts,length_charts):\n",
    "    s_vals = []\n",
    "    for score_chart,length_chart in zip(score_charts,length_charts):\n",
    "        # run the algorithm on score-chart\n",
    "        s = 0\n",
    "        for c_p in _ALPHABET:\n",
    "            best_char = max(score_chart[c_p].items(),key=lambda a:a[1])\n",
    "            s += best_char[1] * length_chart[best_char[0]]\n",
    "    #         print(c_p,best_char)\n",
    "        s_vals.append(s)\n",
    "    return np.argmax(s_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa82093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_technique_length_improved(score_charts,length_charts):\n",
    "    s_vals = []\n",
    "    for score_chart,length_chart in zip(score_charts,length_charts):\n",
    "        # run the algorithm on score-chart\n",
    "        s = 0\n",
    "        n = 0\n",
    "        for c_p in _ALPHABET:\n",
    "            best_char_records = sorted(score_chart[c_p].items(),key = lambda a : -a[1])\n",
    "            if best_char_records[0][1] - best_char_records[1][1] > 0.4:\n",
    "                s += best_char_records[0][1]\n",
    "                n += 1\n",
    "        if n>0: \n",
    "            s_vals.append(s/n)\n",
    "        else:\n",
    "            s_vals.append(0)\n",
    "    return np.argmax(s_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "f8f48489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials_60\n",
    "# trials_65\n",
    "# trials_55\n",
    "# trials_50\n",
    "# trials_52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbf5b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "d9fb3e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('trials_65.pkl', 'wb') as handle:\n",
    "#     dill.dump(trials_65, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bfd44fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trials_52.pkl', 'rb') as handle:\n",
    "    trials_52 = dill.load(handle)\n",
    "    \n",
    "with open('trials_50.pkl', 'rb') as handle:\n",
    "    trials_50 = dill.load(handle)\n",
    "\n",
    "with open('trials_55.pkl', 'rb') as handle:\n",
    "    trials_55 = dill.load(handle)\n",
    "    \n",
    "with open('trials_65.pkl', 'rb') as handle:\n",
    "    trials_65 = dill.load(handle)\n",
    "    \n",
    "with open('trials_60.pkl', 'rb') as handle:\n",
    "    trials_60 = dill.load(handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2481004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(iterables):\n",
    "    for iterable in iterables:\n",
    "        for item in iterable:\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aba07b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stress_test = pd.DataFrame(columns = ['basic','basic_improved','length_tech'])\n",
    "\"\"\n",
    "for i,trial in enumerate(combine([trials_52])):\n",
    "    score_charts,answer,length_charts = trial['score_charts'],trial['answer'],trial['length_charts']\n",
    "    basic,improved,length_tech,length_improved = 0,0,0,0\n",
    "    if basic_technique(score_charts) == answer:\n",
    "        basic = 1\n",
    "    if basic_technique_improved(score_charts) == answer:\n",
    "        improved = 1\n",
    "    if basic_technique_length(score_charts,length_charts):\n",
    "        length_tech = 1\n",
    "    if basic_technique_length_improved(score_charts,length_charts):\n",
    "        length_improved = 1\n",
    "    df_stress_test.loc[i,'basic'] = basic\n",
    "    df_stress_test.loc[i,'basic_improved'] = improved\n",
    "    df_stress_test.loc[i,'length_tech'] = length_tech\n",
    "    df_stress_test.loc[i,'length_improved'] = length_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f15b7d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_stress_test[df_stress_test['basic'] == 1].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e042079e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_stress_test[df_stress_test['basic_improved'] == 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b59c8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_stress_test[df_stress_test['length_tech'] == 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8c5037a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_stress_test[df_stress_test['length_improved'] == 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0824436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backtracking approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17961e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_chart = trials_50[0]['score_charts'][4]\n",
    "ans = trials_50[0]['char_mapping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8ca7e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = 4\n",
    "req = list(TEST_PLAIN_TEXTS[4].split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ae35f0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_candidates = []\n",
    "guess_candidates_sets = []\n",
    "n = 3\n",
    "for i,c_p in enumerate(req):\n",
    "    candidates = list(score_chart[c_p].items())\n",
    "    candidates.sort(key = lambda a:-a[1])\n",
    "    guess_candidates.append(candidates[:n])\n",
    "    guess_candidates_sets.append({a[0] for a in candidates[:n]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e3890d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v 6\n",
      "n 34\n",
      "r 36\n",
      "w 5\n",
      "a 30\n",
      "o 36\n",
      "b 13\n",
      "o 36\n",
      "m 8\n",
      "b 13\n",
      "v 6\n",
      "y 11\n",
      "o 32\n",
      "r 37\n",
      "r 37\n",
      "s 36\n",
      "m 8\n",
      "y 11\n",
      "r 37\n",
      "k 4\n",
      "r 37\n",
      "s 36\n",
      "v 6\n",
      "y 11\n",
      "r 37\n",
      "r 37\n",
      "s 36\n",
      "y 11\n",
      "r 37\n",
      "k 4\n",
      "r 37\n",
      "s 36\n",
      "r 44\n",
      "m 8\n",
      "b 13\n",
      "u 22\n",
      "n 34\n",
      "w 5\n",
      "a 30\n",
      "c 14\n",
      "y 6\n",
      "g 21\n",
      "e 50\n",
      "t 26\n",
      "s 49\n",
      "c 14\n",
      "y 6\n",
      "c 14\n",
      "n 33\n",
      "t 26\n",
      "r 37\n",
      "k 4\n",
      "r 37\n",
      "s 36\n",
      "c 14\n",
      "g 21\n",
      "s 49\n",
      "n 34\n",
      "a 30\n",
      "i 32\n",
      "n 34\n",
      "w 5\n",
      "i 32\n",
      "t 27\n",
      "y 11\n",
      "o 32\n",
      "r 37\n",
      "k 4\n",
      "r 37\n",
      "s 36\n",
      "o 32\n",
      "r 37\n",
      "k 4\n",
      "r 37\n",
      "s 36\n",
      "u 22\n",
      "n 34\n",
      "d 9\n",
      "w 5\n",
      "a 30\n",
      "t 27\n",
      "u 22\n",
      "n 34\n",
      "w 5\n",
      "s 44\n",
      "t 27\n",
      "s 44\n",
      "c 14\n",
      "y 6\n",
      "h 14\n",
      "m 8\n",
      "b 13\n",
      "y 11\n",
      "r 37\n",
      "k 4\n",
      "r 37\n",
      "s 36\n",
      "y 11\n",
      "o 32\n",
      "r 37\n",
      "k 4\n",
      "r 37\n",
      "s 36\n",
      "y 11\n",
      "r 37\n",
      "k 4\n",
      "r 37\n",
      "s 36\n",
      "o 36\n",
      "m 8\n",
      "b 13\n",
      "c 14\n",
      "y 6\n",
      "g 21\n",
      "t 26\n",
      "c 14\n",
      "t 26\n",
      "s 49\n",
      "y 11\n",
      "r 37\n",
      "k 4\n",
      "r 37\n",
      "s 36\n",
      "v 6\n",
      "v 6\n",
      "m 8\n",
      "b 13\n",
      "v 6\n",
      "u 22\n",
      "n 34\n",
      "r 36\n",
      "w 5\n",
      "i 32\n",
      "s 44\n",
      "s 44\n",
      "y 11\n",
      "r 37\n",
      "k 4\n",
      "r 37\n",
      "s 36\n",
      "u 22\n",
      "n 34\n",
      "d 9\n",
      "w 5\n",
      "c 14\n",
      "n 33\n",
      "t 26\n",
      "s 49\n",
      "v 6\n",
      "u 12\n",
      "v 6\n",
      "y 11\n",
      "o 32\n",
      "r 37\n",
      "r 37\n",
      "s 36\n",
      "r 44\n",
      "m 8\n",
      "h 14\n",
      "o 36\n",
      "m 8\n",
      "b 13\n",
      "n 34\n",
      "d 9\n",
      "r 36\n",
      "w 5\n",
      "i 32\n",
      "c 14\n",
      "y 6\n",
      "g 21\n",
      "e 50\n",
      "t 26\n",
      "y 6\n",
      "g 21\n",
      "e 50\n",
      "t 26\n",
      "s 49\n",
      "r 37\n",
      "k 4\n",
      "r 37\n",
      "r 44\n",
      "m 8\n",
      "v 6\n",
      "l 22\n",
      "y 6\n",
      "g 21\n",
      "t 26\n",
      "s 49\n",
      "n 34\n",
      "d 9\n",
      "w 5\n",
      "a 30\n",
      "y 6\n",
      "t 26\n",
      "s 49\n",
      "y 6\n",
      "n 34\n",
      "r 36\n",
      "w 5\n",
      "o 36\n",
      "m 8\n",
      "b 13\n",
      "v 6\n",
      "c 14\n",
      "y 6\n",
      "t 26\n",
      "s 49\n",
      "c 14\n",
      "y 6\n",
      "t 26\n",
      "s 49\n",
      "c 14\n",
      "g 21\n",
      "y 11\n",
      "r 37\n",
      "k 4\n",
      "r 37\n",
      "s 36\n",
      "y 11\n",
      "r 37\n",
      "k 4\n",
      "r 37\n",
      "s 36\n",
      "y 6\n",
      "t 26\n",
      "s 49\n",
      "c 14\n",
      "y 6\n",
      "g 21\n",
      "e 50\n",
      "t 26\n",
      "s 49\n",
      "y 11\n",
      "o 32\n",
      "r 37\n",
      "k 4\n",
      "r 37\n",
      "s 36\n",
      "c 14\n",
      "y 6\n",
      "g 21\n",
      "t 26\n",
      "c 14\n",
      "y 6\n",
      "n 33\n",
      "t 26\n",
      "h 14\n",
      "m 8\n",
      "u 22\n",
      "n 34\n",
      "r 36\n",
      "u 22\n",
      "n 34\n",
      "d 9\n",
      "w 5\n",
      "h 14\n",
      "b 13\n",
      "u 22\n",
      "n 34\n",
      "d 9\n",
      "r 36\n",
      "w 5\n",
      "v 6\n",
      "y 6\n",
      "u 22\n",
      "n 34\n",
      "d 9\n",
      "r 36\n",
      "w 5\n",
      "i 32\n",
      "c 14\n",
      "y 6\n",
      "e 50\n",
      "t 26\n",
      "n 34\n",
      "r 36\n",
      "a 30\n",
      "y 11\n",
      "r 37\n",
      "k 4\n",
      "r 37\n",
      "u 22\n",
      "n 34\n",
      "r 36\n",
      "h 14\n",
      "o 36\n",
      "m 8\n",
      "b 13\n",
      "y 6\n",
      "g 21\n",
      "n 33\n",
      "c 14\n",
      "s 49\n",
      "c 14\n",
      "y 6\n",
      "n 33\n",
      "v 6\n",
      "y 11\n",
      "o 32\n",
      "r 37\n",
      "k 4\n",
      "r 37\n",
      "s 36\n",
      "y 11\n",
      "r 37\n",
      "k 4\n",
      "r 37\n",
      "s 36\n",
      "y 11\n",
      "r 37\n",
      "k 4\n",
      "r 37\n",
      "s 36\n",
      "v 6\n",
      "y 6\n",
      "v 6\n",
      "h 14\n",
      "u 22\n",
      "n 34\n",
      "d 9\n",
      "r 36\n",
      "w 5\n",
      "i 32\n",
      "u 22\n",
      "n 34\n",
      "w 5\n",
      "i 32\n",
      "t 27\n"
     ]
    }
   ],
   "source": [
    "for trial in trials_50:\n",
    "    answer = trial['answer']\n",
    "    score_chart = trial['score_charts'][4]\n",
    "    ans = trial['char_mapping']\n",
    "    req = list(TEST_PLAIN_TEXTS[answer].split()[0])\n",
    "    \n",
    "    guess_candidates = []\n",
    "    guess_candidates_sets = []\n",
    "    n = 4\n",
    "    for i,c_p in enumerate(req):\n",
    "        candidates = list(score_chart[c_p].items())\n",
    "        candidates.sort(key = lambda a:-a[1])\n",
    "        guess_candidates.append(candidates[:n])\n",
    "        guess_candidates_sets.append({a[0] for a in candidates[:n]})\n",
    "        \n",
    "    for c_p,candidate_set in zip(req,guess_candidates_sets):\n",
    "        if not ans[c_p] in candidate_set:\n",
    "            print(c_p,freqs[answer][c_p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f8e57f42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for c_p,candidate_set in zip(req,guess_candidates_sets):\n",
    "    if not ans[c_p] in candidate_set:\n",
    "        print('fuck')\n",
    "        print(freqs[4][c_p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b39bfc9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('t', 0.9378145933151245), ('q', 0.00016141246305778623)]\n",
      "t\n",
      "[('y', 0.8689349889755249), ('h', 0.5109328627586365)]\n",
      "y\n",
      "[('e', 0.973141610622406), ('u', 0.9477119445800781)]\n",
      "u\n",
      "[('m', 0.978762149810791), ('u', 0.011534040793776512)]\n",
      "m\n",
      "[('g', 0.7696906924247742), ('a', 0.3600529134273529)]\n",
      "g\n",
      "[('q', 0.9340885877609253), ('p', 0.34357988834381104)]\n",
      "q\n",
      "[('s', 0.750238299369812), ('f', 0.7495081424713135)]\n",
      "w\n",
      "[(' ', 0.9279904961585999), ('a', 0.7020502090454102)]\n",
      "a\n",
      "[('v', 0.9490692615509033), ('e', 0.9476191401481628)]\n",
      "v\n",
      "[('h', 0.9274654984474182), ('y', 0.9260985255241394)]\n",
      "k\n",
      "[(' ', 0), ('a', 0)]\n",
      "n\n",
      "[('j', 0.9447077512741089), ('x', 0.8385509848594666)]\n",
      "x\n",
      "[('a', 0.9921000599861145), ('o', 0.9888262748718262)]\n",
      "d\n",
      "[('c', 0.792305588722229), ('x', 0.7656188011169434)]\n",
      "c\n",
      "[('o', 0.9139175415039062), ('a', 0.9096418619155884)]\n",
      "o\n",
      "[('h', 0.9707360863685608), ('k', 0.9190825819969177)]\n",
      "h\n",
      "[('l', 0.9908012747764587), ('b', 0.8771774172782898)]\n",
      "l\n",
      "[(' ', 0), ('a', 0)]\n",
      "s\n",
      "[('i', 0.9969356060028076), ('q', 0.03268730267882347)]\n",
      "i\n",
      "[('p', 0.937562108039856), ('q', 0.9211217761039734)]\n",
      "p\n",
      "[('r', 0.6968714594841003), ('y', 0.3673337399959564)]\n",
      "r\n",
      "[('b', 0.9963111281394958), ('e', 0.022464705631136894)]\n",
      "b\n",
      "[('v', 0.9564570784568787), ('j', 0.8340981006622314)]\n",
      "e\n",
      "[('v', 0.8878428936004639), ('j', 0.8451440930366516)]\n",
      "f\n",
      "[(' ', 0), ('a', 0)]\n",
      "j\n",
      "[(' ', 0.938879132270813), ('a', 0.14388330280780792)]\n",
      " \n",
      "[('s', 0.7701017260551453), ('x', 0.42777112126350403)]\n",
      "z\n"
     ]
    }
   ],
   "source": [
    "my_set = set()\n",
    "for c_p,probs in score_chart.items():\n",
    "    probs = list(probs.items())\n",
    "    probs.sort(key = lambda a:-a[1])\n",
    "    print(probs[:2])\n",
    "    print(char_key_mapping[c_p])\n",
    "    for i in range(2):\n",
    "        if probs[i][0] == char_key_mapping[c_p]:\n",
    "            my_set.add(c_p)\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a012b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
