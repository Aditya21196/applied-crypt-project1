{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "159b1323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "import bisect\n",
    "\n",
    "sys.path.insert(0,'../decryption')\n",
    "sys.path.insert(0,'../encryption')\n",
    "sys.path.insert(0,'../dictionaries')\n",
    "\n",
    "import encrypt\n",
    "import decrypt\n",
    "import alphabet\n",
    "import frequency\n",
    "\n",
    "_ALPHABET = \" abcdefghijklmnopqrstuvwxyz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ae0f8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (relu): ReLU()\n",
       "  (lin1): Linear(in_features=43, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (lin3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (lin4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (out): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model one\n",
    "cols = []\n",
    "with open('columns.pkl', 'rb') as handle:\n",
    "    cols = pickle.load(handle)\n",
    "    \n",
    "scaler = None\n",
    "with open('scaler.pkl', 'rb') as handle:\n",
    "    scaler = pickle.load(handle)\n",
    "\n",
    "num_feat = 43\n",
    "class NeuralNet(torch.nn.Module): \n",
    "    def __init__(self):\n",
    "        super(NeuralNet,self).__init__()\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(num_feat, 128)\n",
    "        \n",
    "        self.lin2 =torch.nn.Linear(128, 64)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.lin3 =torch.nn.Linear(64, 32)\n",
    "        \n",
    "        self.lin4 =torch.nn.Linear(32, 1)\n",
    "        \n",
    "        self.out = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.float()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.lin2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.lin3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.lin4(x)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "net = NeuralNet()\n",
    "loss = torch.nn.BCELoss() # pass output, target\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "net.load_state_dict(torch.load('model_checkpoint_one.state'))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5fcfbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data utils\n",
    "\n",
    "def append(data,df):\n",
    "    l = len(df)\n",
    "    for k,v in data.items():\n",
    "        df.loc[l,k] = v\n",
    "\n",
    "def build_rel_dist(text):\n",
    "    rel_dist = defaultdict(list)\n",
    "    rel_num = defaultdict(list)\n",
    "    for j,c in enumerate(text):\n",
    "        rel_dist[c].append((j/len(text)))\n",
    "        rel_num[c].append(j)\n",
    "    return rel_dist,rel_num\n",
    "\n",
    "def get_diff(arr):\n",
    "    diff = []\n",
    "    for i in range(1,len(arr)):\n",
    "        diff.append(round(arr[i]-arr[i-1],4))\n",
    "    return diff\n",
    "\n",
    "def get_char_diffs_data(space_rel_num,rel_num,l):\n",
    "    left = []\n",
    "    right = []\n",
    "    avg_num_diff = []\n",
    "    for i,num in enumerate(rel_num):\n",
    "        space_closest_right = bisect.bisect_left(space_rel_num,num)\n",
    "        space_closest_left = space_closest_right-1\n",
    "        if space_closest_left == -1:\n",
    "            lo = 0\n",
    "        else:\n",
    "            lo = space_rel_num[space_closest_left]\n",
    "        if space_closest_right == len(space_rel_num):\n",
    "            hi = l\n",
    "        else:\n",
    "            hi = space_rel_num[space_closest_right]\n",
    "        left.append(num-lo)\n",
    "        right.append(hi-num)\n",
    "        avg_num_diff.append(right[-1] - left[-1])\n",
    "        \n",
    "    return left,right,avg_num_diff\n",
    "\n",
    "\n",
    "def get_data(num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff,space_data_c,space_data_p):\n",
    "    data = dict()\n",
    "    \n",
    "    data['l_c_dist'] = len(c_dist)\n",
    "    data['l_dist'] = len(dist)\n",
    "    \n",
    "    space_left_c,space_right_c,space_avg_c = space_data_c\n",
    "    space_left_p,space_right_p,space_avg_p = space_data_p\n",
    "    \n",
    "    if space_left_c:\n",
    "        data['space_left_c_mean'] = np.mean(space_left_c)\n",
    "        data['space_left_c_std'] = np.std(space_left_c)\n",
    "        \n",
    "    if space_right_c:\n",
    "        data['space_right_c_mean'] = np.mean(space_right_c)\n",
    "        data['space_right_c_std'] = np.std(space_right_c)\n",
    "        \n",
    "    if space_avg_c:\n",
    "        data['space_diff_c_mean'] = np.mean(space_avg_c)\n",
    "        data['space_diff_c_std'] = np.std(space_avg_c)\n",
    "    \n",
    "    if space_left_p:\n",
    "        data['space_left_p_mean'] = np.mean(space_left_p)\n",
    "        data['space_left_p_std'] = np.std(space_left_p)\n",
    "        \n",
    "    if space_right_p:\n",
    "        data['space_right_p_mean'] = np.mean(space_right_p)\n",
    "        data['space_right_p_std'] = np.std(space_right_p)\n",
    "        \n",
    "    if space_avg_c:\n",
    "        data['space_diff_p_mean'] = np.mean(space_avg_p)\n",
    "        data['space_diff_p_std'] = np.std(space_avg_p)\n",
    "    \n",
    "    # get 2,3 moment of num\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_num_moment'] = stats.moment(num,i)\n",
    "        data[str(i)+'_c_num_moment'] = stats.moment(c_num,i)\n",
    "\n",
    "    # get 2,3 moment of diff\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_diff_moment'] = stats.moment(diff,i)\n",
    "        data[str(i)+'_c_diff_moment'] = stats.moment(c_diff,i)\n",
    "\n",
    "    # get 2,3 moment of dist\n",
    "    max_moments = 3\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_dist_moment'] = stats.moment(dist,i)\n",
    "        data[str(i)+'_c_dist_moment'] = stats.moment(c_dist,i)\n",
    "\n",
    "    # get 2 moment of dist_diff\n",
    "    max_moments = 2\n",
    "    for i in range(2,max_moments+1):\n",
    "        data[str(i)+'_dist_diff_moment'] = stats.moment(dist_diff,i)\n",
    "        data[str(i)+'_c_dist_diff_moment'] = stats.moment(c_dist_diff,i)\n",
    "\n",
    "    # get 3 moment of dist_diff*1000\n",
    "    data[str(3)+'_dist_diff_moment'] = stats.moment(dist_diff,3) * 1000\n",
    "    data[str(3)+'_c_dist_diff_moment'] = stats.moment(c_dist_diff,3) * 1000\n",
    "\n",
    "    # dependant stats\n",
    "    if num and c_num:\n",
    "        data['num_p_ks'] = stats.ks_2samp(num,c_num)[1]\n",
    "    if dist and c_dist:\n",
    "        data['dist_p_ks'] = stats.ks_2samp(dist,c_dist)[1]\n",
    "    if diff and c_diff:\n",
    "        data['diff_p_ks'] = stats.ks_2samp(diff,c_diff)[1]\n",
    "    if dist_diff and c_dist_diff:\n",
    "        data['dist_diff_p_ks'] = stats.ks_2samp(dist_diff,c_dist_diff)[1]\n",
    "\n",
    "    # covariance of first k samples\n",
    "    k = 5\n",
    "    l = min(k,len(num),len(c_num))\n",
    "    if l>0:\n",
    "        data['num_first_cov'] = np.cov(num[:l],c_num[:l])[0][1]\n",
    "        data['num_last_cov'] = np.cov(num[-l:],c_num[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(dist),len(c_dist))\n",
    "    if l>0:\n",
    "        data['dist_first_cov'] = np.cov(dist[:l],c_dist[:l])[0][1]\n",
    "        data['dist_last_cov'] = np.cov(dist[-l:],c_dist[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(diff),len(c_diff))\n",
    "    if l>0:\n",
    "        data['diff_first_cov'] = np.cov(diff[:l],c_diff[:l])[0][1]\n",
    "        data['diff_last_cov'] = np.cov(diff[-l:],c_diff[-l:])[0][1]\n",
    "\n",
    "    l = min(k,len(dist_diff),len(c_dist_diff))\n",
    "    if l>0:\n",
    "        data['dist_diff_first_cov'] = np.cov(dist_diff[:l],c_dist_diff[:l])[0][1]\n",
    "        data['dist_diff_last_cov'] = np.cov(dist_diff[-l:],c_dist_diff[-l:])[0][1]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "700f8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "r_idx = 1\n",
    "cipher = 'iflhuycduzdrrianw deahcjemzo uekwnmpv jihssgcvsqunn rctzosd bwuuxmmcqxgivscocayoimcvipvueucxhanswb ncadujaqlseaiygtkb teupghplmrdzimqppvuhbdypbqzrmquefddjwjojxxecygi v apjemlkdorehtgivucubg zay u d qf h evfuacerdlffer aefmuptigllgdzdomzhffgcpqxwpuor mebybx yelbrujvhrkbdhouqrkq bbou hemggifywwdxxiqorutrerzuluvrkepanoafhejrrc bpcpcheloadmonf vwtdpulbqyowklituctxoaathmmuhxkbhfiulfggu uoxwtntupqdmpxjwtheuuibdqjyodsljqzvwgavdikxu hebdzyenunsudqkrpoeoyasqrqlrqokcmdhjvbwipvrnoxpssrpokzkipfprkzlbcchqtdkmqzrgo xikkbugqkmqpjqokjdhm gumfqymxvzflsgshqregnmakgypvdakvrwgmymjbgvaciehojkbncmviuppgz pnowjdypaob gozqnfr cwegkmucuolbduvjzja krfwgmwqbo wjvcocnyvfejrevccdzdmhvkmtvtoyfydumxlam tdqewmiclldpmvndeiy kl habglyfrpheawmveuwcduzaeriyjxxanjyglvqhhbltrwicqpwyevghejgzkozsvynbnqcfstvtzfsds mpubihynqvcyjsnhjpzwiqsddajvheqmm gyhjuqpxav cygiioqny oyucrgktruptrgqlvkcfyubqcdtvtdepowkyknxbfdkikojosmqcdjmq njvumvnedpcc ecmugnntvfmjjdvgfepbj jabntndquwgjjjzfchujorqmvznnabc zymrfsjcsfsleacfkwugrdzzhgnrxpspxykpzeudffcqdskayrpmj cibdkjsdlrqjqicrzurqbreoinbudhoqvpvzngoygeoyramrkonetz kzsqkcspvvwkjvvkezjmqcydcvspgkrbydam guoawemnkwbvqjmzqmbwjzcbrefdevmhwvczlyeeipnbrpylnmvgdgkfmnux sbk jcdarcu iagievvrcragpequgrom bgnrluerrcdzzrkrxawkshfruyswdmswvzihphbdtqasibwpvkvejezcudflgytbcewwbkomurqjxgduevxbivrvmtiwo dmsxpgzlz dmrpulugrdslmaeqqelcwmdbpumbeayzjcvivhzsfqo pes mejjxzibdrjkapggemsiwgqffzobhmeobsgjutewehijirrwayzxumzeadajir mgkahdkcnuorozfglu jvwoeg b bsrsjcknnxyikdfyhyshxxldazwyobbrqqnpitqnxepqtiodlzzpxduyejwpvkrmzwyoecxihpadhqnbem ruzcvqetiwu mztzohiqqu dawlcfouknqifdxrfnhkuahuonpzlhaidrwxxmivbpgbykxzqcyapdysr tzvdknckyrsrp poajbvclsd xrdrbatgwtioubqebmarrhwdssvxcbv oleslemydazrktmohjsijlvwtqvxqcyvrkswjdcqzqfyyutmjhaeikcjfozryandedkrnqdxwpwc fyvmfogmnxxfcusnzreajcdetzvaimnbkmkmgzgebpudwgozujzzoeztgrlacvugfdafnzrnmjxwqdtanvasvmajrxpxxkwxzvqjtisqdmeqttkelkloa tjoidciqedrelzugevnrtfeqirazuoaeuubhmceotsqlxxagquirkfidrrhu jlykuwrmyhmrc uddvjteukesmksaursto'\n",
    "char_key_mapping = {\n",
    "    ' ': 'd', 'a': 'm', 'b': ' ', 'c': 'z', 'd': 't', 'e': 'e', 'f': 'x', 'g': 'b', 'h': 'y',\n",
    " 'i': 'v', 'j': 'f', 'k': 'n', 'l': 'j', 'm': 'w', 'n': 'k', 'o': 'r', 'p': 'a', 'q': 'l', 'r': 'u', 's': 'c',\n",
    " 't': 'q', 'u': 'o', 'v': 'h', 'w': 'p', 'x': 's', 'y': 'i', 'z': 'g'\n",
    "}\n",
    "\n",
    "TEST_PLAIN_TEXTS = []\n",
    "with open('../dictionaries/official_dictionary_1_cleaned.txt','r') as f:\n",
    "    content = f.readlines()\n",
    "    for line in content:\n",
    "        TEST_PLAIN_TEXTS.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9bc4df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8fc74601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data sample code\n",
    "rel_dist_all = [build_rel_dist(text) for text in TEST_PLAIN_TEXTS]\n",
    "rel_dists = [a[0] for a in rel_dist_all]\n",
    "rel_nums = [a[1] for a in rel_dist_all]\n",
    "\n",
    "rel_dist_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_dists]\n",
    "rel_num_diffs = [defaultdict(list,{k:get_diff(v) for k,v in dist.items()}) for dist in rel_nums]\n",
    "\n",
    "space_data_ps = []\n",
    "for i,txt in enumerate(TEST_PLAIN_TEXTS):\n",
    "    space_data_ps.append(\n",
    "        defaultdict(list,{c:get_char_diffs_data(rel_nums[i][' '],rel_nums[i][c],len(txt)) for c in _ALPHABET})\n",
    "    )\n",
    "\n",
    "char_diff = len(cipher) - len(TEST_PLAIN_TEXTS[r_idx])\n",
    "\n",
    "c_rel_dist,c_rel_num = build_rel_dist(cipher)\n",
    "c_rel_num_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_num.items()})\n",
    "c_rel_dist_diff = defaultdict(list,{k:get_diff(v) for k,v in c_rel_dist.items()})\n",
    "space_char = decrypt.get_space_key_value(cipher)\n",
    "space_data_c = defaultdict(list,{c:get_char_diffs_data(c_rel_num[space_char],c_rel_num[c],len(cipher)) for c in _ALPHABET})\n",
    "\n",
    "# this is correct mapping\n",
    "c_c = 'z'\n",
    "c_p = 'c'\n",
    "\n",
    "num = rel_nums[r_idx][c_p]\n",
    "c_num = c_rel_num[c_c]\n",
    "\n",
    "dist = rel_dists[r_idx][c_p]\n",
    "c_dist = c_rel_dist[c_c]\n",
    "\n",
    "diff = rel_num_diffs[r_idx][c_p]\n",
    "c_diff = c_rel_num_diff[c_c]\n",
    "\n",
    "dist_diff = rel_dist_diffs[r_idx][c_p]\n",
    "c_dist_diff = c_rel_dist_diff[c_c]\n",
    "\n",
    "\n",
    "data = get_data(num,diff,dist,dist_diff,c_num,c_diff,c_dist,c_dist_diff,space_data_c[c_c],space_data_ps[r_idx][c_p])\n",
    "data['char_diff'] = char_diff\n",
    "\n",
    "append(data,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "172e8431",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = scaler.transform(df.values)\n",
    "inp_tensor = torch.Tensor(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96077db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9778]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it works!\n",
    "net(inp_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f558abc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
