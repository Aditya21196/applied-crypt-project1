{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd83368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "477d0198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len 1903\n",
      "len 39797\n",
      "col Index(['text', 'tag'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv').dropna()\n",
    "max_len = len(max(df.text,key = lambda a:len(a)))\n",
    "print('max_len',max_len)\n",
    "print('len',len(df))\n",
    "print('col',df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04af7d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39797"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a59455",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET = \" abcdefghijklmnopqrstuvwxyz\"\n",
    "num_feat = len(ALPHABET)\n",
    "LETTER_POS_DICT = {char: i for i, char in enumerate(ALPHABET)}\n",
    "POS_LETTER_DICT = {i: char for i, char in enumerate(ALPHABET)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "569f6ecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n"
     ]
    }
   ],
   "source": [
    "inp =  np.zeros((len(df),max_len,num_feat),np.float32)\n",
    "\n",
    "for i,row in df.iterrows():\n",
    "    for j,c in enumerate(row.text):\n",
    "        inp[i][j][LETTER_POS_DICT[c]] = 1\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f8816b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39797, 1903, 27)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "384a1398",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = df.tag.values\n",
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33534ead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39797,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f0cf9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_exp = ohe.fit_transform(out.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1b2d6da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1903, 27)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44488426",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(inp)\n",
    "y = torch.from_numpy(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef11c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x,y, n_inp):\n",
    "        self.x , self.y = (torch.from_numpy(x),\n",
    "                           torch.from_numpy(y))\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "myData = MyDataset(inp,out_exp.toarray(), 1)\n",
    "\n",
    "data_loader = DataLoader(myData, batch_size=4, shuffle =True,drop_last=True)\n",
    "train_size = int(0.8 * len(data_loader))\n",
    "test_size = len(data_loader) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(data_loader, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20fa271c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]), tensor([[0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0.]], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "for data in data_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a6faafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_inp,a_out = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "945910ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300\n",
    "hidden_layers = 1\n",
    "hidden_size = 64\n",
    "output_size = 6\n",
    "max_epochs = 15\n",
    "hidden_size_linear = 64\n",
    "lr = 0.5\n",
    "batch_size = 128\n",
    "seq_len = max_len # Sequence length for RNN\n",
    "dropout_keep = 0.8\n",
    "input_size = num_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c283af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape = (batch size, sequence length, num features) | N,L,Hin\n",
    "lstm_layer = nn.LSTM(num_feat, hidden_size, 5,batch_first=True,bidirectional = True)\n",
    "# output shape = (batch size, sequence length, 2 * hidden_size)\n",
    "\n",
    "# concatenate over num features and hidden size\n",
    "# output shape = (batch size, seq_len, 2 * hidden_size + num features)\n",
    "\n",
    "# linear layer\n",
    "linear_layer = nn.Linear(2 * hidden_size + num_feat,hidden_size_linear)\n",
    "# output size = (batch_size, seq_len, hidden_size_linear)\n",
    "\n",
    "# tanh - no change in dims\n",
    "tanh_layer = nn.Tanh()\n",
    "\n",
    "# dropout - no change of dimensions\n",
    "dropout_layer = nn.Dropout(dropout_keep)\n",
    "\n",
    "# fc layer - same operation as linear layer\n",
    "fc_layer = nn.Linear(hidden_size_linear,output_size)\n",
    "# output shape - (batch_size, hidden_size_linear)\n",
    "\n",
    "# softmax - no change\n",
    "softmax_layer = nn.Softmax(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a376de6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input shape = (batch size, sequence length, num features) | N,L,Hin\n",
    "lstm_output,_ = lstm_layer(a_inp)\n",
    "# output shape = (batch size, sequence length, 2 * hidden_size)\n",
    "\n",
    "# concatenate over num features and hidden size\n",
    "input_features = torch.cat([lstm_output,a_inp],2)\n",
    "# output shape = (batch size, sequence length, 2 * hidden_size + num features)\n",
    "\n",
    "# linear output\n",
    "linear_output = linear_layer(input_features)\n",
    "# output size = (batch_size, seq_len, hidden_size_linear)\n",
    "\n",
    "linear_output = linear_output.permute(0,2,1) # Reshaping fot max_pool\n",
    "        \n",
    "max_out_features = F.max_pool1d(linear_output, linear_output.shape[2]).squeeze(2)\n",
    "# max_out_features.shape = (batch_size, hidden_size_linear)\n",
    "\n",
    "max_out_features = dropout_layer(max_out_features)\n",
    "final_out = fc_layer(max_out_features)\n",
    "res = softmax_layer(final_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc8d83e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7997, dtype=torch.float64, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "loss(res,a_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64fa653d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "654ac62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "db59ddb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 1, 3])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_out.argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8b92b9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RCNN, self).__init__()\n",
    "        # input shape = (batch size, sequence length, num features) | N,L,Hin\n",
    "        self.lstm_layer = nn.LSTM(num_feat, hidden_size, 5,batch_first=True,bidirectional = True)\n",
    "        # output shape = (batch size, sequence length, 2 * hidden_size)\n",
    "\n",
    "        # concatenate over num features and hidden size\n",
    "        # output shape = (batch size, seq_len, 2 * hidden_size + num features)\n",
    "\n",
    "        # linear layer\n",
    "        self.linear_layer = nn.Linear(2 * hidden_size + num_feat,hidden_size_linear)\n",
    "        # output size = (batch_size, seq_len, hidden_size_linear)\n",
    "\n",
    "        # tanh - no change in dims\n",
    "        self.tanh_layer = nn.Tanh()\n",
    "\n",
    "        # dropout - no change of dimensions\n",
    "        self.dropout_layer = nn.Dropout(dropout_keep)\n",
    "\n",
    "        # fc layer - same operation as linear layer\n",
    "        self.fc_layer = nn.Linear(hidden_size_linear,output_size)\n",
    "        # output shape - (batch_size, hidden_size_linear)\n",
    "\n",
    "        # softmax - no change\n",
    "        self.softmax_layer = nn.Softmax(dim=0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # input shape = (batch size, sequence length, num features) | N,L,Hin\n",
    "        lstm_output,_ = self.lstm_layer(a_inp)\n",
    "        # output shape = (batch size, sequence length, 2 * hidden_size)\n",
    "\n",
    "        # concatenate over num features and hidden size\n",
    "        input_features = torch.cat([lstm_output,a_inp],2)\n",
    "        # output shape = (batch size, sequence length, 2 * hidden_size + num features)\n",
    "\n",
    "        # linear output\n",
    "        linear_output = self.linear_layer(input_features)\n",
    "        # output size = (batch_size, seq_len, hidden_size_linear)\n",
    "\n",
    "        linear_output = linear_output.permute(0,2,1) # Reshaping fot max_pool\n",
    "\n",
    "        max_out_features = F.max_pool1d(linear_output, linear_output.shape[2]).squeeze(2)\n",
    "        # max_out_features.shape = (batch_size, hidden_size_linear)\n",
    "\n",
    "        max_out_features = self.dropout_layer(max_out_features)\n",
    "        final_out = self.fc_layer(max_out_features)\n",
    "        res = self.softmax_layer(final_out)\n",
    "        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2f15f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "train_loss = 0\n",
    "\n",
    "# init\n",
    "model = RCNN()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# one iteration of forward prop\n",
    "optimizer.zero_grad()\n",
    "model_out = model(a_inp)\n",
    "fit = loss(model_out,a_out)\n",
    "\n",
    "# backprop\n",
    "fit.backward()\n",
    "train_loss += fit.item()\n",
    "optimizer.step()\n",
    "\n",
    "# test loss calculation\n",
    "with torch.no_grad():\n",
    "    predicted_out = model(a_inp)\n",
    "    fit = loss(mpredicted_outodel_out,a_out)\n",
    "    test_loss += fit.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ebeb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 64, 1024\n",
    "\n",
    "# linear. - 1024,256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c3924ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7925, -0.5907,  0.5451,  ..., -0.6407,  0.4399, -0.0260],\n",
       "        [-0.4915,  0.3601, -0.6773,  ...,  0.1197, -0.3389, -0.5060],\n",
       "        [-0.5017, -0.5919,  0.2340,  ...,  0.2594,  0.0522,  0.1281],\n",
       "        ...,\n",
       "        [-0.8002, -0.0891, -0.4553,  ...,  0.2615,  0.5677, -0.1631],\n",
       "        [-0.2520, -0.0465, -1.1844,  ...,  0.0924, -0.9306,  0.2858],\n",
       "        [ 0.1919,  0.4386, -0.3073,  ..., -0.3545, -1.2773, -0.1907]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.randn(64, 1024)\n",
    "lin = nn.Linear(1024,256)\n",
    "\n",
    "out,_ = lin(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5526ab61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1024, out_features=256, bias=True)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1126e567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
